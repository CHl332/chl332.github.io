<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-minimal.min.css">
  <script src="/lib/pace/pace.min.js"></script>

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"right","display":"always","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="运气和努力一样重要">
<meta property="og:type" content="website">
<meta property="og:title" content="和善寺">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="和善寺">
<meta property="og:description" content="运气和努力一样重要">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="善善332">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>和善寺</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="和善寺" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">和善寺</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">学习</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-resources">

    <a href="/resources/" rel="section"><i class="download fa-fw"></i>resources</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/10/12/20-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%882020%E6%9C%80%E6%96%B0%E7%89%88%EF%BC%89/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="善善332">
      <meta itemprop="description" content="运气和努力一样重要">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="和善寺">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/10/12/20-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%882020%E6%9C%80%E6%96%B0%E7%89%88%EF%BC%89/" class="post-title-link" itemprop="url">未命名</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-10-12 15:01:16" itemprop="dateCreated datePublished" datetime="2022-10-12T15:01:16+08:00">2022-10-12</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-03-03 13:51:38" itemprop="dateModified" datetime="2021-03-03T13:51:38+08:00">2021-03-03</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="计算机网络体系结构"><a href="#计算机网络体系结构" class="headerlink" title="计算机网络体系结构"></a>计算机网络体系结构</h1><p>在计算机网络的基本概念中，分层次的体系结构是  基本的。计算机网络体系结</p>
<p>构的抽象概念较多，在学习时要多思考。这些概念对后面的学习很有帮助。</p>
<h2 id="网络协议是什么？"><a href="#网络协议是什么？" class="headerlink" title="网络协议是什么？"></a>网络协议是什么？</h2><p>在计算机网络要做到有条不紊地交换数据，就必须遵守一些事先约定好的规则， 比如交换数据的格式、是否需要发送一个应答信息。这些规则被称为网络协议。 </p>
<h2 id="为什么要对网络协议分层？"><a href="#为什么要对网络协议分层？" class="headerlink" title="为什么要对网络协议分层？"></a>为什么要对网络协议分层？</h2><ul>
<li>简化问题难度和复杂度。由于各层之间独立，我们可以分割大问题为小问题。 </li>
<li>灵活性好。当其中一层的技术变化时，只要层间接口关系保持不变，其他层不受 影响。 </li>
<li>易于实现和维护。 </li>
<li>促进标准化工作。分开后，每层功能可以相对简单地被描述。</li>
</ul>
<p>网络协议分层的缺点： 功能可能出现在多个层里，产生了额外开销。 为了使不同体系结构的计算机网络都能互联，国际标准化组织 ISO 于1977年提 出了一个试图使各种计算机在世界范围内互联成网的标准框架，即著名的开放系统互联基本参考模型 OSI&#x2F;RM，简称为OSI。 </p>
<p>OSI 的七层协议体系结构的概念清楚，理论也较完整，但它既复杂又不实用， TCP&#x2F;IP 体系结构则不同，但它现在却得到了非常广泛的应用。TCP&#x2F;IP 是一个四 层体系结构，它包含应用层，运输层，网际层和网络接口层（用网际层这个名字 是强调这一层是为了解决不同网络的互连问题），不过从实质上讲，TCP&#x2F;IP 只 有上面的三层，因为下面的网络接口层并没有什么具体内容，因此在学习计 算机网络的原理时往往采用折中的办法，即综合 OSI 和 TCP&#x2F;IP 的优点，采用 一种只有五层协议的体系结构，这样既简洁又能将概念阐述清楚，有时为了方 便，也可把底下两层称为网络接口层。 </p>
<ul>
<li>四层协议，五层协议和七层协议的关系如下： </li>
<li>TCP&#x2F;IP是一个四层的体系结构，主要包括：应用层、运输层、网际层和网络接 口层。 </li>
<li>五层协议的体系结构主要包括：应用层、运输层、网络层，数据链路层和物理层。 </li>
<li>OSI七层协议模型主要包括是：应用层（Application）、表示层 （Presentation）、会话层（Session）、运输层（Transport）、网络层 （Network）、数据链路层（Data Link）、物理层（Physical）。</li>
</ul>
<p><img src="/20-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%882020%E6%9C%80%E6%96%B0%E7%89%88%EF%BC%89.assets/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84.png" alt="计算机网络体系结构"></p>
<p>注：五层协议的体系结构只是为了介绍网络原理而设计的，实际应用还是  TCP&#x2F;IP 四层体系结构。 </p>
<h1 id="TCP-x2F-IP-四层体系结构。-TCP-x2F-IP-协议族"><a href="#TCP-x2F-IP-四层体系结构。-TCP-x2F-IP-协议族" class="headerlink" title="TCP&#x2F;IP 四层体系结构。 TCP&#x2F;IP 协议族"></a>TCP&#x2F;IP 四层体系结构。 TCP&#x2F;IP 协议族</h1><h2 id="应用层"><a href="#应用层" class="headerlink" title="应用层"></a>应用层</h2><p>应用层( application-layer ）的任务是通过应用进程间的交互来完成特定网络应 用。应用层协议定义的是应用进程（进程：主机中正在运行的程序）间的通信和 交互的规则。 </p>
<p>对于不同的网络应用需要不同的应用层协议。在互联网中应用层协议很多，如域 名系统 DNS，支持万维网应用的 HTTP 协议，支持电子邮件的 SMTP 协议等 等。 </p>
<h2 id="运输层"><a href="#运输层" class="headerlink" title="运输层"></a>运输层</h2><p>运输层(transport layer)的主要任务就是负责向两台主机进程之间的通信提供通 用的数据传输服务。应用进程利用该服务传送应用层报文。 运输层主要使用一下两种协议 </p>
<ol>
<li>传输控制协议-TCP：提供面向连接的，可靠的数据传输服务。 </li>
<li>用户数据协议-UDP：提供无连接的，尽大努力的数据传输服务（不 保证数据传输的可靠性）。</li>
</ol>
<table>
<thead>
<tr>
<th>UDP</th>
<th>TCP</th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>是否连接</td>
<td>无连接</td>
<td>面向连接</td>
</tr>
<tr>
<td>是否可靠</td>
<td>不可靠传 输，不使 用流量控 制和拥塞 控制</td>
<td>可靠传 输，使用 流量控制 和拥塞控 制</td>
</tr>
<tr>
<td>连接对象 个数</td>
<td>支持一对 一，一对 多，多对 一和多对 多交互通 信</td>
<td>只能是一 对一通信</td>
</tr>
<tr>
<td>传输方式</td>
<td>面向报文</td>
<td>面向字节 流</td>
</tr>
<tr>
<td>首部开销</td>
<td>首部开销 小，仅8字 节</td>
<td>首部小 20字节， 大60字 节</td>
</tr>
<tr>
<td>场景</td>
<td>适用于实 时应用 （IP电 话、视频会议、直 播等）</td>
<td>适用于要 求可靠传 输的应 用，例如 文件传输</td>
</tr>
</tbody></table>
<p>每一个应用层（TCP&#x2F;IP参考模型的最高层）协议一般都会使用到两个传输层协 议之一： </p>
<p>运行在TCP协议上的协议： </p>
<ul>
<li><strong>HTTP（Hypertext Transfer Protocol，超文本传输协议）</strong>，主要用于普通浏 览。 </li>
<li><strong>HTTPS（HTTP over SSL，安全超文本传输协议）</strong>,HTTP协议的安全版本。 </li>
<li><strong>FTP（File Transfer Protocol，文件传输协议）</strong>，用于文件传输。 </li>
<li><strong>POP3（Post Office Protocol, version 3，邮局协议）</strong>，收邮件用。 </li>
<li><strong>SMTP（Simple Mail Transfer Protocol，简单邮件传输协议）</strong>，用来发送电子 邮件。 </li>
<li><strong>TELNET（Teletype over the Network，网络电传）</strong>，通过一个终端 （terminal）登陆到网络。 </li>
<li><strong>SSH（Secure Shell，用于替代安全性差的TELNET）</strong>，用于加密安全登陆用。 运行在UDP协议上的协议： </li>
<li><strong>BOOTP（Boot Protocol，启动协议）</strong>，应用于无盘设备。 </li>
<li><strong>NTP（Network Time Protocol，网络时间协议）</strong>，用于网络同步。 </li>
<li><strong>DHCP（Dynamic Host Configuration Protocol，动态主机配置协议）</strong>，动态 配置IP地址。 运行在TCP和UDP协议上： </li>
<li><strong>DNS（Domain Name Service，域名服务）</strong>，用于完成地址查找，邮件转发等 工作。</li>
</ul>
<h2 id="网络层"><a href="#网络层" class="headerlink" title="网络层"></a>网络层</h2><p>网络层的任务就是选择合适的网间路由和交换结点，确保计算机通信的数据及时 传送。在发送数据时，网络层把运输层产生的报文段或用户数据报封装成分组和 包进行传送。在 TCP&#x2F;IP 体系结构中，由于网络层使用 IP 协议，因此分组也叫  IP 数据报 ，简称数据报。 </p>
<p>互联网是由大量的异构（heterogeneous）网络通过路由器（router）相互连 接起来的。互联网使用的网络层协议是无连接的网际协议（Intert Prococol） 和许多路由选择协议，因此互联网的网络层也叫做网际层或 IP 层。 </p>
<h2 id="数据链路层"><a href="#数据链路层" class="headerlink" title="数据链路层"></a>数据链路层</h2><p>数据链路层(data link layer)通常简称为链路层。两台主机之间的数据传输，总 是在一段一段的链路上传送的，这就需要使用专门的链路层的协议。 </p>
<p>在两个相邻节点之间传送数据时，数据链路层将网络层交下来的 IP 数据报组装 成帧，在两个相邻节点间的链路上传送帧。每一帧包括数据和必要的控制信息 （如同步信息，地址信息，差错控制等）。 </p>
<p>在接收数据时，控制信息使接收端能够知道一个帧从哪个比特开始和到哪个比特 结束。 </p>
<p>一般的web应用的通信传输流是这样的：</p>
<p><img src="/20-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%882020%E6%9C%80%E6%96%B0%E7%89%88%EF%BC%89.assets/web%E5%BA%94%E7%94%A8%E9%80%9A%E4%BF%A1%E4%BC%A0%E8%BE%93%E6%B5%81.png" alt="web应用通信传输流"></p>
<p>发送端在层与层之间传输数据时，每经过一层时会被打上一个该层所属的首部信 息。反之，接收端在层与层之间传输数据时，每经过一层时会把对应的首部信息 去除。 </p>
<h2 id="物理层"><a href="#物理层" class="headerlink" title="物理层"></a>物理层</h2><p>在物理层上所传送的数据单位是比特。 物理层(physical layer)的作用是实现相 邻计算机节点之间比特流的透明传送，尽可能屏蔽掉具体传输介质和物理设备的 差异。使其上面的数据链路层不必考虑网络的具体传输介质是什么。“透明传送 比特流”表示经实际电路传送后的比特流没有发生变化，对传送的比特流来说， 这个电路好像是看不见的。</p>
<h2 id="TCP-x2F-IP-协议族"><a href="#TCP-x2F-IP-协议族" class="headerlink" title="TCP&#x2F;IP 协议族"></a>TCP&#x2F;IP 协议族</h2><p>在互联网使用的各种协议中重要和著名的就是 TCP&#x2F;IP 两个协议。现在人们 经常提到的 TCP&#x2F;IP 并不一定是单指 TCP 和 IP 这两个具体的协议，而往往是表 示互联网所使用的整个 TCP&#x2F;IP 协议族。</p>
<p>![TCP_IP 协议族](20-计算机网络面试题（2020最新版）.assets&#x2F;TCP_IP 协议族.png)</p>
<blockquote>
<p>互联网协议套件（英语：Internet Protocol Suite，缩写<strong>IPS</strong>）是一个网络通讯模型， 以及一整个网络传输协议家族，为网际网络的基础通讯架构。它常被通称为TCP&#x2F;IP协 议族（英语：<strong>TCP&#x2F;IP Protocol Suite</strong>，或<strong>TCP&#x2F;IP Protocols</strong>），简称<strong>TCP&#x2F;IP</strong>。因为该 协定家族的两个核心协定：<strong>TCP（传输控制协议）和IP（网际协议）</strong>，为该家族中早 通过的标准。 </p>
</blockquote>
<p>划重点： </p>
<p><strong>TCP（传输控制协议）和IP（网际协议）</strong> 是先定义的两个核心协议，所以才统称为<strong>TCP&#x2F;IP协议族</strong></p>
<h2 id="TCP的三次握手四次挥手"><a href="#TCP的三次握手四次挥手" class="headerlink" title="TCP的三次握手四次挥手"></a>TCP的三次握手四次挥手</h2><p>TCP是一种面向连接的、可靠的、基于字节流的传输层通信协议，在发送数据 前，通信双方必须在彼此间建立一条连接。所谓的“连接”，其实是客户端和服 务端保存的一份关于对方的信息，如ip地址、端口号等。</p>
<p>TCP可以看成是一种字节流，它会处理IP层或以下的层的丢包、重复以及错误问 题。在连接的建立过程中，双方需要交换一些连接的参数。这些参数可以放在 TCP头部。 </p>
<p>一个TCP连接由一个4元组构成，分别是两个IP地址和两个端口号。一个TCP连 接通常分为三个阶段：连接、数据传输、退出（关闭）。<strong>通过三次握手建立一个 链接，通过四次挥手来关闭一个连接。</strong> </p>
<p>**当一个连接被建立或被终止时，交换的报文段只包含TCP头部，而没有数据。 **</p>
<h2 id="TCP报文的头部结构"><a href="#TCP报文的头部结构" class="headerlink" title="TCP报文的头部结构"></a>TCP报文的头部结构</h2><p>在了解TCP连接之前先来了解一下TCP报文的头部结构。</p>
<p><img src="/20-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%882020%E6%9C%80%E6%96%B0%E7%89%88%EF%BC%89.assets/TCP%E6%8A%A5%E6%96%87%E5%A4%B4%E9%83%A8%E7%BB%93%E6%9E%84.png" alt="TCP报文头部结构"></p>
<p>上图中有几个字段需要重点介绍下： </p>
<p>（1）序号：seq序号，占32位，用来标识从TCP源端向目的端发送的字节流， 发起方发送数据时对此进行标记。 </p>
<p>（2）确认序号：ack序号，占32位，只有ACK标志位为1时，确认序号字段才有 效，ack&#x3D;seq+1。 </p>
<p>（3）标志位：共6个，即URG、ACK、PSH、RST、SYN、FIN等，具体含义如 下： </p>
<ul>
<li>ACK：确认序号有效。 </li>
<li>FIN：释放一个连接。 </li>
<li>PSH：接收方应该尽快将这个报文交给应用层。 </li>
<li>RST：重置连接。 </li>
<li>SYN：发起一个新连接。 </li>
<li>URG：紧急指针（urgent pointer）有效。</li>
</ul>
<p>需要注意的是： </p>
<ul>
<li>不要将确认序号ack与标志位中的ACK搞混了。</li>
<li>确认方ack&#x3D;发起方seq+1，两端配对。</li>
</ul>
<h2 id="三次握手"><a href="#三次握手" class="headerlink" title="三次握手"></a>三次握手</h2><p>三次握手的本质是确认通信双方收发数据的能力首先，我让信使运输一份信件给对方，对方收到了，那么他就知道了我的发件能力和他的收件能力是可以的。</p>
<p>于是他给我回信，我若收到了，我便知我的发件能力和他的收件能力是可以的，并且他的发件能力和我的收件能力是可以。</p>
<p>然而此时他还不知道他的发件能力和我的收件能力到底可不可以，于是我 后回馈一次，他若收到了，他便清楚了他的发件能力和我的收件能力是可以的。这，就是三次握手，这样说，你理解了吗？</p>
<p><img src="/20-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%882020%E6%9C%80%E6%96%B0%E7%89%88%EF%BC%89.assets/%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B.jpg" alt="三次握手"></p>
<ul>
<li>第一次握手：客户端要向服务端发起连接请求，首先客户端随机生成一个起始序列号ISN(比如是100)，那客户端向服务端发送的报文段包含SYN标志位(也就是SYN&#x3D;1)，序列号seq&#x3D;100。</li>
<li>第二次握手：服务端收到客户端发过来的报文后，发现SYN&#x3D;1，知道这是一个连接请求，于是将客户端的起始序列号100存起来，并且随机生成一个服务端的起始序列号(比如是300)。然后给客户端回复一段报文，回复报文包含SYN和ACK标志(也就是SYN&#x3D;1,ACK&#x3D;1)、序列号seq&#x3D;300、确认号ack&#x3D;101(客户端发过来的序列号+1)。</li>
<li>第三次握手：客户端收到服务端的回复后发现ACK&#x3D;1并且ack&#x3D;101,于是知道服务端已经收到了序列号为100的那段报文；同时发现SYN&#x3D;1，知道了服务端同意了这次连接，于是就将服务端的序列号300给存下来。然后客户端再回复一段报文给服务端，报文包含ACK标志位(ACK&#x3D;1)、ack&#x3D;301(服务端序列号+1)、seq&#x3D;101(第一次握手时发送报文是占据一个序列号的，所以这次seq就从101开始，需要注意的是不携带数据的ACK报文是不占据序列号的，所以后面第一次正式发送数据时seq还是101)。当服务端收到报文后发现ACK&#x3D;1并且ack&#x3D;301，就知道客户端收到序列号为300的报文了，就这样客户端和服务端通过TCP建立了连接。</li>
</ul>
<h2 id="四次挥手"><a href="#四次挥手" class="headerlink" title="四次挥手"></a>四次挥手</h2><p>四次挥手的目的是关闭一个连接</p>
<p><img src="/20-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%882020%E6%9C%80%E6%96%B0%E7%89%88%EF%BC%89.assets/%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B.jpg" alt="四次挥手"></p>
<p>比如客户端初始化的序列号ISA&#x3D;100，服务端初始化的序列号ISA&#x3D;300。TCP连接成功后客户端总共发送了1000个字节的数据，服务端在客户端发FIN报文前总共回复了2000个字节的数据。</p>
<ul>
<li>第一次挥手：当客户端的数据都传输完成后，客户端向服务端发出连接释放报文(当然数据没发完时也可以发送连接释放报文并停止发送数据)，释放连接报文包含FIN标志位(FIN&#x3D;1)、序列号seq&#x3D;1101(100+1+1000，其中的1是建立连接时占的一个序列号)。需要注意的是客户端发出FIN报文段后只是不能发数据了，但是还可以正常收数据；另外FIN报文段即使不携带数据也要占据一个序列号。</li>
<li>第二次挥手：服务端收到客户端发的FIN报文后给客户端回复确认报文，确认报文包含ACK标志位(ACK&#x3D;1)、确认号ack&#x3D;1102(客户端FIN报文序列号1101+1)、序列号seq&#x3D;2300(300+2000)。此时服务端处于关闭等待状态，而不是立马给客户端发FIN报文，这个状态还要持续一段时间，因为服务端可能还有数据没发完。</li>
<li>第三次挥手：服务端将最后数据(比如50个字节)发送完毕后就向客户端发出连接释放报文，报文包含FIN和ACK标志位(FIN&#x3D;1,ACK&#x3D;1)、确认号和第二次挥手一样ack&#x3D;1102、序列号seq&#x3D;2350(2300+50)。</li>
<li>第四次挥手：客户端收到服务端发的FIN报文后，向服务端发出确认报文，确认报文包含ACK标志位(ACK&#x3D;1)、确认号ack&#x3D;2351、序列号seq&#x3D;1102。注意客户端发出确认报文后不是立马释放TCP连接，而是要经过2MSL(最长报文段寿命的2倍时长)后才释放TCP连接。而服务端一旦收到客户端发出的确认报文就会立马释放TCP连接，所以服务端结束TCP连接的时间要比客户端早一些。</li>
</ul>
<h1 id="常见面试题"><a href="#常见面试题" class="headerlink" title="常见面试题"></a>常见面试题</h1><h2 id="为什么TCP连接的时候是3次？2次不可以吗？"><a href="#为什么TCP连接的时候是3次？2次不可以吗？" class="headerlink" title="为什么TCP连接的时候是3次？2次不可以吗？"></a>为什么TCP连接的时候是3次？2次不可以吗？</h2><p>因为需要考虑连接时丢包的问题，如果只握手2次，第二次握手时如果服务端发给客户端的确认报文段丢失，此时服务端已经准备好了收发数(可以理解服务端已经连接成功)据，而客户端一直没收到服务端的确认报文，所以客户端就不知道服务端是否已经准备好了(可以理解为客户端未连接成功)，这种情况下客户端不会给服务端发数据，也会忽略服务端发过来的数据。</p>
<p>如果是三次握手，即便发生丢包也不会有问题，比如如果第三次握手客户端发的确认ack报文丢失，服务端在一段时间内没有收到确认ack报文的话就会重新进</p>
<p>行第二次握手，也就是服务端会重发SYN报文段，客户端收到重发的报文段后会再次给服务端发送确认ack报文。</p>
<h2 id="为什么TCP连接的时候是3次，关闭的时候却是4次？"><a href="#为什么TCP连接的时候是3次，关闭的时候却是4次？" class="headerlink" title="为什么TCP连接的时候是3次，关闭的时候却是4次？"></a>为什么TCP连接的时候是3次，关闭的时候却是4次？</h2><p>因为只有在客户端和服务端都没有数据要发送的时候才能断开TCP。而客户端发出FIN报文时只能保证客户端没有数据发了，服务端还有没有数据发客户端是不知道的。而服务端收到客户端的FIN报文后只能先回复客户端一个确认报文来告诉客户端我服务端已经收到你的FIN报文了，但我服务端还有一些数据没发完，等这些数据发完了服务端才能给客户端发FIN报文(所以不能一次性将确认报文和</p>
<p>FIN报文发给客户端，就是这里多出来了一次)。</p>
<h2 id="为什么客户端发出第四次挥手的确认报文后要等2MSL的时间才能释放TCP连接？"><a href="#为什么客户端发出第四次挥手的确认报文后要等2MSL的时间才能释放TCP连接？" class="headerlink" title="为什么客户端发出第四次挥手的确认报文后要等2MSL的时间才能释放TCP连接？"></a>为什么客户端发出第四次挥手的确认报文后要等2MSL的时间才能释放TCP连接？</h2><p>这里同样是要考虑丢包的问题，如果第四次挥手的报文丢失，服务端没收到确认 ack报文就会重发第三次挥手的报文，这样报文一去一回  长时间就是2MSL，所以需要等这么长时间来确认服务端确实已经收到了。</p>
<h2 id="如果已经建立了连接，但是客户端突然出现故障了怎么办？"><a href="#如果已经建立了连接，但是客户端突然出现故障了怎么办？" class="headerlink" title="如果已经建立了连接，但是客户端突然出现故障了怎么办？"></a>如果已经建立了连接，但是客户端突然出现故障了怎么办？</h2><p>TCP设有一个保活计时器，客户端如果出现故障，服务器不能一直等下去，白白浪费资源。服务器每收到一次客户端的请求后都会重新复位这个计时器，时间通常是设置为2小时，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75秒钟发送一次。若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。什么是HTTP，HTTP 与 HTTPS 的区别</p>
<p>HTTP 是一个在计算机世界里专门在两点之间传输文字、图片、音频、视频等超文本数据的约定和规范</p>
<table>
<thead>
<tr>
<th>区别</th>
<th>HTTP</th>
<th>HTTPS</th>
</tr>
</thead>
<tbody><tr>
<td>协议</td>
<td>运行在   TCP 之上，明文传输，客户端与服务器端都无法验证对方的身份</td>
<td>身披 SSL(   Secure   Socket   Layer  )外壳的   HTTP，运行于 SSL 上，SSL 运行于   TCP 之  上，  是添加了加密和认证机制的   HTTP。</td>
</tr>
<tr>
<td>端口</td>
<td>80</td>
<td>443</td>
</tr>
<tr>
<td>资源消耗</td>
<td>较少</td>
<td>由于加解密处理，会消耗更  多的 CPU 和内存资源</td>
</tr>
<tr>
<td>开销</td>
<td>无需证书</td>
<td>需要证书，而证书一般需要向认证机构购买</td>
</tr>
<tr>
<td>加密机制</td>
<td>无</td>
<td>共享密钥加密和公开密钥加密并用的混合加密机制</td>
</tr>
<tr>
<td>安全性</td>
<td>弱</td>
<td>由于加密机制，安全性强</td>
</tr>
</tbody></table>
<h2 id="常用HTTP状态码"><a href="#常用HTTP状态码" class="headerlink" title="常用HTTP状态码"></a>常用HTTP状态码</h2><p>HTTP状态码表示客户端HTTP请求的返回结果、标识服务器处理是否正常、表明请求出现的错误等。</p>
<p>状态码的类别：</p>
<table>
<thead>
<tr>
<th>类别</th>
<th>原因短语</th>
</tr>
</thead>
<tbody><tr>
<td>1XX</td>
<td>Informational（信息性状态码）接受的请求正在处理</td>
</tr>
<tr>
<td>2XX</td>
<td>Success（成功状态码）请求正常处理完毕</td>
</tr>
<tr>
<td>3XX</td>
<td>Redirection（重定向状态码）需要进行附加操作以完成请求</td>
</tr>
<tr>
<td>4XX</td>
<td>Client   Error（客户端错误状态码）服务器无法处理请求</td>
</tr>
<tr>
<td>5XX</td>
<td>Server   Error（服务器错误状态码）服务器处理请求出错</td>
</tr>
</tbody></table>
<p>常用HTTP状态码：</p>
<table>
<thead>
<tr>
<th>2XX</th>
<th>成功（这系列表明请求被正常处理了）</th>
</tr>
</thead>
<tbody><tr>
<td>200</td>
<td>OK，表示从客户端发来的请求在服务器端被正确处理</td>
</tr>
<tr>
<td>204</td>
<td>No   content，表示请求成功，但响应报文不含实体的主体部分</td>
</tr>
<tr>
<td>206</td>
<td>Partial   Content  ，进行范围请求成功</td>
</tr>
<tr>
<td>3XX</td>
<td>重定向  （表明浏览器要执行特殊处理）</td>
</tr>
<tr>
<td>301</td>
<td>moved permanently，永久  性重定向，表示资源已被分配了新的 URL</td>
</tr>
<tr>
<td>302</td>
<td>found，临时性重定向，表示资源临时被分配了新的   URL</td>
</tr>
<tr>
<td>303</td>
<td>see   other，表示资源存在着另一个 URL，  应使用   GET 方法获取资源  （对于  301&#x2F;302&#x2F;  303响应，几乎所有浏览器都会删除报文主体并  自动用  GET重新请求）</td>
</tr>
<tr>
<td>304</td>
<td>not   modified ，表示服务器允许访问资源，但请求未满足条件的情况（与重定向无关）</td>
</tr>
<tr>
<td>307</td>
<td>temporary   redirect，临时重定  向，和302 含义类似，但是期望客户端保持请求方法不变向新的地址发出请求</td>
</tr>
<tr>
<td>4XX</td>
<td>客户端错误</td>
</tr>
<tr>
<td>400</td>
<td>bad   request，请求报文存在语法错误</td>
</tr>
<tr>
<td>401</td>
<td>unauthorized，表示发送的请求需要有通过   HTTP 认证的认证信息</td>
</tr>
<tr>
<td>403</td>
<td>forbidden  ，表示对请求资源的访问被服务器拒绝，可在实体主体部分返回原因描述</td>
</tr>
<tr>
<td>404</td>
<td>not   found，表示在服务器上没有找到请求的资源</td>
</tr>
<tr>
<td>5XX</td>
<td>服务器错误</td>
</tr>
<tr>
<td>500</td>
<td>internal   sever   error，表  示服务器端在执行请求时发生了错误</td>
</tr>
<tr>
<td>501</td>
<td>Not   Implemented，表示服务器不支持当前请求所需要的某个功能</td>
</tr>
<tr>
<td>503</td>
<td>service unavailable，表明服务器暂时处于超负载或正在停机维护，无法处理请求</td>
</tr>
</tbody></table>
<h2 id="GET和POST区别"><a href="#GET和POST区别" class="headerlink" title="GET和POST区别"></a>GET和POST区别</h2><p>说道GET和POST，就不得不提HTTP协议，因为浏览器和服务器的交互是通过</p>
<p>HTTP协议执行的，而GET和POST也是HTTP协议中的两种方法。</p>
<p>HTTP全称为Hyper Text Transfer Protocol，中文翻译为超文本传输协议，目的是保证浏览器与服务器之间的通信。HTTP的工作方式是客户端与服务器之间的请求-应答协议。</p>
<p>HTTP协议中定义了浏览器和服务器进行交互的不同方法，基本方法有4种，分别是GET，POST，PUT，DELETE。这四种方法可以理解为，对服务器资源的查，改，增，删。</p>
<ul>
<li>GET：从服务器上获取数据，也就是所谓的查，仅仅是获取服务器资源，不进行修改。</li>
<li>POST：向服务器提交数据，这就涉及到了数据的更新，也就是更改服务器的数据。</li>
<li>PUT：英文含义是放置，也就是向服务器新添加数据，就是所谓的增。</li>
<li>DELETE：从字面意思也能看出，这种方式就是删除服务器数据的过程。</li>
</ul>
<p>GET和POST区别</p>
<p>\1. Get是不安全的，因为在传输过程，数据被放在请求的URL中；Post的所有操作对用户来说都是不可见的。 但是这种做法也不时绝对的，大部分人的做法也是按照上面的说法来的，但是也可以在get请求加上 request body，给 post请求带上 URL 参数。</p>
<p>\2. Get请求提交的url中的数据 多只能是2048字节，这个限制是浏览器或者服务器给添加的，http协议并没有对url长度进行限制，目的是为了保证服务器和浏览器能够正常运行，防止有人恶意发送请求。Post请求则没有大小限制。</p>
<p>\3. Get限制Form表单的数据集的值必须为ASCII字符；而Post支持整个</p>
<p>ISO10646字符集。</p>
<p>\4. Get执行效率却比Post方法好。Get是form提交的默认方法。</p>
<p>\5. GET产生一个TCP数据包；POST产生两个TCP数据包。对于GET方式的请求，浏览器会把http header和data一并发送出去，服务器响应200（返回数据）；而对于POST，浏览器先发送header，服务器响应100 continue，浏览器再发送data，服务器响应200 ok（返回数据）。</p>
<h2 id="什么是对称加密与非对称加密"><a href="#什么是对称加密与非对称加密" class="headerlink" title="什么是对称加密与非对称加密"></a>什么是对称加密与非对称加密</h2><p>对称密钥加密是指加密和解密使用同一个密钥的方式，这种方式存在的最大问题就是密钥发送问题，即如何安全地将密钥发给对方；而非对称加密是指使用一对非对称密钥，即公钥和私钥，公钥可以随意发布，但私钥只有自己知道。发送密文的一方使用对方的公钥进行加密处理，对方接收到加密信息后，使用自己的私钥进行解密。</p>
<p>由于非对称加密的方式不需要发送用来解密的私钥，所以可以保证安全性；但是和对称加密比起来，非常的慢什么是HTTP2</p>
<p>HTTP2 可以提高了网页的性能。</p>
<p>在 HTTP1 中浏览器限制了同一个域名下的请求数量（Chrome 下一般是六</p>
<p>个），当在请求很多资源的时候，由于队头阻塞当浏览器达到  大请求数量时，剩余的资源需等待当前的六个请求完成后才能发起请求。</p>
<p>HTTP2 中引入了多路复用的技术，这个技术可以只通过一个 TCP 连接就可以传输所有的请求数据。多路复用可以绕过浏览器限制同一个域名下的请求数量的问题，进而提高了网页的性能。</p>
<h2 id="Session、Cookie和Token的主要区别"><a href="#Session、Cookie和Token的主要区别" class="headerlink" title="Session、Cookie和Token的主要区别"></a>Session、Cookie和Token的主要区别</h2><p>HTTP协议本身是无状态的。什么是无状态呢，即服务器无法判断用户身份。</p>
<p>什么是cookie</p>
<p>cookie是由Web服务器保存在用户浏览器上的小文件（key-value格式），包含用户相关的信息。客户端向服务器发起请求，如果服务器需要记录该用户状态，就使用response向客户端浏览器颁发一个Cookie。客户端浏览器会把Cookie保存起来。当浏览器再请求该网站时，浏览器把请求的网址连同该Cookie一同提交给服务器。服务器检查该Cookie，以此来辨认用户身份。</p>
<p>什么是session</p>
<p>session是依赖Cookie实现的。session是服务器端对象</p>
<p>session 是浏览器和服务器会话过程中，服务器分配的一块储存空间。服务器默</p>
<p>认为浏览器在cookie中设置 sessionid，浏览器在向服务器请求过程中传输 </p>
<p>cookie 包含 sessionid ，服务器根据 sessionid 获取出会话中存储的信息，然后确定会话的身份信息。</p>
<p>cookie与session区别</p>
<p> 存储位置与安全性：cookie数据存放在客户端上，安全性较差，session数据放在服务器上，安全性相对更高；</p>
<p> 存储空间：单个cookie保存的数据不能超过4K，很多浏览器都限制一个站点多保存20个cookie，session无此限制</p>
<p> 占用服务器资源：session一定时间内保存在服务器上，当访问增多，占用服务器性能，考虑到服务器性能方面，应当使用cookie。</p>
<p>什么是Token</p>
<p>Token的引入：Token是在客户端频繁向服务端请求数据，服务端频繁的去数据库查询用户名和密码并进行对比，判断用户名和密码正确与否，并作出相应提示，在这样的背景下，Token便应运而生。</p>
<p>Token的定义：Token是服务端生成的一串字符串，以作客户端进行请求的一个令牌，当第一次登录后，服务器生成一个Token便将此Token返回给客户端，以后客户端只需带上这个Token前来请求数据即可，无需再次带上用户名和密码。使用Token的目的：Token的目的是为了减轻服务器的压力，减少频繁的查询数据库，使服务器更加健壮。</p>
<p>Token 是在服务端产生的。如果前端使用用户名&#x2F;密码向服务端请求认证，服务端认证成功，那么在服务端会返回 Token 给前端。前端可以在每次请求的时候带上 Token 证明自己的合法地位 session与token区别</p>
<ul>
<li>session机制存在服务器压力增大，CSRF跨站伪造请求攻击，扩展性不强等问题；</li>
<li>session存储在服务器端，token存储在客户端</li>
<li>token提供认证和授权功能，作为身份认证，token安全性比session好；</li>
<li>session这种会话存储方式方式只适用于客户端代码和服务端代码运行在同一台服务器上，token适用于项目级的前后端分离（前后端代码运行在不同的服务器下）</li>
</ul>
<h2 id="Servlet是线程安全的吗"><a href="#Servlet是线程安全的吗" class="headerlink" title="Servlet是线程安全的吗"></a>Servlet是线程安全的吗</h2><p>Servlet不是线程安全的，多线程并发的读写会导致数据不同步的问题。解决的办法是尽量不要定义name属性，而是要把name变量分别定义在doGet() 和doPost()方法内。虽然使用synchronized(name){}语句块可以解决问题，但是会造成线程的等待，不是很科学的办法。</p>
<p>注意：多线程的并发的读写Servlet类属性会导致数据不同步。但是如果只是并发地读取属性而不写入，则不存在数据不同步的问题。因此Servlet里的只读属性最好定义为final类型的。</p>
<h2 id="Servlet接口中有哪些方法及Servlet生命周期探秘"><a href="#Servlet接口中有哪些方法及Servlet生命周期探秘" class="headerlink" title="Servlet接口中有哪些方法及Servlet生命周期探秘"></a>Servlet接口中有哪些方法及Servlet生命周期探秘</h2><p>在Java Web程序中，Servlet主要负责接收用户请求HttpServletRequest，在 doGet()，doPost()中做相应的处理，并将回应HttpServletResponse反馈给用户。Servlet可以设置初始化参数，供Servlet内部使用。</p>
<p>Servlet接口定义了5个方法，其中前三个方法与Servlet生命周期相关：</p>
<ul>
<li>void init(ServletConfig config) throws ServletException </li>
<li>void service(ServletRequest req, ServletResponse resp) throws ServletException, java.io.IOException</li>
<li>void destory() </li>
<li>java.lang.String getServletInfo() </li>
<li>ServletConfig getServletConfig()</li>
</ul>
<p>生命周期：</p>
<p>Web容器加载Servlet并将其实例化后，Servlet生命周期开始，容器运行其 init()方法进行Servlet的初始化；</p>
<p>请求到达时调用Servlet的service()方法，service()方法会根据需要调用与请求</p>
<p>对应的doGet或doPost等方法；</p>
<p>当服务器关闭或项目被卸载时服务器会将Servlet实例销毁，此时会调用Servlet 的destroy()方法。</p>
<p>init方法和destory方法只会执行一次，service方法客户端每次请求Servlet都会执行。Servlet中有时会用到一些需要初始化与销毁的资源，因此可以把初始化资源的代码放入init方法中，销毁资源的代码放入destroy方法中，这样就不需要每次处理客户端的请求都要初始化与销毁资源。</p>
<h2 id="如果客户端禁止-cookie-能实现-session-还能用吗？"><a href="#如果客户端禁止-cookie-能实现-session-还能用吗？" class="headerlink" title="如果客户端禁止 cookie 能实现 session 还能用吗？"></a>如果客户端禁止 cookie 能实现 session 还能用吗？</h2><p>Cookie 与 Session，一般认为是两个独立的东西，Session采用的是在服务器端保持状态的方案，而Cookie采用的是在客户端保持状态的方案。</p>
<p>但为什么禁用Cookie就不能得到Session呢？因为Session是用Session ID来确定当前对话所对应的服务器Session，而Session ID是通过Cookie来传递的，禁用Cookie相当于失去了Session ID，也就得不到Session了。</p>
<p>假定用户关闭Cookie的情况下使用Session，其实现途径有以下几种：</p>
<ol>
<li><p>手动通过URL传值、隐藏表单传递Session ID。</p>
</li>
<li><p>用文件、数据库等形式保存Session ID，在跨页过程中手动调用。</p>
</li>
</ol>

      
    </div>

    
    
    

       
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/10/12/19-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9D%A2%E8%AF%95%E5%BF%85%E4%BC%9A%EF%BC%882020%E6%9C%80%E6%96%B0%E7%89%88%EF%BC%89/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="善善332">
      <meta itemprop="description" content="运气和努力一样重要">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="和善寺">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/10/12/19-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9D%A2%E8%AF%95%E5%BF%85%E4%BC%9A%EF%BC%882020%E6%9C%80%E6%96%B0%E7%89%88%EF%BC%89/" class="post-title-link" itemprop="url">未命名</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-10-12 15:01:16" itemprop="dateCreated datePublished" datetime="2022-10-12T15:01:16+08:00">2022-10-12</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-03-03 13:51:37" itemprop="dateModified" datetime="2021-03-03T13:51:37+08:00">2021-03-03</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="一-模型"><a href="#一-模型" class="headerlink" title="一. 模型"></a>一. 模型</h2><h3 id="1-节点"><a href="#1-节点" class="headerlink" title="1. 节点"></a>1. 节点</h3><p>在具体的工程项目中，一个节点往往是一个操作系统上的进程。在本文的模型中，认 为节点是一个完整的、不可分的整体，如果某个程序进程实际上由若干相对独立部分 构成，则在模型中可以将一个进程划分为多个节点。</p>
<h3 id="异常"><a href="#异常" class="headerlink" title="异常"></a>异常</h3><p><strong>机器宕机：</strong>机器宕机是最常见的异常之一。在大型集群中每日宕机发生的概 率为千分之一左右，在实践中，一台宕机的机器恢复的时间通常认为是24 小 时，一般需要人工介入重启机器。 </p>
<p><strong>网络异常：</strong>消息丢失，两片节点之间彼此完全无法通信，即出现了“网络分 化”；消息乱序，有一定的概率不是按照发送时的顺序依次到达目的节点，考 虑使用序列号等机制处理网络消息的乱序问题，使得无效的、过期的网络消息 不影响系统的正确性；数据错误；不可靠的TCP，TCP 协议为应用层提供了可 靠的、面向连接的传输服务，但在分布式系统的协议设计中不能认为所有网络 通信都基于TCP 协议则通信就是可靠的。TCP协议只能保证同一个TCP 链接内 的网络消息不乱序，TCP 链接之间的网络消息顺序则无法保证。 </p>
<p><strong>分布式三态：</strong>如果某个节点向另一个节点发起RPC(Remote procedure call) 调用，即某个节点A 向另一个节点B 发送一个消息，节点B 根据收到的消息内 容完成某些操作，并将操作的结果通过另一个消息返回给节点A，那么这个RPC  执行的结果有三种状态：“成功”、“失败”、“超时（未知）”，称之为分 布式系统的三态。 </p>
<p><strong>存储数据丢失：</strong>对于有状态节点来说，数据丢失意味着状态丢失，通常只能从 其他节点读取、恢复存储的状态。 </p>
<p><strong>异常处理原则：</strong>被大量工程实践所检验过的异常处理黄金原则是：任何在设 计阶段考虑到的异常情况一定会在系统实际运行中发生，但在系统实际运行遇 到的异常却很有可能在设计时未能考虑，所以，除非需求指标允许，在系统设 计时不能放过任何异常情况。</p>
<h2 id="副本"><a href="#副本" class="headerlink" title="副本"></a>副本</h2><p>副本（replica&#x2F;copy）指在分布式系统中为数据或服务提供的冗余。对于数据副本指 在不同的节点上持久化同一份数据，当出现某一个节点的存储的数据丢失时，可以从 副本上读到数据。数据副本是分布式系统解决数据丢失异常的唯一手段。另一类副本 是服务副本，指数个节点提供某种相同的服务，这种服务一般并不依赖于节点的本地 存储，其所需数据一般来自其他节点。</p>
<p>副本协议是贯穿整个分布式系统的理论核心。</p>
<p><strong>副本一致性</strong></p>
<p>分布式系统通过副本控制协议，使得从系统外部读取系统内部各个副本的数据在一定 的约束条件下相同，称之为副本一致性(consistency)。副本一致性是针对分布式系统 而言的，不是针对某一个副本而言。</p>
<ol>
<li>强一致性(strong consistency)：任何时刻任何用户或节点都可以读到最近 一次成功更新的副本数据。强一致性是程度最高的一致性要求，也是实践中最 难以实现的一致性。 </li>
<li>单调一致性(monotonic consistency)：任何时刻，任何用户一旦读到某个 数据在某次更新后的值，这个用户不会再读到比这个值更旧的值。单调一致性 是弱于强一致性却非常实用的一种一致性级别。因为通常来说，用户只关心从 己方视角观察到的一致性，而不会关注其他用户的一致性情况。 </li>
<li>会话一致性(session consistency)：任何用户在某一次会话内一旦读到某 个数据在某次更新后的值，这个用户在这次会话过程中不会再读到比这个值更 旧的值。会话一致性通过引入会话的概念，在单调一致性的基础上进一步放松 约束，会话一致性只保证单个用户单次会话内数据的单调修改，对于不同用户 间的一致性和同一用户不同会话间的一致性没有保障。实践中有许多机制正好 对应会话的概念，例如php 中的session 概念。 </li>
<li>最终一致性(eventual consistency)：最终一致性要求一旦更新成功，各个 副本上的数据最终将达 到完全一致的状态，但达到完全一致状态所需要的时间 不能保障。对于最终一致性系统而言，一个用户只要始终读取某一个副本的数<br>据，则可以实现类似单调一致性的效果，但一旦用户更换读取的副本，则无法 保障任何一致性。 </li>
<li>弱一致性(week consistency)：一旦某个更新成功，用户无法在一个确定 时间内读到这次更新的值，且即使在某个副本上读到了新的值，也不能保证在 其他副本上可以读到新的值。弱一致性系统一般很难在实际中使用，使用弱一 致性系统需要应用方做更多的工作从而使得系统可用。</li>
</ol>
<h2 id="3-衡量分布式系统的指标"><a href="#3-衡量分布式系统的指标" class="headerlink" title="3. 衡量分布式系统的指标"></a>3. 衡量分布式系统的指标</h2><p>性能：系统的吞吐能力，指系统在某一时间可以处理的数据总量，通常可以 用系统每秒处理的总的数据量来衡量；系统的响应延迟，指系统完成某一功能 需要使用的时间；系统的并发能力，指系统可以同时完成某一功能的能力，通 常也用QPS(query per second)来衡量。上述三个性能指标往往会相互制约， 追求高吞吐的系统，往往很难做到低延迟；系统平均响应时间较长时，也很难 提高QPS。 </p>
<p>可用性：系统的可用性(availability)指系统在面对各种异常时可以正确提供 服务的能力。系统的可用性可以用系统停服务的时间与正常服务的时间的比例 来衡量，也可以用某功能的失败次数与成功次数的比例来衡量。可用性是分布 式的重要指标，衡量了系统的鲁棒性，是系统容错能力的体现。 </p>
<p>可扩展性：系统的可扩展性(scalability)指分布式系统通过扩展集群机器规模 提高系统性能（吞吐、延迟、并发）、存储容量、计算能力的特性。好的分布 式系统总在追求“线性扩展性”，也就是使得系统的某一指标可以随着集群中 的机器数量线性增长。 </p>
<p>一致性：分布式系统为了提高可用性，总是不可避免的使用副本的机制，从 而引发副本一致性的问题。越是强的一致的性模型，对于用户使用来说使用起 来越简单。</p>
<h1 id="二-分布式系统原理"><a href="#二-分布式系统原理" class="headerlink" title="二. 分布式系统原理"></a>二. 分布式系统原理</h1><h2 id="4-数据分布方式"><a href="#4-数据分布方式" class="headerlink" title="4. 数据分布方式"></a>4. 数据分布方式</h2><p>所谓分布式系统顾名思义就是利用多台计算机协同解决单台计算机所不能解决的计 算、存储等问题。单机系统与分布式系统的最大的区别在于问题的规模，即计算、存<br>储的数据量的区别。将一个单机问题使用分布式解决，首先要解决的就是如何将问题 拆解为可以使用多机分布式解决，使得分布式系统中的每台机器负责原问题的一个子 集。由于无论是计算还是存储，其问题输入对象都是数据，所以如何拆解分布式系统 的输入数据成为分布式系统的基本问题。</p>
<h3 id="哈希方式"><a href="#哈希方式" class="headerlink" title="哈希方式"></a>哈希方式</h3><p><img src="F:\0马士兵\新建文件夹\BAT面试突击资料(1)\OUT\03-2020最新整理一线大厂面试题合集(重点看)\19-分布式面试必会（2020最新版）.assets/哈希方式.png" alt="哈希方式"></p>
<p>哈希分布数据的缺点同样明显，突出表现为可扩展性不高，一旦集群规模需要扩展， 则几乎所有的数据需要被迁移并重新分布。工程中，扩展哈希分布数据的系统时，往 往使得集群规模成倍扩展，按照数据重新计算哈希，这样原本一台机器上的数据只需 迁移一半到另一台对应的机器上即可完成扩展。</p>
<p>针对哈希方式扩展性差的问题，一种思路是不再简单的将哈希值与机器做除法取模映 射，而是将对应关系作为元数据由专门的元数据服务器管理.同时，哈希值取模个数往 往大于机器个数，这样同一台机器上需要负责多个哈希取模的余数。但需要以较复杂 的机制维护大量的元数据。哈希分布数据的另一个缺点是，一旦某数据特征值的数据 严重不均，容易出现“数据倾斜”（data skew）问题。</p>
<p>哈希分布数据的另一个缺点是，一旦某数据特征值的数据严重不均，容易出现“数据 倾斜”（data skew）问题</p>
<p><img src="F:\0马士兵\新建文件夹\BAT面试突击资料(1)\OUT\03-2020最新整理一线大厂面试题合集(重点看" alt="数据倾斜（data skew）">\19-分布式面试必会（2020最新版）.assets&#x2F;数据倾斜（data skew）.png)</p>
<h3 id="按数据范围分布"><a href="#按数据范围分布" class="headerlink" title="按数据范围分布"></a>按数据范围分布</h3><p>按数据范围分布是另一个常见的数据分布式，将数据按特征值的值域范围划分为不同 的区间，使得集群中每台（组）服务器处理不同区间的数据。</p>
<p><img src="F:\0马士兵\新建文件夹\BAT面试突击资料(1)\OUT\03-2020最新整理一线大厂面试题合集(重点看)\19-分布式面试必会（2020最新版）.assets/按数据范围分布.png" alt="按数据范围分布"></p>
<p>工程中，为了数据迁移等负载均衡操作的方便，往往利用动态划分区间的技术，使得 每个区间中服务的数据量尽量的一样多。当某个区间的数据量较大时，通过将区 间“分裂”的方式拆分为两个区间，使得每个数据区间中的数据量都尽量维持在一个 较为固定的阈值之下。</p>
<p>一般的，往往需要使用专门的服务器在内存中维护数据分布信息，称这种数据的分布 信息为一种元信息。甚至对于大规模的集群，由于元信息的规模非常庞大，单台 计算 机无法独立维护，需要使用多台机器作为元信息服务器。</p>
<h3 id="按数据量分布"><a href="#按数据量分布" class="headerlink" title="按数据量分布"></a>按数据量分布</h3><p>数据量分布数据与具体的数据特征无关，而是将数据视为一个顺序增长的文件，并将 这个文件按照某一较为固定的大小划分为若干数据块（chunk），不同的数据块分布到不同的服务器上。与按数据范围分布数据的方式类似的是，按数据量分布数据也需 要记录数据块的具体分布情况，并将该分布信息作为元数据使用元数据服务器管理。</p>
<p>由于与具体的数据内容无关，按数据量分布数据的方式一般没有数据倾斜的问题，数 据总是被均匀切分并分布到集群中。当集群需要重新负载均衡时，只需通过迁移数据 块即可完成。集群扩容也没有太大的限制，只需将部分数据库迁移到新加入的机器上 即可以完成扩容。按数据量划分数据的缺点是需要管理较为复杂的元信息，与按范围 分布数据的方式类似，当集群规模较大时，元信息的数据量也变得很大，高效的管理 元信息成为新的课题。</p>
<h3 id="一致性哈希"><a href="#一致性哈希" class="headerlink" title="一致性哈希"></a>一致性哈希</h3><p>一致性哈希（consistent hashing）是另一个种在工程中使用较为广泛的数据分布方 式。一致性哈希最初在P2P 网络中作为分布式哈希表（DHT）的常用数据分布算法。 一致性哈希的基本方式是使用一个哈希函数计算数据或数据特征的哈希值，令该哈希 函数的输出值域为一个封闭的环，即哈希函数输出的最大值是最小值的前序。将节点 随机分布到这个环上，每个节点负责处理从自己开始顺时针至下一个节点的全部哈希 值域上的数据。</p>
<p><img src="F:\0马士兵\新建文件夹\BAT面试突击资料(1)\OUT\03-2020最新整理一线大厂面试题合集(重点看)\19-分布式面试必会（2020最新版）.assets/一致性哈希.png" alt="一致性哈希"></p>
<p>使用一致性哈希的方式需要将节点在一致性哈希环上的位置作为元信息加以管理，这 点比直接使用哈希分布数据的方式要复杂。然而，节点的位置信息只于集群中的机器 规模相关，其元信息的量通常比按数据范围分布数据和按数据量分布数据的元信息量 要小很多。</p>
<p>为此一种常见的改进算法是引入虚节点（virtual node）的概念，系统初始时就创建 许多虚节点，虚节点的个数一般远大于未来集群中机器的个数，将虚节点均匀分布到一致性哈希值域环上，其功能与基本一致性哈希算法中的节点相同。为每个节点分配 若干虚节点。操作数据时，首先通过数据的哈希值在环上找到对应的虚节点，进而查 找元数据找到对应的真实节点。使用虚节点改进有多个优点。首先，一旦某个节点不 可用，该节点将使得多个虚节点不可用，从而使得多个相邻的真实节点负载失效节点 的压里。同理，一旦加入一个新节点，可以分配多个虚节点，从而使得新节点可以 负 载多个原有节点的压力，从全局看，较容易实现扩容时的负载均衡。</p>
<h3 id="副本与数据分布"><a href="#副本与数据分布" class="headerlink" title="副本与数据分布"></a>副本与数据分布</h3><p>分布式系统容错、提高可用性的基本手段就是使用副本。对于数据副本的分布方式主 要影响系统的可扩展性。一种基本的数据副本策略是以机器为单位，若干机器互为副 本，副本机器之间的数据完全相同。这种策略适用于上述各种数据分布方式。其优点 是非常简单，其缺点是恢复数据的效率不高、可扩展性也不高。</p>
<p>更合适的做法不是以机器作为副本单位，而是将数据拆为较合理的数据段，以数据段 为单位作为副本。实践中，常常使得每个数据段的大小尽量相等且控制在一定的大小 以内。数据段有很多不同的称谓，segment，fragment，chunk，partition 等等。 数据段的选择与数据分布方式直接相关。对于哈希分数据的方式，每个哈希分桶后的 余数可以作为一个数据段，为了控制数据段的大小，常常使得分桶个数大于集群规 模。一旦将数据分为数据段，则可以以数据段为单位管理副本，从而副本与机器不再 硬相关，每台机器都可以负责一定数据段的副本。</p>
<p><img src="F:\0马士兵\新建文件夹\BAT面试突击资料(1)\OUT\03-2020最新整理一线大厂面试题合集(重点看)\19-分布式面试必会（2020最新版）.assets/副本与数据分布.png" alt="副本与数据分布"></p>
<p>一旦副本分布与机器无关，数据丢失后的恢复效率将非常高。这是因为，一旦某台机 器的数据丢失，其上数据段的副本将分布在整个集群的所有机器中，而不是仅在几个 副本机器中，从而可以从整个集群同时拷贝恢复数据，而集群中每台数据源机器都可 以以非常低的资源做拷贝。作为恢复数据源的机器即使都限速1MB&#x2F;s，若有100 台机 器参与恢复，恢复速度也能达到100MB&#x2F;s。再者，副本分布与机器无关也利于集群容错。如果出现机器宕机，由于宕机机器上的副本分散于整个集群，其压力也自然分散 到整个集群。最后，副本分布与机器无关也利于集群扩展。理论上，设集群规模 为N  台机器，当加入一台新的机器时，只需从各台机器上迁移1&#x2F;N – 1&#x2F;N+1 比例的数据 段到新机器即实现了新的负载均衡。由于是从集群中各机器迁移数据，与数据恢复同 理，效率也较高。工程中，完全按照数据段建立副本会引起需要管理的元数据的开销 增大，副本维护的难度也相应增大。一种折中的做法是将某些数据段组成一个数据段 分组，按数据段分组为粒度进行副本管理。这样做可以将副本粒度控制在一个较为合 适的范围内。</p>
<h3 id="本地化计算"><a href="#本地化计算" class="headerlink" title="本地化计算"></a>本地化计算</h3><p>在分布式系统中，数据的分布方式也深深影响着计算的分布方式。在分布式系统中计 算节点和保存计算数据的存储节点可以在同一台物理机器上，也可以位于不同的物理 机器。如果计算节点和存储节点位于不同的物理机器则计算的数据需要通过网络传 输，此种方式的开销很大，甚至网络带宽会成为系统的总体瓶颈。另一种思路是，将 计算尽量调度到与存储节点在同一台物理机器上的计算节点上进行，这称之为本地化 计算。本地化计算是计算调度的一种重要优化，其体现了一种重要的分布式调度思 想：“移动数据不如移动计算”。</p>
<h3 id="数据分布方式的选择"><a href="#数据分布方式的选择" class="headerlink" title="数据分布方式的选择"></a>数据分布方式的选择</h3><p>在实际工程实践中，可以根据需求及实施复杂度合理选择数据分布方式。另外，数据 分布方式是可以灵活组合使用的，往往可以兼备各种方式的优点，收到较好的综合效 果。</p>
<p>例：数据倾斜问题，在按哈希分数据的基础上引入按数据量分布数据的方式，解决该 数据倾斜问题。按用户id 的哈希值分数据，当某个用户id 的数据量特别大时，该用 户的数据始终落在某一台机器上。此时，引入按数据量分布数据的方式，统计用户的 数据量，并按某一阈值将用户的数据切为多个均匀的数据段，将这些数据段分布到集 群中去。由于大部分用户的数据量不会超过阈值，所以元数据中仅仅保存超过阈值的 用户的数据段分布信息，从而可以控制元数据的规模。这种哈希分布数据方式与按数 据量分布数据方式组合使用的方案，在某真实系统中使用，取得了较好的效果。</p>
<h2 id="5-基本副本协议"><a href="#5-基本副本协议" class="headerlink" title="5. 基本副本协议"></a>5. 基本副本协议</h2><p>副本控制协议指按特定的协议流程控制副本数据的读写行为，使得副本满足一定的可 用性和一致性要求的分布式协议。副本控制协议要具有一定的对抗异常状态的容错能 力，从而使得系统具有一定的可用性，同时副本控制协议要能提供一定一致性级别。 由CAP 原理（在2.9 节详细分析）可知，要设计一种满足强一致性，且在出现任何网 络异常时都可用的副本协议是不可能的。为此，实际中的副本控制协议总是在可用 性、一致性与性能等各要素之间按照具体需求折中。</p>
<p>副本控制协议可以分为两大类：“中心化(centralized)副本控制协议”和“去中心化 (decentralized)副本控制协议”。</p>
<h3 id="中心化副本控制协议"><a href="#中心化副本控制协议" class="headerlink" title="中心化副本控制协议"></a>中心化副本控制协议</h3><p>中心化副本控制协议的基本思路是由一个中心节点协调副本数据的更新、维护副本之 间的一致性。图给出了中心化副本协议的通用架构。中心化副本控制协议的优点是协 议相对较为简单，所有的副本相关的控制交由中心节点完成。并发控制将由中心节点 完成，从而使得一个分布式并发控制问题，简化为一个单机并发控制问题。所谓并发 控制，即多个节点同时需要修改副本数据时，需要解决“写写”、“读写”等并发冲 突。单机系统上常用加锁等方式进行并发控制。对于分布式并发控制，加锁也是一个 常用的方法，但如果没有中心节点统一进行锁管理，就需要完全分布式化的锁系统， 会使得协议非常复杂。中心化副本控制协议的缺点是系统的可用性依赖于中心化节 点，当中心节点异常或与中心节点通信中断时，系统将失去某些服务（通常至少失去 更新服务），所以中心化副本控制协议的缺点正是存在一定的停服务时间。</p>
<p><img src="F:\0马士兵\新建文件夹\BAT面试突击资料(1)\OUT\03-2020最新整理一线大厂面试题合集(重点看)\19-分布式面试必会（2020最新版）.assets/中心化副本控制协议.png" alt="中心化副本控制协议"></p>
<h3 id="primary-secondary-协议"><a href="#primary-secondary-协议" class="headerlink" title="primary-secondary 协议"></a>primary-secondary 协议</h3><p>在primary-secondary 类型的协议中，副本被分为两大类，其中有且仅有一个副本作 为primary 副本，除primary 以外的副本都作为secondary 副本。维护primary 副本 的节点作为中心节点，中心节点负责维护数据的更新、并发控制、协调副本的一致 性。</p>
<p>Primary-secondary 类型的协议一般要解决四大类问题：数据更新流程、数据读取方 式、Primary 副本的确定和切换、数据同步（reconcile）。</p>
<p>数据更新基本流程 </p>
<ol>
<li>数据更新都由primary 节点协调完成。 </li>
<li>外部节点将更新操作发给primary 节点 </li>
<li>primary 节点进行并发控制即确定并发更新操作的先后顺序 </li>
<li>primary 节点将更新操作发送给secondary 节点 </li>
<li>primary 根据secondary 节点的完成情况决定更新是否成功并将结果返回外 部节点</li>
</ol>
<p><img src="F:\0马士兵\新建文件夹\BAT面试突击资料(1)\OUT\03-2020最新整理一线大厂面试题合集(重点看)\19-分布式面试必会（2020最新版）.assets/数据更新基本流程.png" alt="数据更新基本流程"></p>
<p>在工程实践中，如果由primary 直接同时发送给其他N 个副本发送数据，则每个  secondary 的更新吞吐受限于primary 总的出口网络带宽，最大为primary 网络出口 带宽的1&#x2F;N。为了解决这个问题，有些系统（例如，GFS），使用接力的方式同步数 据，即primary 将更新发送给第一 个secondary 副本，第一个secondary 副本发送 给第二secondary 副本，依次类推。</p>
<h3 id="数据读取方式"><a href="#数据读取方式" class="headerlink" title="数据读取方式"></a>数据读取方式</h3><p>数据读取方式也与一致性高度相关。如果只需要最终一致性，则读取任何副本都可以 满足需求。如果需要会话一致性，则可以为副本设置版本号，每次更新后递增版本 号，用户读取副本时验证版本号，从而保证用户读到的数据在会话范围内单调递增。 使用primary-secondary 比较困难的是实现强一致性。</p>
<ol>
<li>由于数据的更新流程都是由primary 控制的，primary 副本上的数据一定是 最新的，所以 如果始终只读primary 副本的数据，可以实现强一致性。如果只 读primary 副本，则secondary 副本将不提供读服务。实践中，如果副本不与 机器绑定，而是按照数据段为单位维护副本，仅有primary 副本提供读服务在 很多场景下并不会造出机器资源浪费。</li>
</ol>
<p>将副本分散到集群中个，假设primary 也是随机的确定的，那么每台机器上都有一些 数据的primary 副本，也有另一些数据段的secondary 副本。从而某台服务器实际都 提供读写服务。</p>
<ol>
<li>由primary 控制节点secondary 节点的可用性。当primary 更新某个 secondary 副本不成功时，primary 将该secondary 副本标记为不可用，从而 用户不再读取该不可用的副本。不可用的 secondary 副本可以继续尝试与 primary 同步数据，当与primary 完成数据同步后，primary 可以副本标记为 可用。这种方式使得所有的可用的副本，无论是primary 还是secondary 都是 可读的，且在一个确定的时间内，某secondary 副本要么更新到与primary 一 致的最新状态，要么被标记为不可用，从而符合较高的一致性要求。这种方式 依赖于一个中心元数据管理系统，用于记录哪些副本可用，哪些副本不可用。 某种意义上，该方式通过降低系统的可用性来提高系统的一致性。</li>
</ol>
<h3 id="primary-副本的确定与切换"><a href="#primary-副本的确定与切换" class="headerlink" title="primary 副本的确定与切换"></a>primary 副本的确定与切换</h3><p>在primary-secondary 类型的协议中，另一个核心的问题是如何确定primary 副本， 尤其是在原primary 副本所在机器出现宕机等异常时，需要有某种机制切换primary  副本，使得某个secondary 副本成为新的primary 副本。</p>
<p>通常的，在primary-secondary 类型的分布式系统中，哪个副本是primary 这一信息 都属于元信息，由专门的元数据服务器维护。执行更新操作时，首先查询元数据服务 器获取副本的primary 信息，从而进一步执行数据更新流程。</p>
<p>由于分布式系统中可靠的发现节点异常是需要一定的探测时间的，这样的探测时间通 常是10 秒级别，这也意味着一旦primary 异常，最多需要10 秒级别的发现时间，系统才能开始primary 的切换，在这10 秒时间内，由于没有primary，系统不能提供更  新服务，如果系统只能读primary 副本，则这段时间内甚至不能提供读服务。从这里 可以看到，primary-backup 类副本协议的最大缺点就是由于primary 切换带来的一 定的停服务时间。</p>
<h3 id="数据同步"><a href="#数据同步" class="headerlink" title="数据同步"></a>数据同步</h3><p>不一致的secondary 副本需要与primary 进行同步（reconcile）。</p>
<p>通常不一致的形式有三种：一、由于网络分化等异常，secondary 上的数据落后于 primary 上的数据。二、在某些协议下，secondary 上的数据有可能是脏数据，需要 被丢弃。所谓脏数据是由于primary 副本没有进行某一更新操作，而secondary 副本 上反而进行的多余的修改操作，从而造成secondary 副本数据错误。三、secondary  是一个新增加的副本，完全没有数据，需要从其他副本上拷贝数据。</p>
<p>对于第一种secondary 数据落后的情况，常见的同步方式是回放primary 上的操作日 志（通常是redo 日志），从而追上primary 的更新进度。对于脏数据的情况，较好 的做法是设计的分布式协议不产生脏数据。如果协议一定有产生脏数据的可能，则也 应该使得产生脏数据的概率降到非常低得情况，从而一旦发生脏数据的情况可以简单 的直接丢弃有脏数据的副本，这样相当于副本没有数据。另外，也可以设计一些基于 undo 日志的方式从而可以删除脏数据。如果secondary 副本完全没有数据，则常见 的做法是直接拷贝primary 副本的数据，这种方法往往比回放日志追更新进度的方法 快很多。但拷贝数据时primary 副本需要能够继续提供更新服务，这就要求primary  副本支持快照(snapshot)功能。即对某一刻的副本数据形成快照，然后拷贝快照，拷 贝完成后使用回放日志的方式追快照形成后的更新操作。</p>
<h3 id="去中心化副本控制协议"><a href="#去中心化副本控制协议" class="headerlink" title="去中心化副本控制协议"></a>去中心化副本控制协议</h3><p>去中心化副本控制协议没有中心节点，协议中所有的节点都是完全对等的，节点之间 通过平等协商达到一致。从而去中心化协议没有因为中心化节点异常而带来的停服务 等问题。 去中心化协议的最大的缺点是协议过程通常比较复杂。尤其当去中心化协议需要实现 强一致性时，协议流程变得复杂且不容易理解。由于流程的复杂，去中心化协议的效<br>率或者性能一般也较中心化协议低。一个不恰当的比方就是，中心化副本控制协议类 似专制制度，系统效率高但高度依赖于中心节点，一旦中心节点异常，系统受到的影 响较大；去中心化副本控制协议类似民主制度，节点集体协商，效率低下，但个别节 点的异常不会对系统总体造成太大影响。</p>
<p><img src="F:\0马士兵\新建文件夹\BAT面试突击资料(1)\OUT\03-2020最新整理一线大厂面试题合集(重点看)\19-分布式面试必会（2020最新版）.assets/去中心化副本控制协议.png" alt="去中心化副本控制协议"></p>
<h2 id="6-Lease-机制"><a href="#6-Lease-机制" class="headerlink" title="6. Lease 机制"></a>6. Lease 机制</h2><p>Lease 机制是最重要的分布式协议，广泛应用于各种实际的分布式系统中。</p>
<h3 id="基于lease-的分布式cache-系统"><a href="#基于lease-的分布式cache-系统" class="headerlink" title="基于lease 的分布式cache 系统"></a>基于lease 的分布式cache 系统</h3><p>基本的问题背景如下：在一个分布式系统中，有一个中心服务器节点，中心服务器存 储、维护着一些数据，这些数据是系统的元数据。系统中其他的节点通过访问中心服 务器节点读取、修改其上的元数据。由于系统中各种操作都依赖于元数据，如果每次 读取元数据的操作都访问中心服务器 节点，那么中心服务器节点的性能成为系统的瓶 颈。为此，设计一种元数据cache，在各个节点上 cache 元数据信息，从而减少对中 心服务器节点的访问，提高性能。另一方面，系统的正确运行严格依赖于元数据的正 确，这就要求各个节点上cache 的数据始终与中心服务器上的数据一致，cache 中的 数据不能是旧的脏数据。最后，设计的cache 系统要能最大可能的处理节点宕机、网 络中断等异常，最大程度的提高系统的可用性。</p>
<p>为此，利用lease 机制设计一套cache 系统，其基本原理为如下。中心服务器在向各 节点发送数据时同时向节点颁发一个lease。每个lease 具有一个有效期，和信用卡上 的有效期类似，lease 上的 有效期通常是一个明确的时间点，例如12:00:10，一旦真 实时间超过这个时间点，则lease 过期失效。这样lease 的有效期与节点收到lease 的 时间无关，节点可能收到lease 时该lease 就已经过期失效。这里首先假设中心服务 器与各节点的时钟是同步的，在下节中讨论时钟不同步对lease 的影响。中心服务器 发出的lease 的含义为：在lease 的有效期内，中心服务器保证不会修改对应数据的值。因此，节点收到数据和lease 后，将数据加入本地Cache，一旦对应的lease 超 时，节点将对应的本地cache 数据删除。中心服务器在修改数据时，首先阻塞所有新 的读请求，并等待之前为该数据发出的所有lease 超时过期，然后修改数据的值。<br>基于lease 的cache，客户端节点读取元数据</p>
<ol>
<li>判断元数据是否已经处于本地cache 且lease 处于有效期内1.1 是：直接返回 cache 中的元数据1.2 否：向中心服务器节点请求读取元数据信息1.2.1 服务器 收到读取请求后，返回元数据及一个对应的lease 1.2.2 客户端是否成功收到服 务器返回的数据   1.2.2.1 失败或超时：退出流程，读取失败，可重试1.2.2.2 成 功：将元数据与该元数据的lease 记录到内存中，返回元数据 </li>
<li>基于lease 的cache，客户端节点修改元数据流程2.1 节点向服务器发起修改 元数据请求。2.2 服务器收到修改请求后，阻塞所有新的读数据请求，即接收读 请求，但不返回数据。2.3 服务器等待所有与该元数据相关的lease 超时。2.4  服务器修改元数据并向客户端节点返回修改成功。</li>
</ol>
<p>上述机制可以保证各个节点上的cache 与中心服务器上的中心始终一致。这是因为中 心服务器节点在发送数据的同时授予了节点对应的lease，在lease 有效期内，服务器 不会修改数据，从而客户端节点可以放心的在lease 有效期内cache 数据。上述lease  机制可以容错的关键是：服务器一旦 发出数据及lease，无论客户端是否收到，也无 论后续客户端是否宕机，也无论后续网络是否正常，服务器只要等待lease 超时，就 可以保证对应的客户端节点不会再继续cache 数据，从而可以放心的修改数据而不会 破坏cache 的一致性。</p>
<p>上述基础流程有一些性能和可用性上的问题，但可以很容易就优化改性。优化点一： 服务器在修改元数据时首先要阻塞所有新的读请求，造成没有读服务。这是为了防止 发出新的lease 从而引起不断有新客户端节点持有lease 并缓存着数据，形成“活 锁”。优化的方法很简单，服务器在进入修改数据流程后，一旦收到读请求则只返回 数据但不颁发lease。从而造成在修改流程执行的过程中，客户端可以读到元数据， 只是不能缓存元数据。进一步的优化是，当进入修改流程，服务器颁发的lease 有效 期限选择为已发出的lease 的最大有效期限。这样做，客户端可以继续在服务器进入 修改流程后继续缓存元数据，但服务器的等待所有lease 过期的时间也不会因为颁发 新的lease 而不断延长。</p>
<p>最后，&#x3D;cache 机制与多副本机制的区别。Cache 机制与多副本机制的相似之处都 是 将一份数据保存在多个节点上。但Cache 机制却要简单许多，对于cache 的数据，可 以随时删除丢弃，并命中cache 的后果仅仅是需要访问数据源读取数据；然而副本机 制却不一样，副本是不能随意丢弃的，每失去一个副本，服务质量都在下降，一旦副 本数下降到一定程度，则往往服务将不再可用。</p>
<h3 id="lease-机制的分析"><a href="#lease-机制的分析" class="headerlink" title="lease 机制的分析"></a>lease 机制的分析</h3><p>lease 的定义：Lease 是由颁发者授予的在某一有效期内的承诺。颁发者一旦发出 lease，则无论接受方是否收到，也无论后续接收方处于何种状态，只要lease 不过 期，颁发者一定严守承诺；另一方面，接收方在lease 的有效期内可以使用颁发者的 承诺，但一旦lease 过期，接收方一定不能继续使用颁发者的承诺。</p>
<p>Lease 机制具有很高的容错能力。首先，通过引入有效期，Lease 机制能否非常好的 容错网络异常。Lease 颁发过程只依赖于网络可以单向通信，即使接收方无法向颁发 者发送消息，也不影响lease 的颁发。由于lease 的有效期是一个确定的时间点， lease 的语义与发送lease 的具体时间无关，所以 同一个lease 可以被颁发者不断重 复向接受方发送。即使颁发者偶尔发送lease 失败，颁发者也可以 简单的通过重发的 办法解决。一旦lease 被接收方成功接受，后续lease 机制不再依赖于网络通信，即 使网络完全中断lease 机制也不受影响。再者，Lease 机制能较好的容错节点宕机。 如果颁发者宕机，则宕机的颁发者通常无法改变之前的承诺，不会影响lease 的正确 性。在颁发者机恢复后，如果颁发者恢复出了之前的lease 信息，颁发者可以继续遵 守lease 的承诺。如果颁发者无法恢复lease 信息，则只需等待一个最大的lease 超时 时间就可以使得所有的lease 都失效，从而不破坏lease机制。</p>
<p>例如上节中的cache 系统的例子中，一旦服务器宕机，肯定不会修改元数据，重新恢 复后，只需等待一个最大的lease 超时时间，所有节点上的缓存信息都将被清空。对 于接受方宕机的情况，颁发者 不需要做更多的容错处理，只需等待lease 过期失效， 就可以收回承诺，实践中也就是收回之前赋予的权限、身份等。最后，lease 机制不 依赖于存储。颁发者可以持久化颁发过的lease 信息，从而在 宕机恢复后可以使得在 有效期的lease 继续有效。但这对于lease 机制只是一个优化，如之前的分析，即使颁发者没有持久化lease 信息，也可以通过等待一个最大的lease 时间的方式使得之 前所有颁发 的lease 失效，从而保证机制继续有效。</p>
<p>Lease 机制依赖于有效期，这就要求颁发者和接收者的时钟是同步的。一方面，如果 颁发者的 时钟比接收者的时钟慢，则当接收者认为lease 已经过期的时候，颁发者依 旧认为lease 有效。接收者可以用在lease 到期前申请新的lease 的方式解决这个问 题。另一方面，如果颁发者的时钟比接收 者的时钟快，则当颁发者认为lease 已经过 期的时候，接收者依旧认为lease 有效，颁发者可能将lease 颁发给其他节点，造成 承诺失效，影响系统的正确性。对于这种时钟不同步，实践中的通常做法是将颁发者 的有效期设置得比接收者的略大，只需大过时钟误差就可以避免对lease 的有效性的 影响。</p>
<h3 id="基于lease-机制确定节点状态"><a href="#基于lease-机制确定节点状态" class="headerlink" title="基于lease 机制确定节点状态"></a>基于lease 机制确定节点状态</h3><p>分布式协议依赖于对节点状态认知的全局一致性，即一旦节点Q 认为某个节点 A 异 常，则节点A 也必须认为自己异常，从而节点A 停止作为primary，避免“双主”问 题的出现。解决这种问题有两种思路，第一、设计的分布式协议可以容忍“双主”错 误，即不依赖于对节点状 态的全局一致性认识，或者全局一致性状态是全体协商后的 结果；第二、利用lease 机制。对于第一 种思路即放弃使用中心化的设计，而改用去 中心化设计，超过本节的讨论范畴。下面着重讨论利用 lease 机制确定节点状态。</p>
<p>由中心节点向其他节点发送lease，若某个节点持有有效的lease，则认为该节点正常 可以提供服 务。用于例2.3.1 中，节点A、B、C 依然周期性的发送heart beat 报告自 身状态，节点Q 收到heart beat 后发送一个lease，表示节点Q 确认了节点A、B、C  的状态，并允许节点在lease 有效期内正常工 作。节点Q 可以给primary 节点一个特 殊的lease，表示节点可以作为primary 工作。一旦节点Q 希望切换新的primary，则 只需等前一个primary 的lease 过期，则就可以安全的颁发新的lease 给新的 primary 节点，而不会出现“双主”问题。</p>
<p>在实际系统中，若用一个中心节点发送lease 也有很大的风险，一旦该中心节点宕机 或网络异常，则所有的节点没有lease，从而造成系统高度不可用。为此，实际系统 总是使用多个中心节点互为副本，成为一个小的集群，该小集群具有高可用性，对外 提供颁发lease 的功能。chubby 和zookeeper 都是基于这样的设计。</p>
<h3 id="lease-的有效期时间选择"><a href="#lease-的有效期时间选择" class="headerlink" title="lease 的有效期时间选择"></a>lease 的有效期时间选择</h3><p>工程中，常选择的lease 时长是10 秒级别，这是一个经过验证的经验值，实践中可以 作为参考并综合选择合适的时长。</p>
<h2 id="7-Quorum-机制"><a href="#7-Quorum-机制" class="headerlink" title="7. Quorum 机制"></a>7. Quorum 机制</h2><p>先做这样的约定：更新操作（write）是一系列顺序的过程，通过其他机制确定更新操 作的顺序（例如primary-secondary 架构中由primary 决定顺序），每个更新操作记 为wi， i 为更新操作单调递增的序号，每个wi 执行成功后副本数据都发生变化，称为 不同的数据版本，记 作vi。假设每个副本都保存了历史上所有版本的数据。</p>
<h3 id="write-all-read-one"><a href="#write-all-read-one" class="headerlink" title="write-all-read-one"></a>write-all-read-one</h3><p>Write-all-read-one（简称WARO）是一种最简单的副本控制规则，顾名思义即在更 新时写所有的副本，只有在所有的副本上更新成功，才认为更新成功，从而保证所有 的副本一致，这样在读取数据时可以读任一副本上的数据。</p>
<p>由于更新操作需要在所有的N 个副本上都成功，更新操作才能成 功，所以一旦有一 个副本异常，更新操作失败，更新服务不可用。对于更新服务，虽然有N 个副本，  但系统无法容忍任何一个副本异常。另一方面，N 个副本中只要有一个副本正常，系 统就可以提供读服务。对于读服务而言，当有N 个副本时，系统可以容忍N-1 个副本 异常。从上述分析可以发现WARO 读服务的可用性较高，但更新服务的可用性不 高，甚至虽然使用了副本，但更新服务的可用性等效于没有副本。</p>
<h3 id="Quorum-定义"><a href="#Quorum-定义" class="headerlink" title="Quorum 定义"></a>Quorum 定义</h3><p>在Quorum 机制下，当某次更新操作wi 一旦在所有N 个副本中的W 个副本上都成 功，则就称 该更新操作为“成功提交的更新操作”，称对应的数据为“成功提交的数 据”。令R&gt;N-W，由于更新 操作wi 仅在W 个副本上成功，所以在读取数据时，最 多需要读取R 个副本则一定能读到wi 更新后 的数据vi 。如果某次更新wi 在W 个副本 上成功，由于W+R&gt;N，任意R 个副本组成的集合一定与 成功的W个副本组成的集合有交集，所以读取R 个副本一定能读到wi 更新后的数据vi。如图 2-10， Quorum 机 制的原理可以文森图表示。</p>
<p><img src="F:\0马士兵\新建文件夹\BAT面试突击资料(1)\OUT\03-2020最新整理一线大厂面试题合集(重点看" alt="Quorum 定义">\19-分布式面试必会（2020最新版）.assets&#x2F;Quorum 定义.png)</p>
<p>某系统有5 个副本，W&#x3D;3，R&#x3D;3，最初5 个副本的数据一致，都是v1，某次更新操作  w2 在前3 副本上成功，副本情况变成（v2 v2 v2 v1 v1）。此时，任意3 个副本组成 的集合中一定包括 v2。在上述定义中，令W&#x3D;N，R&#x3D;1，就得到WARO，即WARO  是Quorum 机制的一种特例。与分析WARO 相似，分析Quorum 机制的可用性。限 制Quorum 参数为W+R&#x3D;N+1。由于更新 操作需要在W 个副本上都成功，更新操作 才能成功，所以一旦N-W+1 个副本异常，更新操作始终无法在W 个副本上成功，更 新服务不可用。另一方面，一旦N-R+1 个副本异常，则无法保证一定可以读到与W  个副本有交集的副本集合，则读服务的一致性下降。</p>
<p>再次强调：仅仅依赖quorum 机制是无法保证强一致性的。因为仅有quorum 机制时 无法确定最新已成功提交的版本号，除非将最新已提交的版本号作为元数据由特定的 元数据服务器或元数据集群管理，否则很难确定最新成功提交的版本号。在下一节 中，将讨论在哪些情况下，可以仅仅 通过quorum 机制来确定最新成功提交的版本号。</p>
<p>Quorum 机制的三个系统参数N、W、R 控制了系统的可用性，也是系统对用户的服 务承诺：数据最多有N 个副本，但数据更新成功W 个副本即返回用户成功。对于一 致性要求较高的Quorum 系统，系统还应该承诺任何时候不读取未成功提交的数据， 即读取到的数据都是曾经在W 个副本上成功的数据。</p>
<h3 id="读取最新成功提交的数据"><a href="#读取最新成功提交的数据" class="headerlink" title="读取最新成功提交的数据"></a>读取最新成功提交的数据</h3><p>Quorum 机制只需成功更新N 个副本中的W 个，在读取R 个副本时，一定可以读到 最新的成功提交的数据。但由于有不成功的更新情况存在，仅仅读取R 个副本却不一 定能确定哪个版本的数据 是最新的已提交的数据。对于一个强一致性Quorum 系 统，若存在个数据少于W 个，假设为X 个，则继续读取其他副本，直若成功读取到W  个 该版本的副本，则该数据为最新的成功提交的数据；如果在所有副本中该数据的个数肯定不满 足W 个，则R 中版本号第二大的为最新的成功提交的副本。例：在读取 到（v2 v1 v1）时，继续读取剩余的副本，若读到剩余两个副本 为（v2 v2）则v2 是 最新的已提交的副本；若读到剩余的两个副本为（v2 v1）或（v1 v1）则v1 是最新 成功提交的版本；若读取后续两个副本有任一超时或失败，则无法判断哪个版本是最 新的成功提交的版本。</p>
<p>可以看出，在单纯使用Quorum 机制时，若要确定最新的成功提交的版本，最多需要 读取R+ （W-R-1）&#x3D;N 个副本，当出现任一副本异常时，读最新的成功提交的版本 这一功能都有可能不可用。实际工程中，应该尽量通过其他技术手段，回避通过 Quorum 机制读取最新的成功提交的版本。例如，当quorum 机制与primarysecondary 控制协议结合使用时，可以通过读取primary 的方式读取到最新的已提交 的数据。</p>
<h3 id="基于Quorum-机制选择primary副本"><a href="#基于Quorum-机制选择primary副本" class="headerlink" title="基于Quorum 机制选择primary副本"></a>基于Quorum 机制选择primary副本</h3><p>读取数据时依照一致性要求的不同可以有不同的做法：如果需要强一致性的立刻读取 到最新的成功提交的数据，则可以简单的只读取primary 副本上的数据即可，也可以 通过上节的方式读取；如果需要会话一致性，则可以根据之前已经读到的数据版本号 在各个副本上进行选择性读取；如果只需要弱一致性，则可以选择任意副本读取。</p>
<p>在primary-secondary 协议中，当primary 异常时，需要选择出一个新的primary， 之后secondary 副本与primary 同步数据。通常情况下，选择新的primary 的工作是 由某一中心节点完成的，在引入 quorum 机制后，常用的primary 选择方式与读取 数据的方式类似，即中心节点读取R 个副本，选择 R 个副本中版本号最高的副本作为 新的primary。新primary 与至少W 个副本完成数据同步后作为新的primary 提供读 写服务。首先，R 个副本中版本号最高的副本一定蕴含了最新的成功提交的数据。再 者，虽然不能确定最高版本号的数是一个成功提交的数据，但新的primary 在随后与 secondary 同 步数据，使得该版本的副本个数达到W，从而使得该版本的数据成为 成功提交的数据。</p>
<p>例：在N&#x3D;5，W&#x3D;3，R&#x3D;3 的系统中，某时刻副本最大版本号为（v2 v2 v1 v1  v1），此时v1 是系统的最新的成功提交的数据，v2 是一个处于中间状态的未成功提交的数据。假设此刻原primary 副本异常，中心节点进行primary 切换工作。这 类“中间态”数据究竟作为“脏数据”被删除，还是作为新的数据被同步后成为生效 的数据，完全取决于这个数据能否参与新primary 的选举。下面分别分析这两种情 况。</p>
<p><img src="F:\0马士兵\新建文件夹\BAT面试突击资料(1)\OUT\03-2020最新整理一线大厂面试题合集(重点看" alt="基于Quorum 机制选择primary副本1">\19-分布式面试必会（2020最新版）.assets&#x2F;基于Quorum 机制选择primary副本1.png)</p>
<p>第一、如图 2-12，若中心节点与其中3 个副本通信成功，读取到的版本号为（v1 v1  v1），则任 选一个副本作为primary，新primary 以v1 作为最新的成功提交的版本 并与其他副本同步，当与第1、第2 个副本同步数据时，由于第1、第2 个副本版本号 大于primary，属于脏数据，可以按照2.2.2.4 节中介绍的处理脏数据的方式解决。实 践中，新primary 也有可能与后两个副本完成同步后就提供数据服务，随后自身版本 号也更新到v2，如果系统不能保证之后的v2 与之前的v2 完全一样，则新 primary 在 与第1、2 个副本同步数据时不但要比较数据版本号还需要比较更新操作的具体内容 是否一样。</p>
<p><img src="F:\0马士兵\新建文件夹\BAT面试突击资料(1)\OUT\03-2020最新整理一线大厂面试题合集(重点看" alt="基于Quorum 机制选择primary副本2">\19-分布式面试必会（2020最新版）.assets&#x2F;基于Quorum 机制选择primary副本2.png)</p>
<p>第二、若中心节点与其他3 个副本通信成功，读取到的版本号为（v2 v1 v1），则选 取版本号为 v2 的副本作为新的primary，之后，一旦新primary 与其他2 个副本完成 数据同步，则符合v2 的副 本个数达到W 个，成为最新的成功提交的副本，新 primary 可以提供正常的读写服务。</p>
<h2 id="8-日志技术"><a href="#8-日志技术" class="headerlink" title="8. 日志技术"></a>8. 日志技术</h2><p>日志技术是宕机恢复的主要技术之一。日志技术最初使用在数据库系统中。严格来说 日志技术不是一种分布式系统的技术，但在分布式系统的实践中，却广泛使用了日志 技术做宕机恢复，甚 至如BigTable 等系统将日志保存到一个分布式系统中进一步增 强了系统容错能力。</p>
<h3 id="Redo-Log-与Check-point"><a href="#Redo-Log-与Check-point" class="headerlink" title="Redo Log 与Check point"></a>Redo Log 与Check point</h3><p>设计一个高速的单机查询系统，将数据全部存放在内存中以实现高速的数据查询，每 次更新操作更新一小部分数据（例如 key-value 中的某一个key）。现在问题为利用 日志技术实现该内存查询系统的宕机恢复。与数据库的事务不同的是，这个问题模型 中的每个成功的更新操作都会生效。这也等效为数据库的每个事务只有一个更新操 作，且每次更新操作都可以也必须立即提交（Auto commit）。</p>
<ul>
<li>Redo Log</li>
</ul>
<ol>
<li>将更新操作的结果（例如Set K1&#x3D;1，则记录K1&#x3D;1）以追加写（append）的 方式写入磁盘的 日志文件 </li>
<li>按更新操作修改内存中的数据 </li>
<li>返回更新成功</li>
</ol>
<p>从Redo Log 的流程可以看出，Redo 写入日志的是更新操作完成后的结果（虽然本 文不讨论Undo Log，这点是与Undo Log 的区别之一），且由于是顺序追加写日志 文件，在磁盘等对顺序写有力的 存储设备上效率较高。</p>
<p>用Redo Log 进行宕机恢复非常简单，只需要“回放”日志即可。</p>
<p>流程2.5.2：Redo Log 的宕机恢复</p>
<p>从头读取日志文件中的每次更新操作的结果，用这些结果修改内存中的数 据。<br>从Redo Log 的宕机恢复流程也可以看出，只有写入日志文件的更新结果才能在宕机 后恢复。这也是为什么在Redo Log 流程中需要先更新日志文件再更新内存中的数据 的原因。假如先更新内存中的数据，那么用户立刻就能读到更新后的数据，一旦在完 成内存修改与写入日志之间发生宕机，那么最后一次更新操作无法恢复，但之前用户 可能已经读取到了更新后的数据，从而引起不一致的问题。</p>
<ul>
<li>Check point</li>
</ul>
<p>。在简化的模型下，check point 技术的过程即将内存中的数据以某种易于重新加载 的数据组织方式完整的dump 到磁盘，从而减少宕机恢复时需要回放的日志数据。</p>
<p>流程：check point</p>
<ol>
<li>向日志文件中记录“Begin Check Point” </li>
<li>将内存中的数据以某种易于重新加载的数据组织方式dump 到磁盘上 </li>
<li>向日志文件中记录“End Check Point” 在check point 流程中，数据可以 继续按照流程2.5.1 被更新，这段过程中新更新的数据可以dump 到磁盘也可以 不dump 到磁盘，具体取决于实现。例如，check point 开始时k1&#x3D;v1，check  point 过程 中某次更新为k1 &#x3D; v2，那么dump 到磁盘上的k1 的值可以是v1 也 可以是v2。</li>
</ol>
<p>流程：基于check point 的宕机恢复流程</p>
<ol>
<li>将dump 到磁盘的数据加载到内存。 </li>
<li>从后向前扫描日志文件，寻找最后一个“End Check Point”日志。 </li>
<li>从最后一个“End Check Point”日志向前找到最近的一个“Begin Check  Point”日志，并回 放该日志之后的所有更新操作日志。</li>
</ol>
<ul>
<li>No Undo&#x2F;No Redo log</li>
</ul>
<p>若数据维护在磁盘中，某批更新由若干个更新操作组成，这些更新操作需要原子生 效，即要么同时生效，要么都不生效。</p>
<p><img src="F:\0马士兵\新建文件夹\BAT面试突击资料(1)\OUT\03-2020最新整理一线大厂面试题合集(重点看" alt="Redo Log 与Check point">\19-分布式面试必会（2020最新版）.assets&#x2F;Redo Log 与Check point.png)</p>
<p>0&#x2F;1 目录技术中有两个目录结构，称为目录0(Directory 0)和目录1(Directory 1)。另 有一个结构称为主记录（Master record）记录当前正在使用的目录称为活动目录。 主记录中要么记录使用目录0，要么记录使用目录1。目录0 或目录1 中记录了各个数 据的在日志文件中的位置。0&#x2F;1 目录的数据更新过程始终在非活动目录上进行，只是 在数据生效前，将主记录中的0、1 值反转，从而切换主记录。</p>
<p>流程：0&#x2F;1 目录数据更新流程</p>
<ol>
<li>将活动目录完整拷贝到非活动目录。 </li>
<li>对于每个更新操作，新建一个日志项纪录操作后的值，并在非活动目录中将 相应数据的位置修改为新建的日志项的位置。 </li>
<li>原子性修改主记录：反转主记录中的值，使得非活动目录生效。</li>
</ol>
<p>0&#x2F;1 目录的更新流程非常简单，通过0、1 目录的主记录切换使得一批修改的生效是原 子的。0&#x2F;1 目录将批量事务操作的原子性通过目录手段归结到主记录的原子切换。由 于多条记录的原子修改一般较难实现而单条记录的原子修改往往可以实现，从而降低 了问题实现的难度。在工程中0&#x2F;1 目录的思想运用非常广泛，其形式也不局限在上述 流程中，可以是内存中的两个数据结构来回切换，也可以是磁盘上的两个文件目录来 回生效切换。</p>
<h2 id="9-两阶段提交协议"><a href="#9-两阶段提交协议" class="headerlink" title="9. 两阶段提交协议"></a>9. 两阶段提交协议</h2><p>两阶段提交协议是一种经典的强一致性中心化副本控制协议。虽然在工程中该协议有 较多的问题，但研究该协议能很好的理解分布式系统的几个典型问题。</p>
<h3 id="流程描述"><a href="#流程描述" class="headerlink" title="流程描述"></a>流程描述</h3><p>两阶段提交协议是一种典型的“中心化副本控制”协议。在该协议中，参与的节点分 为 两 类 ： 一 个 中 心 化 协 调 者 节 点 （ coordinator ） 和 N  个 参 与 者 节 点 （participant）。每个参与者节点即上文背景介绍中的管理数据库副本的节点。</p>
<p>两阶段提交的思路比较简单，在第一阶段，协调者询问所有的参与者是否可以提交事 务（请参与者投票），所有参与者向协调者投票。在第二阶段，协调者根据所有参与 者的投票结果做出是否事务可以全局提交的决定，并通知所有的参与者执行该决定。 在一个两阶段提交流程中，参与者不能改变自己的投票结果。两阶段提交协议的可以 全局提交的前提是所有的参与者都同意提交事务，只要有一个参与者投票选择放弃 (abort)事务，则事务必须被放弃。</p>
<p>流程：两阶段提交协调者流程</p>
<ol>
<li>写本地日志“begin_commit”，并进入WAIT 状态； </li>
<li>向所有参与者发送“prepare 消息”； </li>
<li>等待并接收参与者发送的对“prepare 消息”的响应；3.1 若收到任何一个 参与者发送的“vote-abort 消息”；3.1.1 写本地“global-abort”日志，进 入ABORT；3.1.2 向所有的参与者发送“global-abort 消息”；3.1.3 进入 ABORT 状态；3.2 若收到所有参与者发送的“vote-commit”消息；3.2.1 写 本地“global-commit”日志，进入COMMIT 状态；3.1.2 向所有的参与者发 送“global-commit 消息”； 4. 等待并接收参与者发送的对“global-abort 消息”或“global-commit 消 息”的确认响应消息，一旦收到所有参与者的确认消息，写本 地“end_transaction” 日志流程结束。</li>
</ol>
<p>流程：两阶段提交协调者流程</p>
<ol>
<li>写本地日志“init”记录，进入INIT 状态 </li>
<li>等待并接受协调者发送的“prepare 消息”，收到后  2.1 若参与者可以提交 本次事务 2.1.1 写本地日志“ready”，进入READY 状态 2.1.2 向协调者发 送“vote-commit”消息 2.1.4 等待协调者的消息2.1.4.1 若收到协调者 的“global-abort”消息2.1.4.1.1 写本地日志“abort”，进入ABORT 状态 2.1.4.1.2 向协调者发送对“global-abort”的确认消息   2.1.4.2 若收到协调者 的“global-commit”消息2.1.4.1.1 写本地日志“commit”，进入COMMIT  状态     2.1.4.1.2 向协调者发送对“global-commit”的确认消息  2.2 若参与 者无法提交本次事务 2.2.1 写本地日志“abort”，进入ABORT 状态 2.2.2 向协调者发送“vote-abort”消息 2.2.3 流程对该参与者结束 2.2.4 若后续收到 协调者的“global-abort”消息可以响应 </li>
<li>即使流程结束，但任何时候收到协调者发送的“global-abort”消息 或“global-commit”消息也都要发送一个对应的确认消息。</li>
</ol>
<h3 id="异常处理"><a href="#异常处理" class="headerlink" title="异常处理"></a>异常处理</h3><p>宕机恢复</p>
<ol>
<li>协调者宕机恢复 协调者宕机恢复后，首先通过日志查找到宕机前的状态。如 果日志中最后是“begin_commit”记录，说明宕机前协调者处于WAIT 状态， 协调者可能已经发送过“prepare 消息”也可能还没发送，但协调者一定还没 有发送过“global-commit 消息”或“global-abort 消息”，即事务的全局状 态还没有确定。此时，协调者可以重新发送“prepare 消息” 继续两阶段提交 流程，即使参与者已经发送过对“prepare 消息”的响应，也不过是再次重传 之前的响应而不会影响协议的一致性。如果日志中最后是“globalcommit”或“global-abort”记录，说明宕机前协调者处于COMMIT 或 ABORT 状态。此时协调者只需重新向所有的参与者发送“global-commit 消 息”或“global-abort 消息”就可以继续两阶段提交流程。 </li>
<li>参与者宕机恢复参与者宕机恢复后，首先通过日志查找宕机前的状态。如果 日志中最后是“init”记录，说明参与者处于INIT 状态，还没有对本次事务做 出投票选择，参与者可以继续流程等待协调者发送的“prepare 消息”。如果 日志中最后是“ready”记录，说明参与者处于REDAY 状态，此时说明参与者 已经就本次 事务做出了投票选择，但宕机前参与者是否已经向协调者发 送“vote-commit”消息并不可知。所以此时参与者可以向协调者重发“votecommit”，并继续协议流程。如果日志中最后是“commit”或“abort”记 录，说明参与者已经收到过协调者的“global-commit 消息”（处于COMMIT  状态）或者“global-abort 消息”（处于ABORT 状态）。至于是否向协调者 发 送过对“global-commit”或“global-abort”的确认消息则未知。但即使 没有发送过确认消息，由于协调者会不断重发“global-commit”或“globalabort”，只需在收到这些消息时发送确认消息既可，不影响协议的全局一致 性。</li>
</ol>
<h3 id="协议分析"><a href="#协议分析" class="headerlink" title="协议分析"></a>协议分析</h3><p>两阶段提交协议在工程实践中真正使用的较少，主要原因有以下几点：</p>
<ol>
<li>两阶段提交协议的容错能力较差。从上文的分析可以看出，两阶段提交协议 在某些情况下存在流程无法执行下去的情况，且也无法判断流程状态。在工程 中好的分布式协议往往总是可以在即使发生异常的情况下也能执行下去。例 如，回忆Lease 机制（2.3 ），一旦lease 发出，无论出现任何异常，Lease 服 务器节点总是可以通过时间判定出Lease 是否有效，也可以用等待Lease 超时 的方法收回Lease 权限，整个Lease 协议的流程不存在任何流程被阻塞而无法 执行下去的情况。与Lease 机制的简单有效相比，两阶段提交的协议显得较为 复杂且容错能力差。 </li>
<li>两阶段提交协议的性能较差。一次成功的两阶段提交协议流程中，协调者与 每个参与者 之间至少需要两轮交互4 个消息“prepare”、“votecommit”、“global-commit”、“确认global-commit”。过多的交互次 数会降低性能。另一方面，协调者需要等待所有的参与者的投票结果，一旦存 在较慢的参与者，会影响全局流程执行速度。</li>
</ol>
<p>虽然存在一些改进的两阶段提交协议可以提高容错能力和性能，然而这类协议依旧是 在工程中使用较少的一类协议，其理论价值大于实践意义。</p>
<h2 id="10-MVCC"><a href="#10-MVCC" class="headerlink" title="10. MVCC"></a>10. MVCC</h2><p>MVCC(Multi-version Cocurrent Control，多版本并发控制)技术。MVCC 技术最初 也是在数据库系统中被提出，但这种思想并不局限于单机的分布式系统，在分布式系 统中同样有效。</p>
<p>MVCC 即多个不同版本的数据实现并发控制的技术，其基本思想是为每次事务生成  一个新版本的数据，在读数据时选择不同版本的数据即可以实现对事务结果的完整性 读取。在使用MVCC 时，每个事务都是基于一个已生效的基础版本进行更新，事务可 以并行进行，从而可以产生一种图状结构。</p>
<p><img src="F:\0马士兵\新建文件夹\BAT面试突击资料(1)\OUT\03-2020最新整理一线大厂面试题合集(重点看)\19-分布式面试必会（2020最新版）.assets/MVCC.png" alt="MVCC"></p>
<p>基础数据的版本为1，同时产生了两个事务：事务A 与事务B。这两个事务都各自对数 据进行了一些本地修改（这些修改只有事务自己可见，不影响真正的数据），之后事 务A 首先提交，生成数据版本2；基于数据版本2，又发起了事务C，事务C 继续提 交，生成了数据版 本3；最后事务B 提交，此时事务B 的结果需要与事务C 的结果合 并，如果数据没有冲突，即事务 B 没有修改事务A 与事务C 修改过的变量，那么事务 B 可以提交，否则事务B 提交失败。MVCC 的流程过程非常类似于SVN 等版本控制 系统的流程，或者说SVN 等版本控制系统就是 使用的MVCC 思想。事务在基于基础 数据版本做本地修改时，为了不影响真正的数据，通常有两种做法，一是将基础数据 版本中的数据完全拷贝出来再修改，SVN 即使用了这种方法，SVN check out 即是 拷贝的过程；二是每个事务中只记录更新操作，而不记录完整的数据，读取数据时再 将更新操作应用到用基础版本的数据从而计算出结果，这个过程也类似SVN 的增量提 交。</p>
<h2 id="11-Paxos协议"><a href="#11-Paxos协议" class="headerlink" title="11. Paxos协议"></a>11. Paxos协议</h2><p>Paxos 协议是少数在工程实践中证实的强一致性、高可用的去中心化分布式协议。 Paxos 协议的流程较为复杂，但其基本思想却不难理解，类似于人类社会的投票过程。Paxos 协议中，有一组完全对等的参与节点（称为accpetor），这组节点各自就某一事件做出决议，如果某个决议获得了超过半数节点的同意则生效。Paxos 协议中只要有超过一半的节点正常，就可以工作，能很好对抗宕机、网络分化等异常情况。</p>
<p>角色</p>
<p>Proposer：提案者。Proposer 可以有多个，Proposer 提出议案（value）。所谓 value，在工程中可以是任何操作，例如“修改某个变量的值为某个值”、“设置当前primary 为某个节点”等等。Paxos 协议中统一将这些操作抽象为value。不同的 Proposer 可以提出不同的甚至矛盾的value，例如某个Proposer 提议“将变量X 设置为1”，另一个Proposer 提议“将变量X 设置为2”，但对同一轮Paxos 过程，最多只有一个value 被批准。Acceptor：批准者。Acceptor 有N 个，Proposer 提出的value 必须获得超过半数(N&#x2F;2+1)的Acceptor 批准后才能通过。Acceptor 之间完全对等独立。Learner：学习者。Learner 学习被批准的value。所谓学习就是通过读取各个Proposer 对value 的选择结果，如果某个value 被超过半数Proposer 通过，则Learner 学习到了这个value。回忆（2.4 ） 不难理解，这里类似Quorum 机制，某个value 需要获得W&#x3D;N&#x2F;2 + 1 的Acceptor 批准，从而学习者需要至少读取N&#x2F;2+1 个Accpetor，至多读取N 个Acceptor 的结果后，能学习到一个通过的value。上述三类角色只是逻辑上的划分，实践中一个节点可以同时充当这三类角色。</p>
<p>流程</p>
<p>Paxos 协议一轮一轮的进行，每轮都有一个编号。每轮Paxos 协议可能会批准一个 value，也可 能无法批准一个value。如果某一轮Paxos 协议批准了某个value，则以后各轮Paxos 只能批准这个 value。上述各轮协议流程组成了一个Paxos 协议实例，即一次Paxos 协议实例只能批准一个value，这也是Paxos 协议强一致性的重要体现。每轮Paxos 协议分为阶段，准备阶段和批准阶段，在这两个阶段Proposer 和 Acceptor 有各自的处理流程。</p>
<p>流程：Proposer 的流程 （准备阶段）</p>
<ol>
<li>向所有的Acceptor 发送消息“Prepare(b)”；这里b 是Paxos 的轮数，每</li>
</ol>
<p>轮递增</p>
<ol start="2">
<li><p>如果收到任何一个Acceptor 发送的消息“Reject(B)”，则对于这个 Proposer 而言本轮Paxos 失败，将轮数b 设置为B+1 后重新步骤1；（批准阶段，根据收到的Acceptor 的消息作出不同选择）</p>
</li>
<li><p>如果接收到的Acceptor 的“Promise(b, v_i)”消息达到N&#x2F;2+1 个（N 为 Acceptor 总数，除法取整， 下同）；v_i 表示Acceptor 最近一次在i 轮批准过 value v。3.1 如果收到的“Promise(b, v)”消息中，v 都为空，Proposer 选择一个value v，向所有Acceptor 广播Accept(b, v)；3.2 否则，在所有收到的“Promise(b, v_i)”消息中，选择i 最大的value v，向所有Acceptor 广播消息Accept(b，v)；</p>
</li>
<li><p>如果收到Nack(B)，将轮数b 设置为B+1 后重新步骤1；流程：Accpetor 流程 （准备阶段）</p>
</li>
<li><p>接受某个Propeser 的消息Prepare(b)。参数B 是该Acceptor 收到的最大</p>
</li>
</ol>
<p>Paxos 轮数编号；V 是Acceptor 批准的value，可以为空 1.1 如果b&gt;B，回复 Promise(b, V_B)，设置B&#x3D;b; 表示保证不再接受编号小于b 的提案。1.2 否则，回复Reject(B) （批准阶段）</p>
<ol start="2">
<li>接收Accept(b, v)， 2.1 如果b &lt; B, 回复Nack(B)，暗示proposer 有一个更大编号的提案被这个Acceptor 接收了 2.2 否则设置V&#x3D;v。表示这个Acceptor 批准的Value 是v。广播Accepted 消息。</li>
</ol>
<p>例子</p>
<p>基本例子里有5 个Acceptor，1 个Proposer，不存在任何网络、宕机异常。我们着重考察各个Accpetor 上变量B 和变量V 的变化，及Proposer 上变量b 的变化。</p>
<ol>
<li>初始状态</li>
</ol>
<p><img src="F:\0马士兵\新建文件夹\BAT面试突击资料(1)\OUT\03-2020最新整理一线大厂面试题合集(重点看)\19-分布式面试必会（2020最新版）.assets/初始状态.jpg" alt="初始状态"></p>
<ol start="2">
<li>Proposer 向所有Accpetor 发送“Prepare(1)”，所有Acceptor 正确处理，并回复Promise(1, NULL</li>
</ol>
<p><img src="F:\0马士兵\新建文件夹\BAT面试突击资料(1)\OUT\03-2020最新整理一线大厂面试题合集(重点看)\19-分布式面试必会（2020最新版）.assets/2.jpg" alt="2"></p>
<ol start="3">
<li>Proposer 收到5 个Promise(1, NULL)，满足多余半数的Promise 的value 为空，此时发送 Accept(1, v1)，其中v1 是Proposer 选择的Value。</li>
</ol>
<p><img src="F:\0马士兵\新建文件夹\BAT面试突击资料(1)\OUT\03-2020最新整理一线大厂面试题合集(重点看)\19-分布式面试必会（2020最新版）.assets/3.jpg" alt="3"></p>
<ol start="4">
<li>此时，v1 被超过半数的Acceptor 批准，v1 即是本次Paxos 协议实例批准的</li>
</ol>
<p>Value。如果Learner 学习value，学到的只能是v1</p>
<p>在同一个Paxos 实例中，批准的Value 是无法改变的，即使后续Proposer 以更高的序号发起Paxos 协议也无法改变value。Paxos 协议的核心就在于“批准的value 无法改变”，这也是整个协议正确性的基础。</p>
<p>Paxos 协议是被人为设计出来，其设计过程也是协议的推导过程。Paxos 协议利用了 Quorom 机 制，选择的W&#x3D;R&#x3D;N&#x2F;2+1。简单而言，协议就是Proposer 更新 Acceptor 的过程，一旦某个Acceptor 成功更新了超过半数的Acceptor，则更新成功。Learner 按Quorum 去读取Acceptor，一旦某个value 在超过半数的Proposer 上被成功读取，则说明这是一个被批准的value。协议通过引入轮次，使得高轮次的提议抢占低轮次的提议来避免死锁。协议设计关键点是如何满足“在一次Paxos 算法实例过程中只批准一个Value”这一约束条件。</p>
<h2 id="12-CAP"><a href="#12-CAP" class="headerlink" title="12. CAP"></a>12. CAP</h2><p>CAP 理论的定义很简单，CAP 三个字母分别代表了分布式系统中三个相互矛盾的属性：</p>
<ul>
<li>Consistency (一致性)：CAP 理论中的副本一致性特指强一致性（1.3.4 ）；</li>
<li>Availiablity(可用性)：指系统在出现异常时已经可以提供服务；</li>
<li>Tolerance to the partition of network (分区容忍)：指系统可以对网络分区（1.1.4.2 ）这种异常情 况进行容错处理；</li>
</ul>
<p>CAP 理论指出：无法设计一种分布式协议，使得同时完全具备CAP 三个属性，即1) 该种协议下的副本始终是强一致性，2)服务始终是可用的，3)协议可以容忍任何网络分区异常；分布式系统协议只能在CAP 这三者间所有折中。热力学第二定律说明了永动机是不可能存在的，不要去妄图设计永动机。与之类似， CAP 理论的意义就在于明确提出了不要去妄图设计一种对CAP 三大属性都完全拥有的完美系统，因为这种系统在理论上就已经被证明不存在。</p>
<ul>
<li><p>Lease 机制: Lease 机制牺牲了部分异常情况下的A，从而获得了完全的C 与很好的P。</p>
</li>
<li><p>Quorum 机制: Quorum 机制，在CAP 三大因素中都各做了折中，有一定的C，有较好 的A，也有较好的P，是一种较为平衡的分布式协议。</p>
</li>
<li><p>两阶段提交协议: 两阶段提交系统具有完全的C，很糟糕的A，很糟糕的P。</p>
</li>
<li><p>Paxos 协议：同样是强一致性协议，Paxos 在CAP 三方面较之两阶段提交协议要优秀得多。Paxos 协议具有 完全的C，较好的A，较好的P。Paxos 的A 与P 的属性与Quorum 机制类似，因为Paxos 的协议本 身就具有Quorum 机制的因素。</p>
</li>
</ul>

      
    </div>

    
    
    

       
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/10/12/18-Spring%20Cloud%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%882020%E6%9C%80%E6%96%B0%E7%89%88%EF%BC%89/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="善善332">
      <meta itemprop="description" content="运气和努力一样重要">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="和善寺">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/10/12/18-Spring%20Cloud%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%882020%E6%9C%80%E6%96%B0%E7%89%88%EF%BC%89/" class="post-title-link" itemprop="url">未命名</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-10-12 15:01:16" itemprop="dateCreated datePublished" datetime="2022-10-12T15:01:16+08:00">2022-10-12</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-03-03 13:51:35" itemprop="dateModified" datetime="2021-03-03T13:51:35+08:00">2021-03-03</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="为什么需要学习Spring-Cloud"><a href="#为什么需要学习Spring-Cloud" class="headerlink" title="为什么需要学习Spring Cloud"></a>为什么需要学习Spring Cloud</h1><p>不论是商业应用还是用户应用，在业务初期都很简单，我们通常会把它实现为单体结构的应用。但是，随着业务逐渐发展，产品思想会变得越来越复杂，单体结构的应用也会越来越复杂。这就会给应用带来如下的几个问题：</p>
<p> 代码结构混乱：业务复杂，导致代码量很大，管理会越来越困难。同时，这也会给业务的快速迭代带来巨大挑战；</p>
<p> 开发效率变低：开发人员同时开发一套代码，很难避免代码冲突。开发过程会伴随着不断解决冲突的过程，这会严重的影响开发效率；</p>
<p> 排查解决问题成本高：线上业务发现 bug，修复 bug 的过程可能很简单。但是，由于只有一套代码，需要重新编译、打包、上线，成本很高。</p>
<p>由于单体结构的应用随着系统复杂度的增高，会暴露出各种各样的问题。近些年来，微服务架构逐渐取代了单体架构，且这种趋势将会越来越流行。Spring </p>
<p>Cloud是目前最常用的微服务开发框架，已经在企业级开发中大量的应用。</p>
<h1 id="什么是Spring-Cloud"><a href="#什么是Spring-Cloud" class="headerlink" title="什么是Spring Cloud"></a>什么是Spring Cloud</h1><p>Spring Cloud是一系列框架的有序集合。它利用Spring Boot的开发便利性巧妙地简化了分布式系统基础设施的开发，如服务发现注册、配置中心、智能路由、消息总线、负载均衡、断路器、数据监控等，都可以用Spring Boot的开发风格做到一键启动和部署。Spring Cloud并没有重复制造轮子，它只是将各家公司开发的比较成熟、经得起实际考验的服务框架组合起来，通过Spring Boot风格进行再封装屏蔽掉了复杂的配置和实现原理，最终给开发者留出了一套简单易懂、易部署和易维护的分布式系统开发工具包。</p>
<h1 id="设计目标与优缺点"><a href="#设计目标与优缺点" class="headerlink" title="设计目标与优缺点"></a>设计目标与优缺点</h1><p>设计目标</p>
<p>协调各个微服务，简化分布式系统开发。</p>
<h2 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h2><p>微服务的框架那么多比如：dubbo、Kubernetes，为什么就要使用Spring </p>
<p>Cloud的呢？</p>
<p>优点：</p>
<ul>
<li>产出于Spring大家族，Spring在企业级开发框架中无人能敌，来头很大，可以保证后续的更新、完善</li>
<li>组件丰富，功能齐全。Spring Cloud 为微服务架构提供了非常完整的支持。例如、配置管理、服务发现、断路器、微服务网关等；</li>
<li>Spring Cloud 社区活跃度很高，教程很丰富，遇到问题很容易找到解决方案服务拆分粒度更细，耦合度比较低，有利于资源重复利用，有利于提高开发效率可以更精准的制定优化服务方案，提高系统的可维护性减轻团队的成本，可以并行开发，不用关注其他人怎么开发，先关注自己的开发微服务可以是跨平台的，可以用任何一种语言开发适于互联网时代，产品迭代周期更短</li>
</ul>
<p>缺点：</p>
<ul>
<li>微服务过多，治理成本高，不利于维护系统</li>
<li>分布式系统开发的成本高（容错，分布式事务等）对团队挑战大总的来说优点大过于缺点，目前看来Spring Cloud是一套非常完善的分布式框架，目前很多企业开始用微服务、Spring Cloud的优势是显而易见的。因此对于想研究微服务架构的同学来说，学习Spring Cloud是一个不错的选择。</li>
</ul>
<h1 id="Spring-Cloud发展前景"><a href="#Spring-Cloud发展前景" class="headerlink" title="Spring Cloud发展前景"></a>Spring Cloud发展前景</h1><p>Spring Cloud对于中小型互联网公司来说是一种福音，因为这类公司往往没有实力或者没有足够的资金投入去开发自己的分布式系统基础设施，使用Spring </p>
<p>Cloud一站式解决方案能在从容应对业务发展的同时大大减少开发成本。同时，随着近几年微服务架构和Docker容器概念的火爆，也会让Spring Cloud在未来越来越“云”化的软件开发风格中立有一席之地，尤其是在五花八门的分布式解决方案中提供了标准化的、全站式的技术方案，意义可能会堪比当年Servlet规范的诞生，有效推进服务端软件系统技术水平的进步。</p>
<h1 id="整体架构"><a href="#整体架构" class="headerlink" title="整体架构"></a>整体架构</h1><p>![整体架构](18-Spring Cloud面试题（2020最新版）.assets&#x2F;整体架构.jpg)</p>
<h1 id="主要项目"><a href="#主要项目" class="headerlink" title="主要项目"></a>主要项目</h1><p>Spring Cloud的子项目，大致可分成两类，一类是对现有成熟框架”Spring </p>
<p>Boot化”的封装和抽象，也是数量最多的项目；第二类是开发了一部分分布式系统的基础设施的实现，如Spring Cloud Stream扮演的就是kafka, ActiveMQ这样的角色。</p>
<h2 id="Spring-Cloud-Config"><a href="#Spring-Cloud-Config" class="headerlink" title="Spring Cloud Config"></a>Spring Cloud Config</h2><p>集中配置管理工具，分布式系统中统一的外部配置管理，默认使用Git来存储配置，可以支持客户端配置的刷新及加密、解密操作。</p>
<h2 id="Spring-Cloud-Netflix"><a href="#Spring-Cloud-Netflix" class="headerlink" title="Spring Cloud Netflix"></a>Spring Cloud Netflix</h2><p>Netflix OSS 开源组件集成，包括Eureka、Hystrix、Ribbon、Feign、Zuul等核心组件。</p>
<p>Eureka：服务治理组件，包括服务端的注册中心和客户端的服务发现机制；</p>
<p>Ribbon：负载均衡的服务调用组件，具有多种负载均衡调用策略；</p>
<p>Hystrix：服务容错组件，实现了断路器模式，为依赖服务的出错和延迟提供了容错能力；</p>
<p>Feign：基于Ribbon和Hystrix的声明式服务调用组件；</p>
<p>Zuul：API网关组件，对请求提供路由及过滤功能。</p>
<h2 id="Spring-Cloud-Bus"><a href="#Spring-Cloud-Bus" class="headerlink" title="Spring Cloud Bus"></a>Spring Cloud Bus</h2><p>用于传播集群状态变化的消息总线，使用轻量级消息代理链接分布式系统中的节点，可以用来动态刷新集群中的服务配置。</p>
<p>Spring Cloud Consul</p>
<p>基于Hashicorp Consul的服务治理组件。</p>
<p>Spring Cloud Security</p>
<p>安全工具包，对Zuul代理中的负载均衡OAuth2客户端及登录认证进行支持。</p>
<h2 id="Spring-Cloud-Sleuth"><a href="#Spring-Cloud-Sleuth" class="headerlink" title="Spring Cloud Sleuth"></a>Spring Cloud Sleuth</h2><p>Spring Cloud应用程序的分布式请求链路跟踪，支持使用Zipkin、HTrace和基于日志（例如ELK）的跟踪。</p>
<h2 id="Spring-Cloud-Stream"><a href="#Spring-Cloud-Stream" class="headerlink" title="Spring Cloud Stream"></a>Spring Cloud Stream</h2><p>轻量级事件驱动微服务框架，可以使用简单的声明式模型来发送及接收消息，主要实现为Apache Kafka及RabbitMQ。</p>
<h2 id="Spring-Cloud-Task"><a href="#Spring-Cloud-Task" class="headerlink" title="Spring Cloud Task"></a>Spring Cloud Task</h2><p>用于快速构建短暂、有限数据处理任务的微服务框架，用于向应用中添加功能性和非功能性的特性。</p>
<p>Spring Cloud Zookeeper</p>
<p>基于Apache Zookeeper的服务治理组件。</p>
<p>Spring Cloud Gateway</p>
<p>API网关组件，对请求提供路由及过滤功能。</p>
<h2 id="Spring-Cloud-OpenFeign"><a href="#Spring-Cloud-OpenFeign" class="headerlink" title="Spring Cloud OpenFeign"></a>Spring Cloud OpenFeign</h2><p>基于Ribbon和Hystrix的声明式服务调用组件，可以动态创建基于Spring MVC 注解的接口实现用于服务调用，在Spring Cloud 2.0中已经取代Feign成为了一等公民。</p>
<h1 id="Spring-Cloud的版本关系"><a href="#Spring-Cloud的版本关系" class="headerlink" title="Spring Cloud的版本关系"></a>Spring Cloud的版本关系</h1><p>Spring Cloud是一个由许多子项目组成的综合项目，各子项目有不同的发布节奏。 为了管理Spring Cloud与各子项目的版本依赖关系，发布了一个清单，其中包括了某个Spring Cloud版本对应的子项目版本。 为了避免Spring Cloud版本号与子项目版本号混淆，Spring Cloud版本采用了名称而非版本号的命名，</p>
<p>这些版本的名字采用了伦敦地铁站的名字，根据字母表的顺序来对应版本时间顺序，例如Angel是第一个版本，Brixton是第二个版本。 当Spring Cloud的发布</p>
<p>内容积累到临界点或者一个重大BUG被解决后，会发布一个”service </p>
<p>releases”版本，简称SRX版本，比如Greenwich.SR2就是Spring Cloud发布的 Greenwich版本的第2个SRX版本。目前Spring Cloud的最新版本是Hoxton。</p>
<h2 id="Spring-Cloud和SpringBoot版本对应关系"><a href="#Spring-Cloud和SpringBoot版本对应关系" class="headerlink" title="Spring Cloud和SpringBoot版本对应关系"></a>Spring Cloud和SpringBoot版本对应关系</h2><table>
<thead>
<tr>
<th>Spring Cloud   Version</th>
<th>SpringBo  ot   Version</th>
</tr>
</thead>
<tbody><tr>
<td>Hoxton</td>
<td>2.2.x</td>
</tr>
<tr>
<td>Greenwic h</td>
<td>2.1.x</td>
</tr>
<tr>
<td>Finchley</td>
<td>2.0.x</td>
</tr>
<tr>
<td>Edgware</td>
<td>1.5.x</td>
</tr>
<tr>
<td>Dalston</td>
<td>1.5.x</td>
</tr>
</tbody></table>
<h2 id="Spring-Cloud和各子项目版本对应关系"><a href="#Spring-Cloud和各子项目版本对应关系" class="headerlink" title="Spring Cloud和各子项目版本对应关系"></a>Spring Cloud和各子项目版本对应关系</h2><table>
<thead>
<tr>
<th>More Actions  Compon  ent</th>
<th>Edgware.  SR6</th>
<th>Greenwic  h.SR2</th>
</tr>
</thead>
<tbody><tr>
<td>spring- cloud- bus</td>
<td>1.3.4.RELE  ASE</td>
<td>2.1.2.RELE  ASE</td>
</tr>
<tr>
<td>spring- cloud-  commons</td>
<td>1.3.6.RELE    ASE</td>
<td>2.1.2.RELE  ASE</td>
</tr>
<tr>
<td>spring- cloud- config</td>
<td>1.4.7.RELE  ASE</td>
<td>2.1.3.RELE  ASE</td>
</tr>
<tr>
<td>spring-  cloud-     netflix</td>
<td>1.4.7.RELE  ASE</td>
<td>2.1.2.RELE  ASE</td>
</tr>
<tr>
<td>spring- cloud- security</td>
<td>1.2.4.RELE  ASE</td>
<td>2.1.3.RELE  ASE</td>
</tr>
<tr>
<td>spring- cloud- consul</td>
<td>1.3.6.RELE  ASE</td>
<td>2.1.2.RELE  ASE</td>
</tr>
<tr>
<td>spring- cloud- sleuth</td>
<td>1.3.6.RELE  ASE</td>
<td>2.1.1.RELE  ASE</td>
</tr>
<tr>
<td>spring- cloud- stream</td>
<td>Ditmars.S  R5</td>
<td>Fishtown.  SR3</td>
</tr>
<tr>
<td>spring- cloud- zookeepe r</td>
<td>1.2.3.RELE  ASE</td>
<td>2.1.2.RELE  ASE</td>
</tr>
<tr>
<td>spring-  boot</td>
<td>1.5.21.REL  EASE</td>
<td>2.1.5.RELE  ASE</td>
</tr>
<tr>
<td>spring- cloud- task</td>
<td>1.2.4.RELE  ASE</td>
<td>2.1.2.RELE  ASE</td>
</tr>
<tr>
<td>spring- cloud- gateway</td>
<td>1.0.3.RELE  ASE</td>
<td>2.1.2.RELE  ASE</td>
</tr>
<tr>
<td>spring- cloud- openfeig n</td>
<td>暂无</td>
<td>2.1.2.RELE  ASE</td>
</tr>
</tbody></table>
<p>注意：Hoxton版本是基于SpringBoot 2.2.x版本构建的，不适用于1.5.x版本。随着2019年8月SpringBoot 1.5.x版本停止维护，Edgware版本也将停止维护。</p>
<h1 id="SpringBoot和SpringCloud的区别？"><a href="#SpringBoot和SpringCloud的区别？" class="headerlink" title="SpringBoot和SpringCloud的区别？"></a>SpringBoot和SpringCloud的区别？</h1><p>SpringBoot专注于快速方便的开发单个个体微服务。</p>
<p>SpringCloud是关注全局的微服务协调整理治理框架，它将SpringBoot开发的一个个单体微服务整合并管理起来，为各个微服务之间提供，配置管理、服务发现、断路器、路由、微代理、事件总线、全局锁、决策竞选、分布式会话等等集成服务</p>
<p>SpringBoot可以离开SpringCloud独立使用开发项目， 但是SpringCloud离不开SpringBoot ，属于依赖的关系</p>
<p>SpringBoot专注于快速、方便的开发单个微服务个体，SpringCloud关注全局的服务治理框架。</p>
<h2 id="使用-Spring-Boot-开发分布式微服务时，我们面临以下问题"><a href="#使用-Spring-Boot-开发分布式微服务时，我们面临以下问题" class="headerlink" title="使用 Spring Boot 开发分布式微服务时，我们面临以下问题"></a>使用 Spring Boot 开发分布式微服务时，我们面临以下问题</h2><p>（1）  与分布式系统相关的复杂性-这种开销包括网络问题，延迟开销，带宽问题，安全问题。</p>
<p>（2）  服务发现-服务发现工具管理群集中的流程和服务如何查找和互相交谈。它涉及一个服务目录，在该目录中注册服务，然后能够查找并连接到该目录中的服务。</p>
<p>（3）  冗余-分布式系统中的冗余问题。</p>
<p>（4）  负载平衡 –负载平衡改善跨多个计算资源的工作负荷，诸如计算机，计算机集群，网络链路，中央处理单元，或磁盘驱动器的分布。</p>
<p>（5）  性能-问题 由于各种运营开销导致的性能问题。</p>
<p>（6）部署复杂性-Devops 技能的要求。</p>
<h1 id="服务注册和发现是什么意思？Spring-Cloud-如何实现？"><a href="#服务注册和发现是什么意思？Spring-Cloud-如何实现？" class="headerlink" title="服务注册和发现是什么意思？Spring Cloud 如何实现？"></a>服务注册和发现是什么意思？Spring Cloud 如何实现？</h1><p>当我们开始一个项目时，我们通常在属性文件中进行所有的配置。随着越来越多的服务开发和部署，添加和修改这些属性变得更加复杂。有些服务可能会下降，而某些位置可能会发生变化。手动更改属性可能会产生问题。 Eureka 服务注册和发现可以在这种情况下提供帮助。由于所有服务都在 Eureka 服务器上注册并通过调用 Eureka 服务器完成查找，因此无需处理服务地点的任何更改和处理。</p>
<p>Spring Cloud 和dubbo区别?</p>
<p>（1）服务调用方式 dubbo是RPC springcloud Rest Api （2）注册中心,dubbo 是zookeeper springcloud是eureka，也可以是 zookeeper</p>
<p>（3）服务网关,dubbo本身没有实现，只能通过其他第三方技术整合， springcloud有Zuul路由网关，作为路由服务器，进行消费者的请求分</p>
<p>发,springcloud支持断路器，与git完美集成配置文件支持版本控制，事物总线实现配置文件的更新与服务自动装配等等一系列的微服务架构要素。</p>
<h1 id="负载平衡的意义什么？"><a href="#负载平衡的意义什么？" class="headerlink" title="负载平衡的意义什么？"></a>负载平衡的意义什么？</h1><p>在计算中，负载平衡可以改善跨计算机，计算机集群，网络链接，中央处理单元或磁盘驱动器等多种计算资源的工作负载分布。负载平衡旨在优化资源使用，最大化吞吐量，最小化响应时间并避免任何单一资源的过载。使用多个组件进行负载平衡而不是单个组件可能会通过冗余来提高可靠性和可用性。负载平衡通常涉及专用软件或硬件，例如多层交换机或域名系统服务器进程。</p>
<h1 id="什么是-Hystrix？它如何实现容错？"><a href="#什么是-Hystrix？它如何实现容错？" class="headerlink" title="什么是 Hystrix？它如何实现容错？"></a>什么是 Hystrix？它如何实现容错？</h1><p>Hystrix 是一个延迟和容错库，旨在隔离远程系统，服务和第三方库的访问点，当出现故障是不可避免的故障时，停止级联故障并在复杂的分布式系统中实现弹性。</p>
<p>通常对于使用微服务架构开发的系统，涉及到许多微服务。这些微服务彼此协作。</p>
<p>思考以下微服务</p>
<p>![Hystrix](18-Spring Cloud面试题（2020最新版）.assets&#x2F;Hystrix.jpg)</p>
<p>假设如果上图中的微服务 9 失败了，那么使用传统方法我们将传播一个异常。</p>
<p>但这仍然会导致整个系统崩溃。</p>
<p>随着微服务数量的增加，这个问题变得更加复杂。微服务的数量可以高达 1000.</p>
<p>这是 hystrix 出现的地方 我们将使用 Hystrix 在这种情况下的 Fallback 方法功</p>
<p>能。我们有两个服务 employee-consumer 使用由 employee-consumer 公开的服务。</p>
<p>简化图如下所示</p>
<p>![简化](18-Spring Cloud面试题（2020最新版）.assets&#x2F;简化.jpg)</p>
<p>现在假设由于某种原因，employee-producer 公开的服务会抛出异常。我们在这种情况下使用 Hystrix 定义了一个回退方法。这种后备方法应该具有与公开服</p>
<p>务相同的返回类型。如果暴露服务中出现异常，则回退方法将返回一些值。</p>
<h1 id="什么是-Hystrix-断路器？我们需要它吗？"><a href="#什么是-Hystrix-断路器？我们需要它吗？" class="headerlink" title="什么是 Hystrix 断路器？我们需要它吗？"></a>什么是 Hystrix 断路器？我们需要它吗？</h1><p>由于某些原因，employee-consumer 公开服务会引发异常。在这种情况下使用Hystrix 我们定义了一个回退方法。如果在公开服务中发生异常，则回退方法返回一些默认值。</p>
<p>![Hystrix断路器](18-Spring Cloud面试题（2020最新版）.assets&#x2F;Hystrix断路器.jpg)</p>
<p>如果 firstPage method() 中的异常继续发生，则 Hystrix 电路将中断，并且员</p>
<p>工使用者将一起跳过 firtsPage 方法，并直接调用回退方法。 断路器的目的是给第一页方法或第一页方法可能调用的其他方法留出时间，并导致异常恢复。可能发生的情况是，在负载较小的情况下，导致异常的问题有更好的恢复机会 。</p>
<h2 id="什么是-Netflix-Feign？它的优点是什么？"><a href="#什么是-Netflix-Feign？它的优点是什么？" class="headerlink" title="什么是 Netflix Feign？它的优点是什么？"></a>什么是 Netflix Feign？它的优点是什么？</h2><p>Feign 是受到 Retrofit，JAXRS-2.0 和 WebSocket 启发的 java 客户端联编程序。</p>
<p>Feign 的第一个目标是将约束分母的复杂性统一到 http apis，而不考虑其稳定性。</p>
<p>在 employee-consumer 的例子中，我们使用了 employee-producer 使用 REST模板公开的 REST 服务。</p>
<p>但是我们必须编写大量代码才能执行以下步骤（1）使用功能区进行负载平衡。</p>
<p>（2）  获取服务实例，然后获取基本 URL。</p>
<p>（3）  利用 REST 模板来使用服务。 前面的代码如下</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">1  @Controller</span><br><span class="line">2  public class ConsumerControllerClient &#123;</span><br><span class="line">3  @Autowired</span><br><span class="line">4  private LoadBalancerClient loadBalancer;</span><br><span class="line">5  public void getEmployee() throws RestClientException, IOException &#123;</span><br><span class="line">6   ServiceInstance serviceInstance=loadBalancer.choose(&quot;employee‐ producer&quot;);</span><br><span class="line">7   System.out.println(serviceInstance.getUri());</span><br><span class="line">8   String baseUrl=serviceInstance.getUri().toString();</span><br><span class="line">9   baseUrl=baseUrl+&quot;/employee&quot;;</span><br><span class="line">10   RestTemplate restTemplate = new RestTemplate();</span><br><span class="line">11   ResponseEntity&lt;String&gt; response=null;</span><br><span class="line">12   try&#123;</span><br><span class="line">13   response=restTemplate.exchange(baseUrl,</span><br><span class="line">14   HttpMethod.GET, getHeaders(),String.class);</span><br><span class="line">15   &#125;</span><br><span class="line">16   catch (Exception ex)</span><br><span class="line">17   &#123;</span><br><span class="line">18   System.out.println(ex);</span><br><span class="line">19   &#125;</span><br><span class="line">20   System.out.println(response.getBody());</span><br><span class="line">21  &#125;</span><br></pre></td></tr></table></figure>

<p>之前的代码，有像 NullPointer 这样的例外的机会，并不是最优的。我们将看到如何使用 Netflix Feign 使呼叫变得更加轻松和清洁。如果 Netflix Ribbon 依赖关系也在类路径中，那么 Feign 默认也会负责负载平衡。</p>
<h2 id="什么是-Spring-Cloud-Bus？我们需要它吗？"><a href="#什么是-Spring-Cloud-Bus？我们需要它吗？" class="headerlink" title="什么是 Spring Cloud Bus？我们需要它吗？"></a>什么是 Spring Cloud Bus？我们需要它吗？</h2><p>考虑以下情况：我们有多个应用程序使用 Spring Cloud Config 读取属性，而</p>
<p>Spring Cloud Config 从 GIT 读取这些属性。</p>
<p>下面的例子中多个员工生产者模块从 Employee Config Module 获取 Eureka 注册的财产。</p>
<p>![获取Eureka注册财产](18-Spring Cloud面试题（2020最新版）.assets&#x2F;获取Eureka注册财产.jpg)</p>
<p>如果假设 GIT 中的 Eureka 注册属性更改(img)为指向另一台 Eureka 服务器，会发生什么情况。在这种情况下，我们将不得不重新启动服务以获取更新的属性。还有另一种使用执行器端点&#x2F;刷新的方式。但是我们将不得不为每个模块单独调</p>
<p>用这个 url。例如，如果 Employee Producer1 部署在端口 8080 上，则调用 http：&#x2F;&#x2F; localhost：8080 &#x2F; refresh。同样对于 Employee Producer2 </p>
<p>http：&#x2F;&#x2F;localhost：8081 &#x2F; refresh 等等。这又很麻烦。这就是 Spring Cloud Bus 发挥作用的地方。</p>
<p>![Spring_Bus](18-Spring Cloud面试题（2020最新版）.assets&#x2F;Spring_Bus.jpg)</p>
<p>Spring Cloud Bus 提供了跨多个实例刷新配置的功能。因此，在上面的示例中，如果我们刷新 Employee Producer1，则会自动刷新所有其他必需的模</p>
<p>块。如果我们有多个微服务启动并运行，这特别有用。这是通过将所有微服务连接到单个消息代理来实现的。无论何时刷新实例，此事件都会订阅到侦听此代理的所有微服务，并且它们也会刷新。可以通过使用端点&#x2F;总线&#x2F;刷新来实现对任何单个实例的刷新。</p>
<h1 id="Spring-Cloud断路器的作用"><a href="#Spring-Cloud断路器的作用" class="headerlink" title="Spring Cloud断路器的作用"></a>Spring Cloud断路器的作用</h1><p>当一个服务调用另一个服务由于网络原因或自身原因出现问题，调用者就会等待被调用者的响应 当更多的服务请求到这些资源导致更多的请求等待，发生连锁效应（雪崩效应）断路器有完全打开状态:一段时间内 达到一定的次数无法调用 并且多次监测没有恢复的迹象 断路器完全打开 那么下次请求就不会请求到该服务半开:短时间内 有恢复迹象 断路器会将部分请求发给该服务，正常调用时 断路器关闭</p>
<p>关闭：当服务一直处于正常状态 能正常调用</p>
<h2 id="什么是Spring-Cloud-Config"><a href="#什么是Spring-Cloud-Config" class="headerlink" title="什么是Spring Cloud Config?"></a>什么是Spring Cloud Config?</h2><p>在分布式系统中，由于服务数量巨多，为了方便服务配置文件统一管理，实时更新，所以需要分布式配置中心组件。在Spring Cloud中，有分布式配置中心组件spring cloud config ，它支持配置服务放在配置服务的内存中（即本地），也支持放在远程Git仓库中。在spring cloud config 组件中，分两个角色，一是 config server，二是config client。</p>
<p>使用：</p>
<p>（1）  添加pom依赖</p>
<p>（2）  配置文件添加相关配置</p>
<p>（3）  启动类添加注解@EnableConfigServer</p>
<h2 id="什么是Spring-Cloud-Gateway"><a href="#什么是Spring-Cloud-Gateway" class="headerlink" title="什么是Spring Cloud Gateway?"></a>什么是Spring Cloud Gateway?</h2><p>Spring Cloud Gateway是Spring Cloud官方推出的第二代网关框架，取代Zuul 网关。网关作为流量的，在微服务系统中有着非常作用，网关常见的功能有路由转发、权限校验、限流控制等作用。</p>
<p>使用了一个RouteLocatorBuilder的bean去创建路由，除了创建路由</p>
<p>RouteLocatorBuilder可以让你添加各种predicates和filters，predicates断言的意思，顾名思义就是根据具体的请求的规则，由具体的route去处理，filters 是各种过滤器，用来对请求做各种判断和修改。</p>

      
    </div>

    
    
    

       
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/10/12/17-Spring%20Boot%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%882020%E6%9C%80%E6%96%B0%E7%89%88%EF%BC%89-%E9%87%8D%E7%82%B9/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="善善332">
      <meta itemprop="description" content="运气和努力一样重要">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="和善寺">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/10/12/17-Spring%20Boot%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%882020%E6%9C%80%E6%96%B0%E7%89%88%EF%BC%89-%E9%87%8D%E7%82%B9/" class="post-title-link" itemprop="url">未命名</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-10-12 15:01:16" itemprop="dateCreated datePublished" datetime="2022-10-12T15:01:16+08:00">2022-10-12</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-03-03 13:51:35" itemprop="dateModified" datetime="2021-03-03T13:51:35+08:00">2021-03-03</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><h2 id="什么是-Spring-Boot？"><a href="#什么是-Spring-Boot？" class="headerlink" title="什么是 Spring Boot？"></a>什么是 Spring Boot？</h2><p>Spring Boot 是 Spring 开源组织下的子项目，是 Spring 组件一站式解决方案，主要是简化了使用 Spring 的难度，简省了繁重的配置，提供了各种启动器，开发者能快速上手。</p>
<h2 id="Spring-Boot-有哪些优点？"><a href="#Spring-Boot-有哪些优点？" class="headerlink" title="Spring Boot 有哪些优点？"></a>Spring Boot 有哪些优点？</h2><p>Spring Boot 主要有如下优点：</p>
<ol>
<li><p>容易上手，提升开发效率，为 Spring 开发提供一个更快、更广泛的入门体验。</p>
</li>
<li><p>开箱即用，远离繁琐的配置。</p>
</li>
<li><p>提供了一系列大型项目通用的非业务性功能，例如：内嵌服务器、安全管理、运行数据监控、运行状况检查和外部化配置等。</p>
</li>
<li><p>没有代码生成，也不需要XML配置。</p>
</li>
<li><p>避免大量的 Maven 导入和各种版本冲突。</p>
</li>
</ol>
<h2 id="Spring-Boot-的核心注解是哪个？它主要由哪几个注解组成的？"><a href="#Spring-Boot-的核心注解是哪个？它主要由哪几个注解组成的？" class="headerlink" title="Spring Boot 的核心注解是哪个？它主要由哪几个注解组成的？"></a>Spring Boot 的核心注解是哪个？它主要由哪几个注解组成的？</h2><p>启动类上面的注解是@SpringBootApplication，它也是 Spring Boot 的核心注解，主要组合包含了以下 3 个注解：</p>
<p>@SpringBootConfiguration：组合了 @Configuration 注解，实现配置文件的功能。</p>
<p>@EnableAutoConfiguration：打开自动配置的功能，也可以关闭某个自动配置的选项，如关闭数据源自动配置功能： @SpringBootApplication(exclude </p>
<p>&#x3D; { DataSourceAutoConfiguration.class })。</p>
<p>@ComponentScan：Spring组件扫描。</p>
<h1 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h1><h2 id="什么是-JavaConfig？"><a href="#什么是-JavaConfig？" class="headerlink" title="什么是 JavaConfig？"></a>什么是 JavaConfig？</h2><p>Spring JavaConfig 是 Spring 社区的产品，它提供了配置 Spring IoC 容器的纯Java 方法。因此它有助于避免使用 XML 配置。使用 JavaConfig 的优点在于：</p>
<p>（1）  面向对象的配置。由于配置被定义为 JavaConfig 中的类，因此用户可以</p>
<p>充分利用 Java 中的面向对象功能。一个配置类可以继承另一个，重写它的</p>
<p>@Bean 方法等。</p>
<p>（2）  减少或消除 XML 配置。基于依赖注入原则的外化配置的好处已被证明。</p>
<p>但是，许多开发人员不希望在 XML 和 Java 之间来回切换。JavaConfig 为开发人员提供了一种纯 Java 方法来配置与 XML 配置概念相似的 Spring 容器。从</p>
<p>技术角度来讲，只使用 JavaConfig 配置类来配置容器是可行的，但实际上很多人认为将JavaConfig 与 XML 混合匹配是理想的。（3）类型安全和重构友好。JavaConfig 提供了一种类型安全的方法来配置 </p>
<p>Spring容器。由于 Java 5.0 对泛型的支持，现在可以按类型而不是按名称检索 bean，不需要任何强制转换或基于字符串的查找。</p>
<h2 id="Spring-Boot-自动配置原理是什么？"><a href="#Spring-Boot-自动配置原理是什么？" class="headerlink" title="Spring Boot 自动配置原理是什么？"></a>Spring Boot 自动配置原理是什么？</h2><p>注解 @EnableAutoConfiguration, @Configuration, @ConditionalOnClass 就是自动配置的核心，</p>
<p>@EnableAutoConfiguration 给容器导入META-INF&#x2F;spring.factories 里定义的自动配置类。</p>
<p>筛选有效的自动配置类。</p>
<p>每一个自动配置类结合对应的 xxxProperties.java 读取配置文件进行自动配置功能</p>
<h2 id="你如何理解-Spring-Boot-配置加载顺序？"><a href="#你如何理解-Spring-Boot-配置加载顺序？" class="headerlink" title="你如何理解 Spring Boot 配置加载顺序？"></a>你如何理解 Spring Boot 配置加载顺序？</h2><p>在 Spring Boot 里面，可以使用以下几种方式来加载配置。</p>
<p>1）     properties文件；</p>
<p>2）     YAML文件；</p>
<p>3）     系统环境变量；</p>
<p>等等……</p>
<h2 id="4）命令行参数；-什么是-YAML？"><a href="#4）命令行参数；-什么是-YAML？" class="headerlink" title="4）命令行参数； 什么是 YAML？"></a>4）命令行参数； 什么是 YAML？</h2><p>YAML 是一种人类可读的数据序列化语言。它通常用于配置文件。与属性文件相比，如果我们想要在配置文件中添加复杂的属性，YAML 文件就更加结构化，而且更少混淆。可以看出 YAML 具有分层配置数据。</p>
<h2 id="YAML-配置的优势在哪里"><a href="#YAML-配置的优势在哪里" class="headerlink" title="YAML 配置的优势在哪里 ?"></a>YAML 配置的优势在哪里 ?</h2><p>YAML 现在可以算是非常流行的一种配置文件格式了，无论是前端还是后端，都可以见到 YAML 配置。那么 YAML 配置和传统的 properties 配置相比到底有哪些优势呢？</p>
<ol>
<li><p>配置有序，在一些特殊的场景下，配置有序很关键</p>
</li>
<li><p>支持数组，数组中的元素可以是基本数据类型也可以是对象</p>
</li>
<li><p>简洁</p>
</li>
</ol>
<p>相比 properties 配置文件，YAML 还有一个缺点，就是不支持 @PropertySource 注解导入自定义的 YAML 配置。</p>
<h2 id="Spring-Boot-是否可以使用-XML-配置"><a href="#Spring-Boot-是否可以使用-XML-配置" class="headerlink" title="Spring Boot 是否可以使用 XML 配置 ?"></a>Spring Boot 是否可以使用 XML 配置 ?</h2><p>Spring Boot 推荐使用 Java 配置而非 XML 配置，但是 Spring Boot 中也可以使用 XML 配置，通过 @ImportResource 注解可以引入一个 XML 配置。 spring boot 核心配置文件是什么？</p>
<p>bootstrap.properties 和 application.properties 有何区别 ?</p>
<p>单纯做 Spring Boot 开发，可能不太容易遇到 bootstrap.properties 配置文</p>
<p>件，但是在结合 Spring Cloud 时，这个配置就会经常遇到了，特别是在需要加载一些远程配置文件的时侯。</p>
<p>spring boot 核心的两个配置文件：</p>
<p> bootstrap (. yml 或者 . properties)：boostrap 由父 ApplicationContext 加载的，比 applicaton 优先加载，配置在应用程序上下文的引导阶段生效。一般来说我们在 Spring Cloud Config 或者 Nacos 中会用到它。且 boostrap 里面的属性不</p>
<p>能被覆盖；</p>
<p> application (. yml 或者 . properties)： 由ApplicatonContext 加载，用于 spring boot 项目的自动化配置。</p>
<h2 id="什么是-Spring-Profiles？"><a href="#什么是-Spring-Profiles？" class="headerlink" title="什么是 Spring Profiles？"></a>什么是 Spring Profiles？</h2><p>Spring Profiles 允许用户根据配置文件（dev，test，prod 等）来注册 bean。因此，当应用程序在开发中运行时，只有某些 bean 可以加载，而在</p>
<p>PRODUCTION中，某些其他 bean 可以加载。假设我们的要求是 Swagger 文档仅适用于 QA 环境，并且禁用所有其他文档。这可以使用配置文件来完成。Spring Boot 使得使用配置文件非常简单。</p>
<h2 id="如何在自定义端口上运行-Spring-Boot-应用程序？"><a href="#如何在自定义端口上运行-Spring-Boot-应用程序？" class="headerlink" title="如何在自定义端口上运行 Spring Boot 应用程序？"></a>如何在自定义端口上运行 Spring Boot 应用程序？</h2><p>为了在自定义端口上运行 Spring Boot 应用程序，您可以在</p>
<p>application.properties 中指定端口。server.port &#x3D; 8090</p>
<h1 id="安全"><a href="#安全" class="headerlink" title="安全"></a>安全</h1><h2 id="如何实现-Spring-Boot-应用程序的安全性？"><a href="#如何实现-Spring-Boot-应用程序的安全性？" class="headerlink" title="如何实现 Spring Boot 应用程序的安全性？"></a>如何实现 Spring Boot 应用程序的安全性？</h2><p>为了实现 Spring Boot 的安全性，我们使用 spring-boot-starter-security 依赖项，并且必须添加安全配置。它只需要很少的代码。配置类将必须扩展</p>
<p>WebSecurityConfigurerAdapter 并覆盖其方法。</p>
<h2 id="比较一下-Spring-Security-和-Shiro-各自的优缺点"><a href="#比较一下-Spring-Security-和-Shiro-各自的优缺点" class="headerlink" title="比较一下 Spring Security 和 Shiro 各自的优缺点 ?"></a>比较一下 Spring Security 和 Shiro 各自的优缺点 ?</h2><p>由于 Spring Boot 官方提供了大量的非常方便的开箱即用的 Starter ，包括 </p>
<p>Spring Security 的 Starter ，使得在 Spring Boot 中使用 Spring Security 变得更加容易，甚至只需要添加一个依赖就可以保护所有的接口，所以，如果是 </p>
<p>Spring Boot 项目，一般选择 Spring Security 。当然这只是一个建议的组合，单纯从技术上来说，无论怎么组合，都是没有问题的。Shiro 和 Spring </p>
<p>Security 相比，主要有如下一些特点：</p>
<ol>
<li>Spring Security 是一个重量级的安全管理框架；Shiro 则是一个轻量级</li>
</ol>
<p>的安全管理框架</p>
<ol start="2">
<li><p>Spring Security 概念复杂，配置繁琐；Shiro 概念简单、配置简单</p>
</li>
<li><p>Spring Security 功能强大；Shiro 功能简单</p>
</li>
</ol>
<h2 id="Spring-Boot-中如何解决跨域问题"><a href="#Spring-Boot-中如何解决跨域问题" class="headerlink" title="Spring Boot 中如何解决跨域问题 ?"></a>Spring Boot 中如何解决跨域问题 ?</h2><p>跨域可以在前端通过 JSONP 来解决，但是 JSONP 只可以发送 GET 请求，无法发送其他类型的请求，在 RESTful 风格的应用中，就显得非常鸡肋，因此我们推荐在后端通过 （CORS，Cross-origin resource sharing） 来解决跨域问题。这种解决方案并非 Spring Boot 特有的，在传统的 SSM 框架中，就可以通过 CORS 来解决跨域问题，只不过之前我们是在 XML 文件中配置 CORS ，现在可以通过实现WebMvcConfigurer接口然后重写addCorsMappings方法解决跨域问题。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">1  @Configuration</span><br><span class="line">2  public class CorsConfig implements WebMvcConfigurer &#123; 3</span><br><span class="line">4   @Override</span><br><span class="line">5   public void addCorsMappings(CorsRegistry registry) &#123;</span><br><span class="line">6   registry.addMapping(&quot;/**&quot;)</span><br><span class="line">7   .allowedOrigins(&quot;*&quot;)</span><br><span class="line">8   .allowCredentials(true)</span><br><span class="line">9   .allowedMethods(&quot;GET&quot;, &quot;POST&quot;, &quot;PUT&quot;, &quot;DELETE&quot;, &quot;OPTIONS&quot;)</span><br><span class="line">10   .maxAge(3600);</span><br><span class="line">11   &#125; </span><br><span class="line">12</span><br><span class="line">13  &#125;</span><br></pre></td></tr></table></figure>

<p>项目中前后端分离部署，所以需要解决跨域的问题。</p>
<p>我们使用cookie存放用户登录的信息，在spring拦截器进行权限控制，当权限不符合时，直接返回给用户固定的json结果。</p>
<p>当用户登录以后，正常使用；当用户退出登录状态时或者token过期时，由于拦截器和跨域的顺序有问题，出现了跨域的现象。</p>
<p>我们知道一个http请求，先走filter，到达servlet后才进行拦截器的处理，如果我们把cors放在filter里，就可以优先于权限拦截器执行。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">1  @Configuration</span><br><span class="line">2  public class CorsConfig &#123; 3</span><br><span class="line">4   @Bean</span><br><span class="line">5   public CorsFilter corsFilter() &#123;</span><br><span class="line">6   CorsConfiguration corsConfiguration = new CorsConfiguration();</span><br><span class="line">7   corsConfiguration.addAllowedOrigin(&quot;*&quot;);</span><br><span class="line">8   corsConfiguration.addAllowedHeader(&quot;*&quot;);</span><br><span class="line">9   corsConfiguration.addAllowedMethod(&quot;*&quot;);</span><br><span class="line">10   corsConfiguration.setAllowCredentials(true);</span><br><span class="line">11   UrlBasedCorsConfigurationSource urlBasedCorsConfigurationSource = new U rlBasedCorsConfigurationSource();</span><br><span class="line">12   urlBasedCorsConfigurationSource.registerCorsConfiguration(&quot;/**&quot;, corsCo nfiguration);</span><br><span class="line">13   return new CorsFilter(urlBasedCorsConfigurationSource);</span><br><span class="line">14   &#125; </span><br><span class="line">15</span><br><span class="line">16  &#125;</span><br></pre></td></tr></table></figure>

<h2 id="什么是-CSRF-攻击？"><a href="#什么是-CSRF-攻击？" class="headerlink" title="什么是 CSRF 攻击？"></a>什么是 CSRF 攻击？</h2><p>CSRF 代表跨站请求伪造。这是一种攻击，迫使 终用户在当前通过身份验证的 Web 应用程序上执行不需要的操作。CSRF 攻击专门针对状态改变请求，而不是数据窃取，因为攻击者无法查看对伪造请求的响应。</p>
<h1 id="监视器"><a href="#监视器" class="headerlink" title="监视器"></a>监视器</h1><h2 id="Spring-Boot-中的监视器是什么？"><a href="#Spring-Boot-中的监视器是什么？" class="headerlink" title="Spring Boot 中的监视器是什么？"></a>Spring Boot 中的监视器是什么？</h2><p>Spring boot actuator 是 spring 启动框架中的重要功能之一。Spring boot 监视器可帮助您访问生产环境中正在运行的应用程序的当前状态。有几个指标必须在生产环境中进行检查和监控。即使一些外部应用程序可能正在使用这些服务来向相关人员触发警报消息。监视器模块公开了一组可直接作为 HTTP URL 访问 的REST 端点来检查状态。</p>
<p>如何在 Spring Boot 中禁用 Actuator 端点安全性？</p>
<p>默认情况下，所有敏感的 HTTP 端点都是安全的，只有具有 ACTUATOR 角色</p>
<p>的用户才能访问它们。安全性是使用标准的 HttpServletRequest.isUserInRole 方法实施的。 我们可以使用来禁用安全性。只有在执行机构端点在防火墙后访问时，才建议禁用安全性。</p>
<h2 id="我们如何监视所有-Spring-Boot-微服务？"><a href="#我们如何监视所有-Spring-Boot-微服务？" class="headerlink" title="我们如何监视所有 Spring Boot 微服务？"></a>我们如何监视所有 Spring Boot 微服务？</h2><p>Spring Boot 提供监视器端点以监控各个微服务的度量。这些端点对于获取有关应用程序的信息（如它们是否已启动）以及它们的组件（如数据库等）是否正常运行很有帮助。但是，使用监视器的一个主要缺点或困难是，我们必须单独打开应用程序的知识点以了解其状态或健康状况。想象一下涉及 50 个应用程序的微服务，管理员将不得不击中所有 50 个应用程序的执行终端。为了帮助我们处理这种情况，我们将使用位于的开源项目。 它建立在 Spring Boot Actuator 之上，它提供了一个 Web UI，使我们能够可视化多个应用程序的度量。</p>
<h1 id="整合第三方项目"><a href="#整合第三方项目" class="headerlink" title="整合第三方项目"></a>整合第三方项目</h1><h2 id="什么是-WebSockets？"><a href="#什么是-WebSockets？" class="headerlink" title="什么是 WebSockets？"></a>什么是 WebSockets？</h2><p>WebSocket 是一种计算机通信协议，通过单个 TCP 连接提供全双工通信信道。</p>
<p>1、     WebSocket 是双向的 -使用 WebSocket 客户端或服务器可以发起消息发送。</p>
<p>2、     WebSocket 是全双工的 -客户端和服务器通信是相互独立的。</p>
<p>3、     单个 TCP 连接 -初始连接使用 HTTP，然后将此连接升级到基于套接字的连接。然后这个单一连接用于所有未来的通信</p>
<p>4、     Light -与 http 相比，WebSocket 消息数据交换要轻得多。</p>
<p>什么是 Spring Data ?</p>
<p>Spring Data 是 Spring 的一个子项目。用于简化数据库访问，支持NoSQL 和 关系数据存储。其主要目标是使数据库的访问变得方便快捷。Spring Data 具有如下特点：</p>
<p>SpringData 项目支持 NoSQL 存储：</p>
<ol>
<li><p>MongoDB （文档数据库）</p>
</li>
<li><p>Neo4j（图形数据库）</p>
</li>
<li><p>Redis（键&#x2F;值存储）</p>
</li>
<li><p>Hbase（列族数据库）</p>
</li>
</ol>
<p>SpringData 项目所支持的关系数据存储技术：</p>
<ol>
<li><p>JDBC</p>
</li>
<li><p>JPA</p>
</li>
</ol>
<p>Spring Data Jpa 致力于减少数据访问层 (DAO) 的开发量. 开发者唯一要做的，就是声明持久层的接口，其他都交给 Spring Data JPA 来帮你完成！Spring Data JPA 通过规范方法的名字，根据符合规范的名字来确定方法需要实现什么样的逻辑。</p>
<h2 id="什么是-Spring-Batch？"><a href="#什么是-Spring-Batch？" class="headerlink" title="什么是 Spring Batch？"></a>什么是 Spring Batch？</h2><p>Spring Boot Batch 提供可重用的函数，这些函数在处理大量记录时非常重要，包括日志&#x2F;跟踪，事务管理，作业处理统计信息，作业重新启动，跳过和资源管理。它还提供了更先进的技术服务和功能，通过优化和分区技术，可以实现极高批量和高性能批处理作业。简单以及复杂的大批量批处理作业可以高度可扩展的方式利用框架处理重要大量的信息。</p>
<h2 id="什么是-FreeMarker-模板？"><a href="#什么是-FreeMarker-模板？" class="headerlink" title="什么是 FreeMarker 模板？"></a>什么是 FreeMarker 模板？</h2><p>FreeMarker 是一个基于 Java 的模板引擎，  初专注于使用 MVC 软件架构进行动态网页生成。使用 Freemarker 的主要优点是表示层和业务层的完全分离。程序员可以处理应用程序代码，而设计人员可以处理 html 页面设计。 后使用 freemarker 可以将这些结合起来，给出  终的输出页面。</p>
<h2 id="如何集成-Spring-Boot-和-ActiveMQ？"><a href="#如何集成-Spring-Boot-和-ActiveMQ？" class="headerlink" title="如何集成 Spring Boot 和 ActiveMQ？"></a>如何集成 Spring Boot 和 ActiveMQ？</h2><p>对于集成 Spring Boot 和 ActiveMQ，我们使用依赖关系。 它只需要很少的配置，并且不需要样板代码。</p>
<h2 id="什么是-Apache-Kafka？"><a href="#什么是-Apache-Kafka？" class="headerlink" title="什么是 Apache Kafka？"></a>什么是 Apache Kafka？</h2><p>Apache Kafka 是一个分布式发布 - 订阅消息系统。它是一个可扩展的，容错的发布 - 订阅消息系统，它使我们能够构建分布式应用程序。这是一个 Apache 顶级项目。Kafka 适合离线和在线消息消费。</p>
<h2 id="什么是-Swagger？你用-Spring-Boot-实现了它吗？"><a href="#什么是-Swagger？你用-Spring-Boot-实现了它吗？" class="headerlink" title="什么是 Swagger？你用 Spring Boot 实现了它吗？"></a>什么是 Swagger？你用 Spring Boot 实现了它吗？</h2><p>Swagger 广泛用于可视化 API，使用 Swagger UI 为前端开发人员提供在线沙箱。Swagger 是用于生成 RESTful Web 服务的可视化表示的工具，规范和完整框架实现。它使文档能够以与服务器相同的速度更新。当通过 Swagger 正确定义时，消费者可以使用 少量的实现逻辑来理解远程服务并与其进行交互。因此，Swagger消除了调用服务时的猜测。</p>
<p>前后端分离，如何维护接口文档 ?</p>
<p>前后端分离开发日益流行，大部分情况下，我们都是通过 Spring Boot 做前后端分离开发，前后端分离一定会有接口文档，不然会前后端会深深陷入到扯皮中。一个比较笨的方法就是使用 word 或者 md 来维护接口文档，但是效率太低，接口一变，所有人手上的文档都得变。在 Spring Boot 中，这个问题常见</p>
<p>的解决方案是 Swagger ，使用 Swagger 我们可以快速生成一个接口文档网</p>
<p>站，接口一旦发生变化，文档就会自动更新，所有开发工程师访问这一个在线网站就可以获取到 新的接口文档，非常方便。</p>
<h1 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h1><h2 id="如何重新加载-Spring-Boot-上的更改，而无需重新启动服务器？Spring-Boot项目如何热部署？"><a href="#如何重新加载-Spring-Boot-上的更改，而无需重新启动服务器？Spring-Boot项目如何热部署？" class="headerlink" title="如何重新加载 Spring Boot 上的更改，而无需重新启动服务器？Spring Boot项目如何热部署？"></a>如何重新加载 Spring Boot 上的更改，而无需重新启动服务器？Spring Boot项目如何热部署？</h2><p>这可以使用 DEV 工具来实现。通过这种依赖关系，您可以节省任何更改，嵌入式tomcat 将重新启动。Spring Boot 有一个开发工具（DevTools）模块，它有助于提高开发人员的生产力。Java 开发人员面临的一个主要挑战是将文件更改自动部署到服务器并自动重启服务器。开发人员可以重新加载 Spring Boot 上的更改，而无需重新启动服务器。这将消除每次手动部署更改的需要。</p>
<p>Spring Boot 在发布它的第一个版本时没有这个功能。这是开发人员 需要的功能。DevTools 模块完全满足开发人员的需求。该模块将在生产环境中被禁用。</p>
<p>它还提供 H2 数据库控制台以更好地测试应用程序。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1 &lt;dependency&gt;</span><br><span class="line">2   &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">3   &lt;artifactId&gt;spring‐boot‐devtools&lt;/artifactId&gt;</span><br><span class="line">4  &lt;/dependency&gt;</span><br></pre></td></tr></table></figure>

<h2 id="您使用了哪些-starter-maven-依赖项？"><a href="#您使用了哪些-starter-maven-依赖项？" class="headerlink" title="您使用了哪些 starter maven 依赖项？"></a>您使用了哪些 starter maven 依赖项？</h2><p>使用了下面的一些依赖项</p>
<p>spring-boot-starter-activemq</p>
<p>spring-boot-starter-security</p>
<p>这有助于增加更少的依赖关系，并减少版本的冲突。</p>
<p>Spring Boot 中的 starter 到底是什么 ?</p>
<p>首先，这个 Starter 并非什么新的技术点，基本上还是基于 Spring 已有功能来实现的。首先它提供了一个自动化配置类，一般命名为 XXXAutoConfiguration </p>
<p>，在这个配置类中通过条件注解来决定一个配置是否生效（条件注解就是 </p>
<p>Spring 中原本就有的），然后它还会提供一系列的默认配置，也允许开发者根据实际情况自定义相关配置，然后通过类型安全的属性注入将这些配置属性注入进来，新注入的属性会代替掉默认属性。正因为如此，很多第三方框架，我们只需要引入依赖就可以直接使用了。当然，开发者也可以自定义 Starter spring-boot-starter-parent 有什么用 ?</p>
<p>我们都知道，新创建一个 Spring Boot 项目，默认都是有 parent 的，这个 </p>
<p>parent 就是 spring-boot-starter-parent ，spring-boot-starter-parent 主要有如下作用：</p>
<ol>
<li><p>定义了 Java 编译版本为 1.8 。</p>
</li>
<li><p>使用 UTF-8 格式编码。</p>
</li>
<li><p>继承自 spring-boot-dependencies，这个里边定义了依赖的版本，也正是因为继承了这个依赖，所以我们在写依赖时才不需要写版本号。</p>
</li>
<li><p>执行打包操作的配置。</p>
</li>
<li><p>自动化的资源过滤。</p>
</li>
<li><p>自动化的插件配置。</p>
</li>
<li><p>针对 application.properties 和 application.yml 的资源过滤，包括通过 profile 定义的不同环境的配置文件，例如 applicationdev.properties 和 application-dev.yml。</p>
</li>
</ol>
<p>Spring Boot 打成的 jar 和普通的 jar 有什么区别 ?</p>
<p>Spring Boot 项目  终打包成的 jar 是可执行 jar ，这种 jar 可以直接通过 java jar xxx.jar 命令来运行，这种 jar 不可以作为普通的 jar 被其他项目依赖，即使依赖了也无法使用其中的类。</p>
<p>Spring Boot 的 jar 无法被其他项目依赖，主要还是他和普通 jar 的结构不同。普通的 jar 包，解压后直接就是包名，包里就是我们的代码，而 Spring Boot </p>
<p>打包成的可执行 jar 解压后，在 \BOOT-INF\classes 目录下才是我们的代码，因此无法被直接引用。如果非要引用，可以在 pom.xml 文件中增加配置，将 Spring Boot 项目打包成两个 jar ，一个可执行，一个可引用。</p>
<h2 id="运行-Spring-Boot-有哪几种方式？"><a href="#运行-Spring-Boot-有哪几种方式？" class="headerlink" title="运行 Spring Boot 有哪几种方式？"></a>运行 Spring Boot 有哪几种方式？</h2><p>1）     打包用命令或者放到容器中运行</p>
<p>2）     用 Maven&#x2F; Gradle 插件运行</p>
<p>3）直接执行 main 方法运行</p>
<h2 id="Spring-Boot-需要独立的容器运行吗？"><a href="#Spring-Boot-需要独立的容器运行吗？" class="headerlink" title="Spring Boot 需要独立的容器运行吗？"></a>Spring Boot 需要独立的容器运行吗？</h2><h2 id="开启-Spring-Boot-特性有哪几种方式？"><a href="#开启-Spring-Boot-特性有哪几种方式？" class="headerlink" title="开启 Spring Boot 特性有哪几种方式？"></a>开启 Spring Boot 特性有哪几种方式？</h2><p>1）     继承spring-boot-starter-parent项目</p>
<p>2）     导入spring-boot-dependencies项目依赖</p>
<h2 id="如何使用-Spring-Boot-实现异常处理？"><a href="#如何使用-Spring-Boot-实现异常处理？" class="headerlink" title="如何使用 Spring Boot 实现异常处理？"></a>如何使用 Spring Boot 实现异常处理？</h2><p>Spring 提供了一种使用 ControllerAdvice 处理异常的非常有用的方法。 我们通过实现一个 ControlerAdvice 类，来处理控制器类抛出的所有异常。</p>
<h2 id="如何使用-Spring-Boot-实现分页和排序？"><a href="#如何使用-Spring-Boot-实现分页和排序？" class="headerlink" title="如何使用 Spring Boot 实现分页和排序？"></a>如何使用 Spring Boot 实现分页和排序？</h2><p>使用 Spring Boot 实现分页非常简单。使用 Spring Data-JPA 可以实现将可分页的传递给存储库方法。</p>
<p>微服务中如何实现 session 共享 ?</p>
<p>在微服务中，一个完整的项目被拆分成多个不相同的独立的服务，各个服务独立部署在不同的服务器上，各自的 session 被从物理空间上隔离开了，但是经</p>
<p>常，我们需要在不同微服务之间共享 session ，常见的方案就是 Spring </p>
<p>Session + Redis 来实现 session 共享。将所有微服务的 session 统一保存在 Redis 上，当各个微服务对 session 有相关的读写操作时，都去操作 Redis 上的 session 。这样就实现了 session 共享，Spring Session 基于 Spring 中的代理过滤器实现，使得 session 的同步操作对开发人员而言是透明的，非常简便。</p>
<h2 id="Spring-Boot-中如何实现定时任务"><a href="#Spring-Boot-中如何实现定时任务" class="headerlink" title="Spring Boot 中如何实现定时任务 ?"></a>Spring Boot 中如何实现定时任务 ?</h2><p>定时任务也是一个常见的需求，Spring Boot 中对于定时任务的支持主要还是来自 Spring 框架。</p>
<p>在 Spring Boot 中使用定时任务主要有两种不同的方式，一个就是使用 Spring 中的 @Scheduled 注解，另一个则是使用第三方框架 Quartz。</p>
<p>使用 Spring 中的 @Scheduled 的方式主要通过 @Scheduled 注解来实现。</p>
<p>使用 Quartz ，则按照 Quartz 的方式，定义 Job 和 Trigger 即可。</p>

      
    </div>

    
    
    

       
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/10/12/16-Netty%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%882020%E6%9C%80%E6%96%B0%E7%89%88%EF%BC%89/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="善善332">
      <meta itemprop="description" content="运气和努力一样重要">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="和善寺">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/10/12/16-Netty%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%882020%E6%9C%80%E6%96%B0%E7%89%88%EF%BC%89/" class="post-title-link" itemprop="url">未命名</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-10-12 15:01:16" itemprop="dateCreated datePublished" datetime="2022-10-12T15:01:16+08:00">2022-10-12</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-03-03 13:51:34" itemprop="dateModified" datetime="2021-03-03T13:51:34+08:00">2021-03-03</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="1-Netty-是什么？"><a href="#1-Netty-是什么？" class="headerlink" title="1. Netty 是什么？"></a>1. Netty 是什么？</h2><p>Netty是 一个异步事件驱动的网络应用程序框架，用于快速开发可维护的高性能 协议服务器和客户端。Netty是基于nio的，它封装了jdk的nio，让我们使用起 来更加方法灵活。 </p>
<h2 id="2-Netty-特点是什么？"><a href="#2-Netty-特点是什么？" class="headerlink" title="2. Netty 特点是什么？"></a>2. Netty 特点是什么？</h2><ul>
<li>高并发：Netty 是一款基于 NIO（Nonblocking IO，非阻塞IO）开发的网络通 信框架，对比于 BIO（Blocking I&#x2F;O，阻塞IO），他的并发性能得到了很大提高。 </li>
<li>传输快：Netty 的传输依赖于零拷贝特性，尽量减少不必要的内存拷贝，实现了 更高效率的传输。 </li>
<li>封装好：Netty 封装了 NIO 操作的很多细节，提供了易于使用调用接口。</li>
</ul>
<h2 id="3-Netty-的优势有哪些？"><a href="#3-Netty-的优势有哪些？" class="headerlink" title="3. Netty 的优势有哪些？"></a>3. Netty 的优势有哪些？</h2><ul>
<li>使用简单：封装了 NIO 的很多细节，使用更简单。 </li>
<li>功能强大：预置了多种编解码功能，支持多种主流协议。 </li>
<li>定制能力强：可以通过 ChannelHandler 对通信框架进行灵活地扩展。 </li>
<li>性能高：通过与其他业界主流的 NIO 框架对比，Netty 的综合性能优。 </li>
<li>稳定：Netty 修复了已经发现的所有 NIO 的 bug，让开发人员可以专注于业务 本身。 </li>
<li>社区活跃：Netty 是活跃的开源项目，版本迭代周期短，bug 修复速度快。</li>
</ul>
<h2 id="4-Netty-的应用场景有哪些？"><a href="#4-Netty-的应用场景有哪些？" class="headerlink" title="4. Netty 的应用场景有哪些？"></a>4. Netty 的应用场景有哪些？</h2><p>典型的应用有：阿里分布式服务框架 Dubbo，默认使用 Netty 作为基础通信组 件，还有 RocketMQ 也是使用 Netty 作为通讯的基础。 </p>
<h2 id="5-Netty-高性能表现在哪些方面？"><a href="#5-Netty-高性能表现在哪些方面？" class="headerlink" title="5. Netty 高性能表现在哪些方面？"></a>5. Netty 高性能表现在哪些方面？</h2><ul>
<li>IO 线程模型：同步非阻塞，用少的资源做更多的事。 </li>
<li>内存零拷贝：尽量减少不必要的内存拷贝，实现了更高效率的传输。 </li>
<li>内存池设计：申请的内存可以重用，主要指直接内存。内部实现是用一颗二叉查 找树管理内存分配情况。 </li>
<li>串形化处理读写：避免使用锁带来的性能开销。</li>
<li>高性能序列化协议：支持 protobuf 等高性能序列化协议。</li>
</ul>
<h2 id="6-BIO、NIO和AIO的区别？"><a href="#6-BIO、NIO和AIO的区别？" class="headerlink" title="6. BIO、NIO和AIO的区别？"></a>6. BIO、NIO和AIO的区别？</h2><p>BIO：一个连接一个线程，客户端有连接请求时服务器端就需要启动一个线程进 行处理。线程开销大。 </p>
<p>伪异步IO：将请求连接放入线程池，一对多，但线程还是很宝贵的资源。 </p>
<p>NIO：一个请求一个线程，但客户端发送的连接请求都会注册到多路复用器上， 多路复用器轮询到连接有I&#x2F;O请求时才启动一个线程进行处理。 </p>
<p>AIO：一个有效请求一个线程，客户端的I&#x2F;O请求都是由OS先完成了再通知服务 器应用去启动线程进行处理， </p>
<p>BIO是面向流的，NIO是面向缓冲区的；BIO的各种流是阻塞的。而NIO是非阻 塞的；BIO的Stream是单向的，而NIO的channel是双向的。 </p>
<p>NIO的特点：事件驱动模型、单线程处理多任务、非阻塞I&#x2F;O，I&#x2F;O读写不再阻 塞，而是返回0、基于block的传输比基于流的传输更高效、更高级的IO函数 zero-copy、IO多路复用大大提高了Java网络应用的可伸缩性和实用性。基于 Reactor线程模型。 </p>
<p>在Reactor模式中，事件分发器等待某个事件或者可应用或个操作的状态发生， 事件分发器就把这个事件传给事先注册的事件处理函数或者回调函数，由后者来 做实际的读写操作。如在Reactor中实现读：注册读就绪事件和相应的事件处理 器、事件分发器等待事件、事件到来，激活分发器，分发器调用事件对应的处理 器、事件处理器完成实际的读操作，处理读到的数据，注册新的事件，然后返还 控制权。 </p>
<h2 id="7-NIO的组成？"><a href="#7-NIO的组成？" class="headerlink" title="7. NIO的组成？"></a>7. NIO的组成？</h2><p>Buffer：与Channel进行交互，数据是从Channel读入缓冲区，从缓冲区写入 Channel中的 </p>
<p>flip方法 ： 反转此缓冲区，将position给limit，然后将position置为0，其实就 是切换读写模式 </p>
<p>clear方法 ：清除此缓冲区，将position置为0，把capacity的值给limit。 </p>
<p>rewind方法 ： 重绕此缓冲区，将position置为0 </p>
<p>DirectByteBuffer可减少一次系统空间到用户空间的拷贝。但Buffer创建和销毁 的成本更高，不可控，通常会用内存池来提高性能。直接缓冲区主要分配给那些易受基础系统的本机I&#x2F;O 操作影响的大型、持久的缓冲区。如果数据量比较小的 中小应用情况下，可以考虑使用heapBuffer，由JVM进行管理。 </p>
<p>Channel：表示 IO 源与目标打开的连接，是双向的，但不能直接访问数据，只 能与Buffer 进行交互。通过源码可知，FileChannel的read方法和write方法都 导致数据复制了两次！ </p>
<p>Selector可使一个单独的线程管理多个Channel，open方法可创建Selector， register方法向多路复用器器注册通道，可以监听的事件类型：读、写、连接、 accept。注册事件后会产生一个SelectionKey：它表示SelectableChannel 和 Selector 之间的注册关系，wakeup方法：使尚未返回的第一个选择操作立即返 回，唤醒的 </p>
<p>原因是：注册了新的channel或者事件；channel关闭，取消注册；优先级更高 的事件触发（如定时器事件），希望及时处理。 </p>
<p>Selector在Linux的实现类是EPollSelectorImpl，委托给EPollArrayWrapper实 现，其中三个native方法是对epoll的封装，而EPollSelectorImpl.  </p>
<p>implRegister方法，通过调用epoll_ctl向epoll实例中注册事件，还将注册的文 件描述符(fd)与SelectionKey的对应关系添加到fdToKey中，这个map维护了文 件描述符与SelectionKey的映射。 </p>
<p>fdToKey有时会变得非常大，因为注册到Selector上的Channel非常多（百万连 接）；过期或失效的Channel没有及时关闭。fdToKey总是串行读取的，而读取 是在select方法中进行的，该方法是非线程安全的。 </p>
<p>Pipe：两个线程之间的单向数据连接，数据会被写到sink通道，从source通道 读取 </p>
<p>NIO的服务端建立过程：Selector.open()：打开一个Selector； </p>
<p>ServerSocketChannel.open()：创建服务端的Channel；bind()：绑定到某个 端口上。并配置非阻塞模式；register()：注册Channel和关注的事件到 Selector上；select()轮询拿到已经就绪的事件 </p>
<h2 id="8-Netty的线程模型？"><a href="#8-Netty的线程模型？" class="headerlink" title="8. Netty的线程模型？"></a>8. Netty的线程模型？</h2><p>Netty通过Reactor模型基于多路复用器接收并处理用户请求，内部实现了两个 线程池，boss线程池和work线程池，其中boss线程池的线程负责处理请求的 accept事件，当接收到accept事件的请求时，把对应的socket封装到一个NioSocketChannel中，并交给work线程池，其中work线程池负责请求的read 和write事件，由对应的Handler处理。 </p>
<p>单线程模型：所有I&#x2F;O操作都由一个线程完成，即多路复用、事件分发和处理都 是在一个Reactor线程上完成的。既要接收客户端的连接请求,向服务端发起连 接，又要发送&#x2F;读取请求或应答&#x2F;响应消息。一个NIO 线程同时处理成百上千的 链路，性能上无法支撑，速度慢，若线程进入死循环，整个程序不可用，对于高 负载、大并发的应用场景不合适。 </p>
<p>多线程模型：有一个NIO 线程（Acceptor） 只负责监听服务端，接收客户端的 TCP 连接请求；NIO 线程池负责网络IO 的操作，即消息的读取、解码、编码和 发送；1 个NIO 线程可以同时处理N 条链路，但是1 个链路只对应1 个NIO 线 程，这是为了防止发生并发操作问题。但在并发百万客户端连接或需要安全认证 时，一个Acceptor 线程可能会存在性能不足问题。 </p>
<p>主从多线程模型：Acceptor 线程用于绑定监听端口，接收客户端连接，将 SocketChannel 从主线程池的Reactor 线程的多路复用器上移除，重新注册到 Sub 线程池的线程上，用于处理I&#x2F;O 的读写等操作，从而保证mainReactor只负 责接入认证、握手等操作； </p>
<h2 id="9-TCP-粘包-x2F-拆包的原因及解决方法？"><a href="#9-TCP-粘包-x2F-拆包的原因及解决方法？" class="headerlink" title="9. TCP 粘包&#x2F;拆包的原因及解决方法？"></a>9. TCP 粘包&#x2F;拆包的原因及解决方法？</h2><p>TCP是以流的方式来处理数据，一个完整的包可能会被TCP拆分成多个包进行发 送，也可能把小的封装成一个大的数据包发送。 </p>
<p>TCP粘包&#x2F;分包的原因： </p>
<p>应用程序写入的字节大小大于套接字发送缓冲区的大小，会发生拆包现象，而应 用程序写入数据小于套接字缓冲区大小，网卡将应用多次写入的数据发送到网络 上，这将会发生粘包现象； </p>
<p>进行MSS大小的TCP分段，当TCP报文长度-TCP头部长度&gt;MSS的时候将发生拆 包 </p>
<p>以太网帧的payload（净荷）大于MTU（1500字节）进行ip分片。 </p>
<p>解决方法 </p>
<p>消息定长：FixedLengthFrameDecoder类 </p>
<p>包尾增加特殊字符分割： </p>
<ul>
<li>行分隔符类：LineBasedFrameDecoder</li>
<li>或自定义分隔符类 ：DelimiterBasedFrameDecoder</li>
</ul>
<p>将消息分为消息头和消息体：LengthFieldBasedFrameDecoder类。分为有头 部的拆包与粘包、长度字段在前且有头部的拆包与粘包、多扩展头部的拆包与粘 包。 </p>
<h2 id="10-什么是-Netty-的零拷贝？"><a href="#10-什么是-Netty-的零拷贝？" class="headerlink" title="10. 什么是 Netty 的零拷贝？"></a>10. 什么是 Netty 的零拷贝？</h2><p>Netty 的零拷贝主要包含三个方面： </p>
<ul>
<li>Netty 的接收和发送 ByteBuffer 采用 DIRECT BUFFERS，使用堆外直接内存进 行 Socket 读写，不需要进行字节缓冲区的二次拷贝。如果使用传统的堆内存 （HEAP BUFFERS）进行 Socket 读写，JVM 会将堆内存 Buffer 拷贝一份到直接内 存中，然后才写入 Socket 中。相比于堆外直接内存，消息在发送过程中多了一次缓 冲区的内存拷贝。 </li>
<li>Netty 提供了组合 Buffer 对象，可以聚合多个 ByteBuffer 对象，用户可以像操 作一个 Buffer 那样方便的对组合 Buffer 进行操作，避免了传统通过内存拷贝的方式 将几个小 Buffer 合并成一个大的 Buffer。 </li>
<li>Netty 的文件传输采用了 transferTo 方法，它可以直接将文件缓冲区的数据发 送到目标 Channel，避免了传统通过循环 write 方式导致的内存拷贝问题。</li>
</ul>
<h1 id="11-Netty-中有哪种重要组件？"><a href="#11-Netty-中有哪种重要组件？" class="headerlink" title="11.Netty 中有哪种重要组件？"></a>11.Netty 中有哪种重要组件？</h1><ul>
<li>Channel：Netty 网络操作抽象类，它除了包括基本的 I&#x2F;O 操作，如 bind、 connect、read、write 等。</li>
<li>EventLoop：主要是配合 Channel 处理 I&#x2F;O 操作，用来处理连接的生命周期中所发生的事情。</li>
<li>ChannelFuture：Netty 框架中所有的 I&#x2F;O 操作都为异步的，因此我们需要 </li>
<li>ChannelFuture 的 addListener()注册一个 ChannelFutureListener 监听事件，当操作执行成功或者失败时，监听就会自动触发返回结果。</li>
<li>ChannelHandler：充当了所有处理入站和出站数据的逻辑容器。</li>
<li>ChannelHandler 主要用来处理各种事件，这里的事件很广泛，比如可以是连接、数据接收、异常、数据转换等。</li>
<li>ChannelPipeline：为 ChannelHandler 链提供了容器，当 channel 创建时，就会被自动分配到它专属的 ChannelPipeline，这个关联是永久性的。</li>
</ul>
<h1 id="12-Netty-发送消息有几种方式？"><a href="#12-Netty-发送消息有几种方式？" class="headerlink" title="12.Netty 发送消息有几种方式？"></a>12.Netty 发送消息有几种方式？</h1><p>Netty 有两种发送消息的方式：</p>
<ul>
<li>直接写入 Channel 中，消息从 ChannelPipeline 当中尾部开始移动；</li>
<li>写入和 ChannelHandler 绑定的 ChannelHandlerContext 中，消息从ChannelPipeline 中的下一个 ChannelHandler 中移动。</li>
</ul>
<h1 id="13-默认情况-Netty-起多少线程？何时启动？"><a href="#13-默认情况-Netty-起多少线程？何时启动？" class="headerlink" title="13.默认情况 Netty 起多少线程？何时启动？"></a>13.默认情况 Netty 起多少线程？何时启动？</h1><p>Netty 默认是 CPU 处理器数的两倍，bind 完之后启动。</p>
<h1 id="14-了解哪几种序列化协议？"><a href="#14-了解哪几种序列化协议？" class="headerlink" title="14.了解哪几种序列化协议？"></a>14.了解哪几种序列化协议？</h1><p>序列化（编码）是将对象序列化为二进制形式（字节数组），主要用于网络传输、数据持久化等；而反序列化（解码）则是将从网络、磁盘等读取的字节数组还原成原始对象，主要用于网络传输对象的解码，以便完成远程调用。</p>
<p>影响序列化性能的关键因素：序列化后的码流大小（网络带宽的占用）、序列化的性能（CPU资源占用）；是否支持跨语言（异构系统的对接和开发语言切换）。</p>
<p>Java默认提供的序列化：无法跨语言、序列化后的码流太大、序列化的性能差 XML，优点：人机可读性好，可指定元素或特性的名称。缺点：序列化数据只包含数据本身以及类的结构，不包括类型标识和程序集信息；只能序列化公共属性和字段；不能序列化方法；文件庞大，文件格式复杂，传输占带宽。适用场景：当做配置文件存储数据，实时数据转换。</p>
<p>JSON，是一种轻量级的数据交换格式，优点：兼容性高、数据格式比较简单，易于读写、序列化后数据较小，可扩展性好，兼容性好、与XML相比，其协议比较简单，解析速度比较快。缺点：数据的描述性比XML差、不适合性能要求为ms级别的情况、额外空间开销比较大。适用场景（可替代ＸＭＬ）：跨防火墙访问、可调式性要求高、基于Web browser的Ajax请求、传输数据量相对小，实时性要求相对低（例如秒级别）的服务。</p>
<p>Fastjson，采用一种“假定有序快速匹配”的算法。优点：接口简单易用、目前 java语言中  快的json库。缺点：过于注重快，而偏离了“标准”及功能性、代码质量不高，文档不全。适用场景：协议交互、Web输出、Android客户端</p>
<p>Thrift，不仅是序列化协议，还是一个RPC框架。优点：序列化后的体积小, 速度快、支持多种语言和丰富的数据类型、对于数据字段的增删具有较强的兼容性、支持二进制压缩编码。缺点：使用者较少、跨防火墙访问时，不安全、不具有可读性，调试代码时相对困难、不能与其他传输层协议共同使用（例如HTTP）、无法支持向持久层直接读写数据，即不适合做数据持久化序列化协议。适用场景：分布式系统的RPC解决方案</p>
<p>Avro，Hadoop的一个子项目，解决了JSON的冗长和没有IDL的问题。优点：支持丰富的数据类型、简单的动态语言结合功能、具有自我描述属性、提高了数据解析速度、快速可压缩的二进制数据形式、可以实现远程过程调用RPC、支持跨编程语言实现。缺点：对于习惯于静态类型语言的用户不直观。适用场景：在</p>
<p>Hadoop中做Hive、Pig和MapReduce的持久化数据格式。</p>
<p>Protobuf，将数据结构以.proto文件进行描述，通过代码生成工具可以生成对应数据结构的POJO对象和Protobuf相关的方法和属性。优点：序列化后码流小，性能高、结构化数据存储格式（XML JSON等）、通过标识字段的顺序，可以实现协议的前向兼容、结构化的文档更容易管理和维护。缺点：需要依赖于工具生成代码、支持的语言相对较少，官方只支持Java 、C++ 、python。适用场景：对性能要求高的RPC调用、具有良好的跨防火墙的访问属性、适合应用层对象的持久化</p>
<p>其它</p>
<p>protostuff 基于protobuf协议，但不需要配置proto文件，直接导包即可</p>
<p>Jboss marshaling 可以直接序列化java类， 无须实java.io.Serializable接口</p>
<p>Message pack 一个高效的二进制序列化格式</p>
<p>Hessian 采用二进制协议的轻量级remoting onhttp工具</p>
<p>kryo 基于protobuf协议，只支持java语言,需要注册（Registration），然后序列化（Output），反序列化（Input）</p>
<h1 id="15-如何选择序列化协议？"><a href="#15-如何选择序列化协议？" class="headerlink" title="15.如何选择序列化协议？"></a>15.如何选择序列化协议？</h1><p>具体场景</p>
<p>对于公司间的系统调用，如果性能要求在100ms以上的服务，基于XML的SOAP 协议是一个值得考虑的方案。</p>
<p>基于Web browser的Ajax，以及Mobile app与服务端之间的通讯，JSON协议是首选。对于性能要求不太高，或者以动态类型语言为主，或者传输数据载荷很小的的运用场景，JSON也是非常不错的选择。</p>
<p>对于调试环境比较恶劣的场景，采用JSON或XML能够极大的提高调试效率，降低系统开发成本。当对性能和简洁性有极高要求的场景，Protobuf，Thrift，Avro之间具有一定的竞争关系。</p>
<p>对于T级别的数据的持久化应用场景，Protobuf和Avro是首要选择。如果持久化后的数据存储在hadoop子项目里，Avro会是更好的选择。</p>
<p>对于持久层非Hadoop项目，以静态类型语言为主的应用场景，Protobuf会更符合静态类型语言工程师的开发习惯。由于Avro的设计理念偏向于动态类型语言，对于动态语言为主的应用场景，Avro是更好的选择。</p>
<p>如果需要提供一个完整的RPC解决方案，Thrift是一个好的选择。</p>
<p>如果序列化之后需要支持不同的传输层协议，或者需要跨防火墙访问的高性能场景，Protobuf可以优先考虑。</p>
<p>protobuf的数据类型有多种：bool、double、float、int32、int64、string、 bytes、enum、message。protobuf的限定符：required: 必须赋值，不能为</p>
<p>空、optional:字段可以赋值，也可以不赋值、repeated: 该字段可以重复任意次数（包括0次）、枚举；只能用指定的常量集中的一个值作为其值；</p>
<p>protobuf的基本规则：每个消息中必须至少留有一个required类型的字段、包含0个或多个optional类型的字段；repeated表示的字段可以包含0个或多个数据；[1,15]之内的标识号在编码的时候会占用一个字节（常用），[16,2047]之内的标识号则占用2个字节，标识号一定不能重复、使用消息类型，也可以将消息嵌套任意多层，可用嵌套消息类型来代替组。</p>
<p>protobuf的消息升级原则：不要更改任何已有的字段的数值标识；不能移除已经存在的required字段，optional和repeated类型的字段可以被移除，但要保留标号不能被重用。新添加的字段必须是optional或repeated。因为旧版本程序无法读取或写入新增的required限定符的字段。</p>
<p>编译器为每一个消息类型生成了一个.java文件，以及一个特殊的Builder类（该类是用来创建消息类接口的）。如：UserProto.User.Builder builder &#x3D; </p>
<p>UserProto.User.newBuilder();builder.build()；</p>
<p>Netty中的使用：ProtobufVarint32FrameDecoder 是用于处理半包消息的解码类；ProtobufDecoder(UserProto.User.getDefaultInstance())这是创建的 UserProto.java文件中的解码类；ProtobufVarint32LengthFieldPrepender 对protobuf协议的消息头上加上一个长度为32的整形字段，用于标志这个消息的长度的类；ProtobufEncoder 是编码类将StringBuilder转换为ByteBuf类型：copiedBuffer()方法</p>
<h1 id="16-Netty-支持哪些心跳类型设置？"><a href="#16-Netty-支持哪些心跳类型设置？" class="headerlink" title="16.Netty 支持哪些心跳类型设置？"></a>16.Netty 支持哪些心跳类型设置？</h1><ul>
<li>readerIdleTime：为读超时时间（即测试端一定时间内未接受到被测试端消息）。</li>
<li>writerIdleTime：为写超时时间（即测试端一定时间内向被测试端发送消息）。</li>
<li>allIdleTime：所有类型的超时时间。</li>
</ul>
<h1 id="17-Netty-和-Tomcat-的区别？"><a href="#17-Netty-和-Tomcat-的区别？" class="headerlink" title="17.Netty 和 Tomcat 的区别？"></a>17.Netty 和 Tomcat 的区别？</h1><ul>
<li>作用不同：Tomcat 是 Servlet 容器，可以视为 Web 服务器，而 Netty 是异步事件驱动的网络应用程序框架和工具用于简化网络编程，例如TCP和UDP套接字服务器。</li>
<li>协议不同：Tomcat 是基于 http 协议的 Web 服务器，而 Netty 能通过编程自定义各种协议，因为 Netty 本身自己能编码&#x2F;解码字节流，所有 Netty 可以实现， HTTP 服务器、FTP 服务器、UDP 服务器、RPC 服务器、WebSocket 服务器、 Redis 的 Proxy 服务器、MySQL 的 Proxy 服务器等等。</li>
</ul>
<h1 id="18-NIOEventLoopGroup源码？"><a href="#18-NIOEventLoopGroup源码？" class="headerlink" title="18.NIOEventLoopGroup源码？"></a>18.NIOEventLoopGroup源码？</h1><p>NioEventLoopGroup(其实是MultithreadEventExecutorGroup) 内部维护一个类型为 EventExecutor children [], 默认大小是处理器核数 * 2, 这样就构成了一个线程池，初始化EventExecutor时NioEventLoopGroup重载newChild方法，所以children元素的实际类型为NioEventLoop。</p>
<p>线程启动时调用SingleThreadEventExecutor的构造方法，执行NioEventLoop 类的run方法，首先会调用hasTasks()方法判断当前taskQueue是否有元素。如果taskQueue中有元素，执行 selectNow() 方法，   终执行 selector.selectNow()，该方法会立即返回。如果taskQueue没有元素，执行 select(oldWakenUp) 方法</p>
<p>select ( oldWakenUp) 方法解决了 Nio 中的 bug，selectCnt 用来记录 selector.select方法的执行次数和标识是否执行过selector.selectNow()，若触发了epoll的空轮询bug，则会反复执行selector.select(timeoutMillis)，变量 selectCnt 会逐渐变大，当selectCnt 达到阈值（默认512），则执行 rebuildSelector方法，进行selector重建，解决cpu占用100%的bug。</p>
<p>rebuildSelector方法先通过openSelector方法创建一个新的selector。然后将</p>
<p>old selector的selectionKey执行cancel。   后将old selector的channel重新注册到新的selector中。rebuild后，需要重新执行方法selectNow，检查是否有已ready的selectionKey。</p>
<p>接下来调用processSelectedKeys 方法（处理I&#x2F;O任务），当selectedKeys !&#x3D; null时，调用processSelectedKeysOptimized方法，迭代 selectedKeys 获取就绪的 IO 事件的selectkey存放在数组selectedKeys中, 然后为每个事件都调用 processSelectedKey 来处理它，processSelectedKey 中分别处理OP_READ； OP_WRITE；OP_CONNECT事件。</p>
<p>后调用runAllTasks方法（非IO任务），该方法首先会调用</p>
<p>fetchFromScheduledTaskQueue方法，把scheduledTaskQueue中已经超过延迟执行时间的任务移到taskQueue中等待被执行，然后依次从taskQueue中取任务执行，每执行64个任务，进行耗时检查，如果已执行时间超过预先设定的执行时间，则停止执行非IO任务，避免非IO任务太多，影响IO任务的执行。每个NioEventLoop对应一个线程和一个Selector，NioServerSocketChannel 会主动注册到某一个NioEventLoop的Selector上，NioEventLoop负责事件轮询。</p>
<p>Outbound 事件都是请求事件, 发起者是 Channel，处理者是 unsafe，通过 Outbound 事件进行通知，传播方向是 tail到head。Inbound 事件发起者是 unsafe，事件的处理者是 Channel, 是通知事件，传播方向是从头到尾。内存管理机制，首先会预申请一大块内存Arena，Arena由许多Chunk组成，而每个Chunk默认由2048个page组成。Chunk通过AVL树的形式组织Page，每个叶子节点表示一个Page，而中间节点表示内存区域，节点自己记录它在整个 Arena中的偏移地址。当区域被分配出去后，中间节点上的标记位会被标记，这样就表示这个中间节点以下的所有节点都已被分配了。大于8k的内存分配在</p>
<p>poolChunkList中，而PoolSubpage用于分配小于8k的内存，它会把一个page 分割成多段，进行内存分配。</p>
<p>ByteBuf的特点：支持自动扩容（4M），保证put方法不会抛出异常、通过内置的复合缓冲类型，实现零拷贝（zero-copy）；不需要调用flip()来切换读&#x2F;写模</p>
<p>式，读取和写入索引分开；方法链；引用计数基于AtomicIntegerFieldUpdater 用于内存回收；PooledByteBuf采用二叉树来实现一个内存池，集中管理内存的分配和释放，不用每次使用都新建一个缓冲区对象。UnpooledHeapByteBuf每次都会新建一个缓冲区对象。</p>
<h1 id="Netty简介"><a href="#Netty简介" class="headerlink" title="Netty简介"></a>Netty简介</h1><p><img src="/16-Netty%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%882020%E6%9C%80%E6%96%B0%E7%89%88%EF%BC%89.assets/Netty.png" alt="Netty"></p>
<p>Netty是 一个异步事件驱动的网络应用程(img)序框架，用于快速开发可维护的高性能协议服务器和客户端。</p>
<h2 id="JDK原生NIO程序的问题"><a href="#JDK原生NIO程序的问题" class="headerlink" title="JDK原生NIO程序的问题"></a>JDK原生NIO程序的问题</h2><p>JDK原生也有一套网络应用程序API，但是存在一系列问题，主要如下：</p>
<ul>
<li>NIO的类库和API繁杂，使用麻烦，你需要熟练掌握Selector、ServerSocketChannel、SocketChannel、ByteBuffer等</li>
<li>需要具备其它的额外技能做铺垫，例如熟悉Java多线程编程，因为NIO编程涉及到Reactor模式，你必须对多线程和网路编程非常熟悉，才能编写出高质量的NIO程序</li>
<li>可靠性能力补齐，开发工作量和难度都非常大。例如客户端面临断连重连、网络闪断、半包读写、失败缓存、网络拥塞和异常码流的处理等等，NIO编程的特点是功能开发相对容易，但是可靠性能力补齐工作量和难度都非常大</li>
<li>JDK NIO的BUG，例如臭名昭著的epoll bug，它会导致Selector空轮询，  终导致CPU 100%。官方声称在JDK1.6版本的update18修复了该问题，但是直到</li>
<li>JDK1.7版本该问题仍旧存在，只不过该bug发生概率降低了一些而已，它并没有被根本解决</li>
</ul>
<h2 id="Netty的特点"><a href="#Netty的特点" class="headerlink" title="Netty的特点"></a>Netty的特点</h2><ul>
<li>Netty的对JDK自带的NIO的API进行封装，解决上述问题，主要特点有：</li>
<li>设计优雅 适用于各种传输类型的统一API - 阻塞和非阻塞Socket 基于灵活且可扩展的事件模型，可以清晰地分离关注点 高度可定制的线程模型 - 单线程，一个或多个线程池 真正的无连接数据报套接字支持（自3.1起）</li>
<li>使用方便 详细记录的Javadoc，用户指南和示例 没有其他依赖项，JDK 5（Netty 3.x）或6（Netty 4.x）就足够了</li>
<li>高性能 吞吐量更高，延迟更低 减少资源消耗   小化不必要的内存复制安全 完整的SSL &#x2F; TLS和StartTLS支持</li>
<li>社区活跃，不断更新 社区活跃，版本迭代周期短，发现的BUG可以被及时修复，同时，更多的新功能会被加入</li>
</ul>
<h2 id="Netty常见使用场景"><a href="#Netty常见使用场景" class="headerlink" title="Netty常见使用场景"></a>Netty常见使用场景</h2><p>Netty常见的使用场景如下：</p>
<ul>
<li>互联网行业 在分布式系统中，各个节点之间需要远程服务调用，高性能的RPC 框架必不可少，Netty作为异步高新能的通信框架,往往作为基础通信组件被这些RPC 框架使用。 典型的应用有：阿里分布式服务框架Dubbo的RPC框架使用Dubbo协议进行节点间通信，Dubbo协议默认使用Netty作为基础通信组件，用于实现各进程节点之间的内部通信。</li>
<li>游戏行业 无论是手游服务端还是大型的网络游戏，Java语言得到了越来越广泛的应用。Netty作为高性能的基础通信组件，它本身提供了TCP&#x2F;UDP和HTTP协议栈。 非常方便定制和开发私有协议栈，账号登录服务器，地图服务器之间可以方便的通过Netty进行高性能的通信</li>
<li>大数据领域 经典的Hadoop的高性能通信和序列化组件Avro的RPC框架，默认采用Netty进行跨界点通信，它的Netty Service基于Netty框架二次封装实现有兴趣的读者可以了解一下目前有哪些开源项目使用了 Netty：Related projects</li>
</ul>
<h1 id="Netty高性能设计"><a href="#Netty高性能设计" class="headerlink" title="Netty高性能设计"></a>Netty高性能设计</h1><p>Netty作为异步事件驱动的网络，高性能之处主要来自于其I&#x2F;O模型和线程处理模型，前者决定如何收发数据，后者决定如何处理数据</p>
<h2 id="I-x2F-O模型"><a href="#I-x2F-O模型" class="headerlink" title="I&#x2F;O模型"></a>I&#x2F;O模型</h2><p>用什么样的通道将数据发送给对方，BIO、NIO或者AIO，I&#x2F;O模型在很大程度上决定了框架的性能阻塞I&#x2F;O 传统阻塞型I&#x2F;O(BIO)可以用下图表示：<img src="/16-Netty%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%882020%E6%9C%80%E6%96%B0%E7%89%88%EF%BC%89.assets/IO%E6%A8%A1%E5%9E%8B.jpg" alt="IO模型"></p>
<p>特点</p>
<p> 每个请求都需要独立的线程完成数据read，业务处理，数据write的完整操作问题</p>
<p>当并发数较大时，需要创建大量线程来处理连接，系统资源占用较大</p>
<p>连接建立后，如果当前线程暂时没有数据可读，则线程就阻塞在read操作上，造成线程资源浪费</p>
<h3 id="I-x2F-O复用模型"><a href="#I-x2F-O复用模型" class="headerlink" title="I&#x2F;O复用模型"></a>I&#x2F;O复用模型</h3><p><img src="/16-Netty%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%882020%E6%9C%80%E6%96%B0%E7%89%88%EF%BC%89.assets/IO%E5%A4%8D%E7%94%A8%E6%A8%A1%E5%9E%8B.jpg" alt="IO复用模型"></p>
<p>在I&#x2F;O复用模型中，会用到select，这个函数也会使进程阻塞，但是和阻塞I&#x2F;O所不同的的，这两个函数可以同时阻塞多个I&#x2F;O操作，而且可以同时对多个读操作，多个写操作的I&#x2F;O函数进行检测，直到有数据可读或可写时，才真正调用</p>
<p>I&#x2F;O操作函数</p>
<p>Netty的非阻塞I&#x2F;O的实现关键是基于I&#x2F;O复用模型，这里用Selector对象表示：</p>
<p>![Nonblocking IO](16-Netty面试题（2020最新版）.assets&#x2F;Nonblocking IO.jpg)</p>
<p>Netty的IO线程NioEventLoop由于聚合了多路复用器Selector，可以同时并发处理成百上千个客户端连接。当线程从某客户端Socket通道进行读写数据时，若没有数据可用时，该线程可以进行其他任务。线程通常将非阻塞 IO 的空闲时间用于在其他通道上执行 IO 操作，所以单独的线程可以管理多个输入和输出通道。</p>
<p>由于读写操作都是非阻塞的，这就可以充分提升IO线程的运行效率，避免由于频繁I&#x2F;O阻塞导致的线程挂起，一个I&#x2F;O线程可以并发处理N个客户端连接和读写操作，这从根本上解决了传统同步阻塞I&#x2F;O一连接一线程模型，架构的性能、弹性伸缩能力和可靠性都得到了极大的提升。</p>
<h3 id="基于buffer"><a href="#基于buffer" class="headerlink" title="基于buffer"></a>基于buffer</h3><p>传统的I&#x2F;O是面向字节流或字符流的，以流式的方式顺序地从一个Stream 中读取一个或多个字节, 因此也就不能随意改变读取指针的位置。</p>
<p>在NIO中, 抛弃了传统的 I&#x2F;O流, 而是引入了Channel和Buffer的概念. 在NIO中, </p>
<p>只能从Channel中读取数据到Buffer中或将数据 Buffer 中写入到 Channel。</p>
<p>基于buffer操作不像传统IO的顺序操作, NIO 中可以随意地读取任意位置的数据线程模型</p>
<p>数据报如何读取？读取之后的编解码在哪个线程进行，编解码后的消息如何派发，线程模型的不同，对性能的影响也非常大。</p>
<h3 id="事件驱动模型"><a href="#事件驱动模型" class="headerlink" title="事件驱动模型"></a>事件驱动模型</h3><p>通常，我们设计一个事件处理模型的程序有两种思路</p>
<p> 轮询方式 线程不断轮询访问相关事件发生源有没有发生事件，有发生事件就调用事件处理逻辑。</p>
<p> 事件驱动方式 发生事件，主线程把事件放入事件队列，在另外线程不断循环消费事件列表中的事件，调用事件对应的处理逻辑处理事件。事件驱动方式也被称为消息通知方式，其实是设计模式中观察者模式的思路。</p>
<p>以GUI的逻辑处理为例，说明两种逻辑的不同：</p>
<p>轮询方式 线程不断轮询是否发生按钮点击事件，如果发生，调用处理逻辑</p>
<p>事件驱动方式 发生点击事件把事件放入事件队列，在另外线程消费的事件列表中的事件，根据事件类型调用相关事件处理逻辑这里借用O’Reilly 大神关于事件驱动模型解释图</p>
<p><img src="/16-Netty%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%882020%E6%9C%80%E6%96%B0%E7%89%88%EF%BC%89.assets/%E4%BA%8B%E4%BB%B6%E9%A9%B1%E5%8A%A8%E6%A8%A1%E5%9E%8B.jpg" alt="事件驱动模型"></p>
<p>主要包括4个基本组件：</p>
<ul>
<li>事件队列（event queue）：接收事件的入口，存储待处理事件</li>
<li>分发器（event mediator）：将不同的事件分发到不同的业务逻辑单元</li>
<li>事件通道（event channel）：分发器与处理器之间的联系渠道</li>
<li>事件处理器（event processor）：实现业务逻辑，处理完成后会发出事件，触发下一步操作</li>
</ul>
<p>可以看出，相对传统轮询模式，事件驱动有如下优点：</p>
<ul>
<li>可扩展性好，分布式的异步架构，事件处理器之间高度解耦，可以方便扩展事件处理逻辑</li>
<li>高性能，基于队列暂存事件，能方便并行异步处理事件</li>
</ul>
<h3 id="Reactor线程模型"><a href="#Reactor线程模型" class="headerlink" title="Reactor线程模型"></a>Reactor线程模型</h3><p>Reactor是反应堆的意思，Reactor模型，是指通过一个或多个输入同时传递给服务处理器的服务请求的事件驱动处理模式。 服务端程序处理传入多路请求，并将它们同步分派给请求对应的处理线程，Reactor模式也叫Dispatcher模式，即I&#x2F;O多了复用统一监听事件，收到事件后分发(Dispatch给某进程)，是编写高性能网络服务器的必备技术之一。</p>
<p>Reactor模型中有2个关键组成：</p>
<ul>
<li>Reactor Reactor在一个单独的线程中运行，负责监听和分发事件，分发给适当的处理程序来对IO事件做出反应。 它就像公司的电话接线员，它接听来自客户的电话并将线路转移到适当的联系人</li>
<li>Handlers 处理程序执行I&#x2F;O事件要完成的实际事件，类似于客户想要与之交谈的公司中的实际官员。Reactor通过调度适当的处理程序来响应I&#x2F;O事件，处理程序执行非阻塞操作</li>
</ul>
<p><img src="/16-Netty%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%882020%E6%9C%80%E6%96%B0%E7%89%88%EF%BC%89.assets/Reactor.jpg" alt="Reactor"></p>
<p>取决于Reactor的数量和Hanndler线程数量的不同，Reactor模型有3个变种</p>
<ul>
<li>单Reactor单线程</li>
<li>单Reactor多线程</li>
<li>主从Reactor多线程</li>
</ul>
<p>可以这样理解，Reactor就是一个执行while (true) { selector.select(); …}循环的线程，会源源不断的产生新的事件，称作反应堆很贴切。</p>
<h3 id="Netty线程模型"><a href="#Netty线程模型" class="headerlink" title="Netty线程模型"></a>Netty线程模型</h3><p>Netty主要基于主从Reactors多线程模型（如下图）做了一定的修改，其中主从</p>
<p>Reactor多线程模型有多个Reactor：MainReactor和SubReactor：</p>
<p>MainReactor负责客户端的连接请求，并将请求转交给SubReactor SubReactor负责相应通道的IO读写请求</p>
<p>非IO请求（具体逻辑处理）的任务则会直接写入队列，等待worker threads进</p>
<p>行处理</p>
<p>这里引用Doug Lee大神的Reactor介绍：Scalable IO in Java里面关于主从 Reactor多线程模型的图</p>
<p><img src="/16-Netty%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%882020%E6%9C%80%E6%96%B0%E7%89%88%EF%BC%89.assets/Reactor%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B.jpg" alt="Reactor多线程模型"></p>
<p>特别说明的是： 虽然Netty的线程模型基于主从Reactor多线程，借用了</p>
<p>MainReactor和SubReactor的结构，但是实际实现上，SubReactor和Worker 线程在同一个线程池中：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1	EventLoopGroup bossGroup =newNioEventLoopGroup();</span><br><span class="line">2	EventLoopGroup workerGroup =newNioEventLoopGroup();</span><br><span class="line">3	ServerBootstrap server =newServerBootstrap();</span><br><span class="line">4	server.group(bossGroup, workerGroup).channel(NioServerSocketChannel.class)</span><br></pre></td></tr></table></figure>

<ul>
<li>bossGroup线程池则只是在bind某个端口后，获得其中一个线程作为MainReactor，专门处理端口的accept事件，<strong>每个端口对应一个boss线程</strong>   </li>
<li>workerGroup线程池会被各个SubReactor和worker线程充分利用</li>
</ul>
<h2 id="异步处理"><a href="#异步处理" class="headerlink" title="异步处理"></a>异步处理</h2><p>异步的概念和同步相对。当一个异步过程调用发出后，调用者不能立刻得到结果。实际处理这个调用的部件在完成后，通过状态、通知和回调来通知调用者。</p>
<p>Netty中的I&#x2F;O操作是异步的，包括bind、write、connect等操作会简单的返回一个ChannelFuture，调用者并不能立刻获得结果，通过Future-Listener机制，用户可以方便的主动获取或者通过通知机制获得IO操作结果。</p>
<p>当future对象刚刚创建时，处于非完成状态，调用者可以通过返回的ChannelFuture来获取操作执行的状态，注册监听函数来执行完成后的操，常见有如下操作：</p>
<ul>
<li>通过isDone方法来判断当前操作是否完成</li>
<li>通过isSuccess方法来判断已完成的当前操作是否成功</li>
<li>通过getCause方法来获取已完成的当前操作失败的原因</li>
<li>通过isCancelled方法来判断已完成的当前操作是否被取消</li>
<li>通过addListener方法来注册监听器，当操作已完成(isDone方法返回完成)，将会通知指定的监听器；如果future对象已完成，则理解通知指定的监听器</li>
</ul>
<p>例如下面的的代码中绑定端口是异步操作，当绑定操作处理完，将会调用相应的监听器处理逻辑</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1 serverBootstrap.bind(port).addListener(future ‐&gt; &#123;</span><br><span class="line">2 if (future.isSuccess()) &#123;</span><br><span class="line">3 System.out.println(new Date() + &quot;: 端口[&quot; + port + &quot;]绑定成功!&quot;);</span><br><span class="line">4 &#125; else &#123;</span><br><span class="line">5 System.err.println(&quot;端口[&quot; + port + &quot;]绑定失败!&quot;);</span><br><span class="line">6 &#125;</span><br><span class="line">7 &#125;);</span><br></pre></td></tr></table></figure>

<p>相比传统阻塞I&#x2F;O，执行I&#x2F;O操作后线程会被阻塞住, 直到操作完成；异步处理的 好处是不会造成线程阻塞，线程在I&#x2F;O操作期间可以执行别的程序，在高并发情 形下会更稳定和更高的吞吐量。</p>
<h1 id="Netty架构设计"><a href="#Netty架构设计" class="headerlink" title="Netty架构设计"></a>Netty架构设计</h1><p>前面介绍完Netty相关一些理论介绍，下面从功能特性、模块组件、运作过程来介绍Netty的架构设计功能特性</p>
<p><img src="/16-Netty%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%882020%E6%9C%80%E6%96%B0%E7%89%88%EF%BC%89.assets/Netty%E5%8A%9F%E8%83%BD%E7%89%B9%E6%80%A7%E5%9B%BE.jpg" alt="Netty功能特性图"></p>
<ul>
<li>传输服务 支持BIO和NIO</li>
<li>容器集成 支持OSGI、JBossMC、Spring、Guice容器</li>
<li>协议支持 HTTP、Protobuf、二进制、文本、WebSocket等一系列常见协议都支持。 还支持通过实行编码解码逻辑来实现自定义协议</li>
<li>Core核心 可扩展事件模型、通用通信API、支持零拷贝的ByteBuf缓冲对象</li>
</ul>
<p>模块组件</p>
<h2 id="Bootstrap、ServerBootstrap"><a href="#Bootstrap、ServerBootstrap" class="headerlink" title="Bootstrap、ServerBootstrap"></a>Bootstrap、ServerBootstrap</h2><p>Bootstrap意思是引导，一个Netty应用通常由一个Bootstrap开始，主要作用是配置整个Netty程序，串联各个组件，Netty中Bootstrap类是客户端程序的启动引导类，ServerBootstrap是服务端启动引导类。</p>
<h2 id="Future、ChannelFuture"><a href="#Future、ChannelFuture" class="headerlink" title="Future、ChannelFuture"></a>Future、ChannelFuture</h2><p>正如前面介绍，在Netty中所有的IO操作都是异步的，不能立刻得知消息是否被正确处理，但是可以过一会等它执行完成或者直接注册一个监听，具体的实现就是通过Future和ChannelFutures，他们可以注册一个监听，当操作执行成功或失败时监听会自动触发注册的监听事件。</p>
<h2 id="Channel"><a href="#Channel" class="headerlink" title="Channel"></a>Channel</h2><p>Netty网络通信的组件，能够用于执行网络I&#x2F;O操作。 Channel为用户提供：</p>
<ul>
<li>当前网络连接的通道的状态（例如是否打开？是否已连接？）</li>
<li>网络连接的配置参数 （例如接收缓冲区大小）</li>
<li>提供异步的网络I&#x2F;O操作(如建立连接，读写，绑定端口)，异步调用意味着任何I &#x2F; O调用都将立即返回，并且不保证在调用结束时所请求的I &#x2F; O操作已完成。调用立即返回一个ChannelFuture实例，通过注册监听器到ChannelFuture上，可以I &#x2F; O操作成功、失败或取消时回调通知调用方。</li>
<li>支持关联I&#x2F;O操作与对应的处理程序</li>
</ul>
<p>不同协议、不同的阻塞类型的连接都有不同的 Channel 类型与之对应，下面是一些常用的 Channel 类型</p>
<ul>
<li>NioSocketChannel，异步的客户端 TCP Socket 连接</li>
<li>NioServerSocketChannel，异步的服务器端 TCP Socket 连接</li>
<li>NioDatagramChannel，异步的 UDP 连接</li>
<li>NioSctpChannel，异步的客户端 Sctp 连接</li>
<li>NioSctpServerChannel，异步的 Sctp 服务器端连接 这些通道涵盖了 UDP 和 TCP网络 IO以及文件 IO.</li>
</ul>
<h2 id="Selector"><a href="#Selector" class="headerlink" title="Selector"></a>Selector</h2><p>Netty基于Selector对象实现I&#x2F;O多路复用，通过 Selector, 一个线程可以监听多个连接的Channel事件, 当向一个Selector中注册Channel 后，Selector 内部的机制就可以自动不断地查询(select) 这些注册的Channel是否有已就绪的I&#x2F;O事件(例如可读, 可写, 网络连接完成等)，这样程序就可以很简单地使用一个线程高效地管理多个 Channel 。</p>
<h2 id="NioEventLoop"><a href="#NioEventLoop" class="headerlink" title="NioEventLoop"></a>NioEventLoop</h2><p>NioEventLoop中维护了一个线程和任务队列，支持异步提交执行任务，线程启动时会调用NioEventLoop的run方法，执行I&#x2F;O任务和非I&#x2F;O任务：</p>
<ul>
<li>I&#x2F;O任务 即selectionKey中ready的事件，如accept、connect、read、write等，由processSelectedKeys方法触发。</li>
<li>非IO任务 添加到taskQueue中的任务，如register0、bind0等任务，由runAllTasks方法触发。</li>
</ul>
<p>两种任务的执行时间比由变量ioRatio控制，默认为50，则表示允许非IO任务执行的时间与IO任务的执行时间相等。</p>
<h2 id="NioEventLoopGroup"><a href="#NioEventLoopGroup" class="headerlink" title="NioEventLoopGroup"></a>NioEventLoopGroup</h2><p>NioEventLoopGroup，主要管理eventLoop的生命周期，可以理解为一个线程池，内部维护了一组线程，每个线程(NioEventLoop)负责处理多个Channel上的事件，而一个Channel只对应于一个线程。 ChannelHandler</p>
<p>ChannelHandler是一个接口，处理I &#x2F; O事件或拦截I &#x2F; O操作，并将其转发到其 ChannelPipeline(业务处理链)中的下一个处理程序。</p>
<p>ChannelHandler本身并没有提供很多方法，因为这个接口有许多的方法需要实现，方便使用期间，可以继承它的子类：</p>
<ul>
<li>ChannelInboundHandler用于处理入站I &#x2F; O事件</li>
<li>ChannelOutboundHandler用于处理出站I &#x2F; O操作</li>
</ul>
<p>或者使用以下适配器类：</p>
<ul>
<li>ChannelInboundHandlerAdapter用于处理入站I &#x2F; O事件</li>
<li>ChannelOutboundHandlerAdapter用于处理出站I &#x2F; O操作</li>
<li>ChannelDuplexHandler用于处理入站和出站事件</li>
</ul>
<p>ChannelHandlerContext 保存Channel相关的所有上下文信息，同时关联一个ChannelHandler对象 ChannelPipline</p>
<p>保存ChannelHandler的List，用于处理或拦截Channel的入站事件和出站操作。 ChannelPipeline实现了一种高级形式的拦截过滤器模式，使用户可以完全控制事件的处理方式，以及Channel中各个的ChannelHandler如何相互交互。</p>
<p>下图引用Netty的Javadoc4.1中ChannelPipline的说明，描述了 ChannelPipeline中ChannelHandler通常如何处理I&#x2F;O事件。 I&#x2F;O事件由</p>
<p>ChannelInboundHandler或ChannelOutboundHandler处理，并通过调用</p>
<p>ChannelHandlerContext中定义的事件传播方法（例如</p>
<p>ChannelHandlerContext.fireChannelRead（Object）和</p>
<p>ChannelOutboundInvoker.write（Object））转发到其 近的处理程序。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">1   I/O Request</span><br><span class="line">2   via Channel or</span><br><span class="line">3   ChannelHandlerContext</span><br><span class="line">4   |</span><br><span class="line">5   +‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐+‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐+</span><br><span class="line">6   | ChannelPipeline | |</span><br><span class="line">7   | \|/ |</span><br><span class="line">8   | +‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐+ +‐‐‐‐‐‐‐‐‐‐‐+‐‐‐‐‐‐‐‐‐‐+ |</span><br><span class="line">9   | | Inbound Handler N | | Outbound Handler 1 | |</span><br><span class="line">10   | +‐‐‐‐‐‐‐‐‐‐+‐‐‐‐‐‐‐‐‐‐+ +‐‐‐‐‐‐‐‐‐‐‐+‐‐‐‐‐‐‐‐‐‐+ |</span><br><span class="line">11   | /|\ | |</span><br><span class="line">12   | | \|/ |</span><br><span class="line">13   | +‐‐‐‐‐‐‐‐‐‐+‐‐‐‐‐‐‐‐‐‐+ +‐‐‐‐‐‐‐‐‐‐‐+‐‐‐‐‐‐‐‐‐‐+ |</span><br><span class="line">14   | | Inbound Handler N‐1 | | Outbound Handler 2 | |</span><br><span class="line">15   | +‐‐‐‐‐‐‐‐‐‐+‐‐‐‐‐‐‐‐‐‐+ +‐‐‐‐‐‐‐‐‐‐‐+‐‐‐‐‐‐‐‐‐‐+ |</span><br><span class="line">16   | /|\ . |</span><br><span class="line">17   | . . |</span><br><span class="line">18   | ChannelHandlerContext.fireIN_EVT() ChannelHandlerContext.OUT_EVT()|</span><br><span class="line">19   | [ method call] [method call] |</span><br><span class="line">20   | . . |</span><br><span class="line">21   | . \|/ |</span><br><span class="line">22   | +‐‐‐‐‐‐‐‐‐‐+‐‐‐‐‐‐‐‐‐‐+ +‐‐‐‐‐‐‐‐‐‐‐+‐‐‐‐‐‐‐‐‐‐+ |</span><br><span class="line">23   | | Inbound Handler 2 | | Outbound Handler M‐1 | |</span><br><span class="line">24   | +‐‐‐‐‐‐‐‐‐‐+‐‐‐‐‐‐‐‐‐‐+ +‐‐‐‐‐‐‐‐‐‐‐+‐‐‐‐‐‐‐‐‐‐+ |</span><br><span class="line">25   | /|\ | |</span><br><span class="line">26   | | \|/ |</span><br><span class="line">27   | +‐‐‐‐‐‐‐‐‐‐+‐‐‐‐‐‐‐‐‐‐+ +‐‐‐‐‐‐‐‐‐‐‐+‐‐‐‐‐‐‐‐‐‐+ |</span><br><span class="line">28   | | Inbound Handler 1 | | Outbound Handler M | |</span><br><span class="line">29   | +‐‐‐‐‐‐‐‐‐‐+‐‐‐‐‐‐‐‐‐‐+ +‐‐‐‐‐‐‐‐‐‐‐+‐‐‐‐‐‐‐‐‐‐+ </span><br><span class="line">30   | /|\ | |</span><br><span class="line">31   +‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐+‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐+‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐+</span><br><span class="line">32   | \|/</span><br><span class="line">33   +‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐+‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐+‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐+</span><br><span class="line">34   | | | |</span><br><span class="line">35   | [ Socket.read() ] [ Socket.write() ] |</span><br><span class="line">36   | |</span><br><span class="line">37   | Netty Internal I/O Threads (Transport Implementation) |</span><br><span class="line">38   +‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐+ 39</span><br><span class="line">40</span><br></pre></td></tr></table></figure>

<p>入站事件由自下而上方向的入站处理程序处理，如图左侧所示。 入站Handler处理程序通常处理由图底部的I &#x2F; O线程生成的入站数据。 通常通过实际输入操作（例如SocketChannel.read（ByteBuffer））从远程读取入站数据。</p>
<p>出站事件由上下方向处理，如图右侧所示。 出站Handler处理程序通常会生成或转换出站传输，例如write请求。 I&#x2F;O线程通常执行实际的输出操作，例如SocketChannel.write（ByteBuffer）。</p>
<p>在 Netty 中每个 Channel 都有且仅有一个 ChannelPipeline 与之对应, 它们的组成关系如下:</p>
<p><img src="/16-Netty%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%882020%E6%9C%80%E6%96%B0%E7%89%88%EF%BC%89.assets/Channel.jpg" alt="Channel"></p>
<p>一个 Channel 包含了一个 ChannelPipel(img)ine, 而 ChannelPipeline 中又维护了</p>
<p>一个由 ChannelHandlerContext 组成的双向链表, 并且每个 </p>
<p>ChannelHandlerContext 中又关联着一个 ChannelHandler。入站事件和出站</p>
<p>事件在一个双向链表中，入站事件会从链表head往后传递到  后一个入站的</p>
<p>handler，出站事件会从链表tail往前传递到   前一个出站的handler，两种类型的handler互不干扰。</p>
<h2 id="工作原理架构"><a href="#工作原理架构" class="headerlink" title="工作原理架构"></a>工作原理架构</h2><p>初始化并启动Netty服务端过程如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">1	public static void main(String[] args) &#123;</span><br><span class="line">2	// 创建mainReactor</span><br><span class="line">3	NioEventLoopGroup boosGroup = new NioEventLoopGroup();</span><br><span class="line">4	// 创建工作线程组</span><br><span class="line">5	NioEventLoopGroup workerGroup = new NioEventLoopGroup();</span><br><span class="line">6</span><br><span class="line">7	final ServerBootstrap serverBootstrap = new ServerBootstrap();</span><br><span class="line">8	serverBootstrap</span><br><span class="line">9	// 组装NioEventLoopGroup</span><br><span class="line">10	.group(boosGroup, workerGroup)</span><br><span class="line">11	// 设置channel类型为NIO类型</span><br><span class="line">12	.channel(NioServerSocketChannel.class)</span><br><span class="line">13	// 设置连接配置参数</span><br><span class="line">14	.option(ChannelOption.SO_BACKLOG, 1024)</span><br><span class="line">15	.childOption(ChannelOption.SO_KEEPALIVE, true)</span><br><span class="line">16	.childOption(ChannelOption.TCP_NODELAY, true)</span><br><span class="line">17	// 配置入站、出站事件handler</span><br><span class="line">18	.childHandler(new ChannelInitializer&lt;NioSocketChannel&gt;() &#123;</span><br><span class="line">19	@Override</span><br><span class="line">20	protected void initChannel(NioSocketChannel ch) &#123;</span><br><span class="line">21	// 配置入站、出站事件channel</span><br><span class="line">22	ch.pipeline().addLast(...); 23 ch.pipeline().addLast(...);</span><br><span class="line">24	&#125;</span><br><span class="line">25	&#125;);</span><br><span class="line">26</span><br><span class="line">27	// 绑定端口</span><br><span class="line">28	int port = 8080;</span><br><span class="line">‐&gt;</span><br><span class="line">29	serverBootstrap.bind(port).addListener(future  &#123;</span><br><span class="line">30	if (future.isSuccess()) &#123;</span><br><span class="line">31	System.out.println(new Date() + &quot;: 端口[&quot; + port + &quot;]绑定成功!&quot;);</span><br><span class="line">32	&#125; else &#123;</span><br><span class="line">33	System.err.println(&quot;端口[&quot; + port + &quot;]绑定失败!&quot;);</span><br><span class="line">34	&#125;</span><br><span class="line">35	&#125;);36	&#125;</span><br></pre></td></tr></table></figure>

<p>基本过程如下：</p>
<p>1 初始化创建2个NioEventLoopGroup，其中boosGroup用于Accetpt连接建立事件并分发请求， workerGroup用于处理I&#x2F;O读写事件和业务逻辑</p>
<p>2 基于ServerBootstrap(服务端启动引导类)，配置EventLoopGroup、Channel类型，连接参数、配置入站、出站事件handler</p>
<p>3 绑定端口，开始工作结合上面的介绍的Netty Reactor模型，介绍服务端Netty的工作架构图：</p>
<p><img src="/16-Netty%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%882020%E6%9C%80%E6%96%B0%E7%89%88%EF%BC%89.assets/Netty%E5%B7%A5%E4%BD%9C%E6%9E%B6%E6%9E%84%E5%9B%BE.jpg" alt="Netty工作架构图"></p>
<p>server端包含1个Boss NioEventLoopGroup和1个Worker </p>
<p>NioEventLoopGroup，NioEventLoopGroup相当于1个事件循环组，这个组</p>
<p>里包含多个事件循环NioEventLoop，每个NioEventLoop包含1个selector和1 个事件循环线程。</p>
<p>每个Boss NioEventLoop循环执行的任务包含3步：</p>
<p>1 轮询accept事件</p>
<p>2 处理accept I&#x2F;O事件，与Client建立连接，生成NioSocketChannel，并将NioSocketChannel注册到某个Worker NioEventLoop的Selector上 *3 处理任务队列中的任务，runAllTasks。任务队列中的任务包括用户调用eventloop.execute或 schedule执行的任务，或者其它线程提交到该eventloop的任务。</p>
<p>每个Worker NioEventLoop循环执行的任务包含3步：</p>
<p>1 轮询read、write事件；</p>
<p>2 处I&#x2F;O事件，即read、write事件，在NioSocketChannel可读、可写事件发生</p>
<p>时进行处理</p>
<p>​            3 处理任务队列中的任务，runAllTasks。</p>
<p>其中任务队列中的task有3种典型使用场景</p>
<p>​            1 用户程序自定义的普通任务</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1	ctx.channel().eventLoop().execute(new Runnable() &#123;</span><br><span class="line">2	@Override</span><br><span class="line">3	public void run() &#123; 4 //...</span><br><span class="line">5	&#125;</span><br><span class="line">6	&#125;);</span><br></pre></td></tr></table></figure>

<p> 2 非当前reactor线程调用channel的各种方法 例如在推送系统的业务线程里面，根据用户的标识，找到对应的channel引用，然后调用write类方法向该用户推送消息，就会进入到这种场景。 终的write会提交到任务队列中后被异步消费。</p>
<p>​           3 用户自定义定时任务</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">1	ctx.channel().eventLoop().schedule(new Runnable() &#123;</span><br><span class="line">2	@Override</span><br><span class="line">3	public void run() &#123;</span><br><span class="line">4</span><br><span class="line">5	&#125;</span><br><span class="line">6	&#125;, 60, TimeUnit.SECONDS);</span><br><span class="line">7	</span><br><span class="line">8</span><br></pre></td></tr></table></figure>

<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>现在稳定推荐使用的主流版本还是Netty4，Netty5 中使用了 ForkJoinPool，</p>
<p>增加了代码的复杂度，但是对性能的改善却不明显，所以这个版本不推荐使用，官网也没有提供下载链接。</p>
<p>Netty 入门门槛相对较高，其实是因为这方面的资料较少，并不是因为他有多</p>
<p>难，大家其实都可以像搞透 Spring 一样搞透 Netty。在学习之前，建议先理解透整个框架原理结构，运行过程，可以少走很多弯路。</p>

      
    </div>

    
    
    

       
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/10/12/15-%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6MQ%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%882020%E6%9C%80%E6%96%B0%E7%89%88%EF%BC%89/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="善善332">
      <meta itemprop="description" content="运气和努力一样重要">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="和善寺">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/10/12/15-%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6MQ%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%882020%E6%9C%80%E6%96%B0%E7%89%88%EF%BC%89/" class="post-title-link" itemprop="url">未命名</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-10-12 15:01:16" itemprop="dateCreated datePublished" datetime="2022-10-12T15:01:16+08:00">2022-10-12</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-03-03 13:51:32" itemprop="dateModified" datetime="2021-03-03T13:51:32+08:00">2021-03-03</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="为什么使用MQ？MQ的优点"><a href="#为什么使用MQ？MQ的优点" class="headerlink" title="为什么使用MQ？MQ的优点"></a>为什么使用MQ？MQ的优点</h2><h3 id="简答"><a href="#简答" class="headerlink" title="简答"></a>简答</h3><ul>
<li>异步处理 - 相比于传统的串行、并行方式，提高了系统吞吐量。 </li>
<li>应用解耦 - 系统间通过消息通信，不用关心其他系统的处理。 </li>
<li>流量削锋 - 可以通过消息队列长度控制请求量；可以缓解短时间内的高并发请 求。 </li>
<li>日志处理 - 解决大量日志传输。 </li>
<li>消息通讯 - 消息队列一般都内置了高效的通信机制，因此也可以用在纯的消息通 讯。比如实现点对点消息队列，或者聊天室等。</li>
</ul>
<h3 id="详答"><a href="#详答" class="headerlink" title="详答"></a>详答</h3><p>主要是：解耦、异步、削峰。 </p>
<p><strong>解耦：</strong>A 系统发送数据到 BCD 三个系统，通过接口调用发送。如果 E 系统也要 这个数据呢？那如果 C 系统现在不需要了呢？A 系统负责人几乎崩溃…A 系统 跟其它各种乱七八糟的系统严重耦合，A 系统产生一条比较关键的数据，很多系 统都需要 A 系统将这个数据发送过来。如果使用 MQ，A 系统产生一条数据， 发送到 MQ 里面去，哪个系统需要数据自己去 MQ 里面消费。如果新系统需要 数据，直接从 MQ 里消费即可；如果某个系统不需要这条数据了，就取消对  MQ 消息的消费即可。这样下来，A 系统压根儿不需要去考虑要给谁发送数 据，不需要维护这个代码，也不需要考虑人家是否调用成功、失败超时等情况。 就是一个系统或者一个模块，调用了多个系统或者模块，互相之间的调用很复 杂，维护起来很麻烦。但是其实这个调用是不需要直接同步调用接口的，如果用  MQ 给它异步化解耦。 </p>
<p><strong>异步：</strong>A 系统接收一个请求，需要在自己本地写库，还需要在 BCD 三个系统写 库，自己本地写库要 3ms，BCD 三个系统分别写库要 300ms、450ms、 200ms。最终请求总延时是 3 + 300 + 450 + 200 &#x3D; 953ms，接近 1s，用户 感觉搞个什么东西，慢死了慢死了。用户通过浏览器发起请求。如果使用  MQ，那么 A 系统连续发送 3 条消息到 MQ 队列中，假如耗时 5ms，A 系统从 接受一个请求到返回响应给用户，总时长是 3 + 5 &#x3D; 8ms。 </p>
<p><strong>削峰：</strong>减少高峰时期对服务器压力。</p>
<h2 id="消息队列有什么优缺点？RabbitMQ有什么优缺点？"><a href="#消息队列有什么优缺点？RabbitMQ有什么优缺点？" class="headerlink" title="消息队列有什么优缺点？RabbitMQ有什么优缺点？"></a>消息队列有什么优缺点？RabbitMQ有什么优缺点？</h2><p>优点上面已经说了，就是**在特殊场景下有其对应的好处，解耦、异步、削峰。 **</p>
<p>缺点有以下几个： </p>
<p>系统可用性降低 </p>
<p>本来系统运行好好的，现在你非要加入个消息队列进去，那消息队列挂了，你的 系统不是呵呵了。因此，系统可用性会降低； </p>
<p>系统复杂度提高 </p>
<p>加入了消息队列，要多考虑很多方面的问题，比如：一致性问题、如何保证消息 不被重复消费、如何保证消息可靠性传输等。因此，需要考虑的东西更多，复杂 性增大。 </p>
<p>一致性问题 </p>
<p>A 系统处理完了直接返回成功了，人都以为你这个请求就成功了；但是问题是， 要是 BCD 三个系统那里，BD 两个系统写库成功了，结果 C 系统写库失败了， 咋整？你这数据就不一致了。 </p>
<p>所以消息队列实际是一种非常复杂的架构，你引入它有很多好处，但是也得针对 它带来的坏处做各种额外的技术方案和架构来规避掉，做好之后，你会发现，妈 呀，系统复杂度提升了一个数量级，也许是复杂了 10 倍。但是关键时刻，用， 还是得用的。 </p>
<h2 id="你们公司生产环境用的是什么消息中间件？"><a href="#你们公司生产环境用的是什么消息中间件？" class="headerlink" title="你们公司生产环境用的是什么消息中间件？"></a>你们公司生产环境用的是什么消息中间件？</h2><p>这个首先你可以说下你们公司选用的是什么消息中间件，比如用的是 RabbitMQ，然后可以初步给一些你对不同MQ中间件技术的选型分析。 </p>
<p>举个例子：比如说ActiveMQ是老牌的消息中间件，国内很多公司过去运用的还 是非常广泛的，功能很强大。 </p>
<p>但是问题在于没法确认ActiveMQ可以支撑互联网公司的高并发、高负载以及高 吞吐的复杂场景，在国内互联网公司落地较少。而且使用较多的是一些传统企 业，用ActiveMQ做异步调用和系统解耦。</p>
<p>然后你可以说说RabbitMQ，他的好处在于可以支撑高并发、高吞吐、性能很 高，同时有非常完善便捷的后台管理界面可以使用。 </p>
<p>另外，他还支持集群化、高可用部署架构、消息高可靠支持，功能较为完善。</p>
<p>而且经过调研，国内各大互联网公司落地大规模RabbitMQ集群支撑自身业务的 case较多，国内各种中小型互联网公司使用RabbitMQ的实践也比较多。 </p>
<p>除此之外，RabbitMQ的开源社区很活跃，较高频率的迭代版本，来修复发现的 bug以及进行各种优化，因此综合考虑过后，公司采取了RabbitMQ。 </p>
<p>但是RabbitMQ也有一点缺陷，就是他自身是基于erlang语言开发的，所以导致 较为难以分析里面的源码，也较难进行深层次的源码定制和改造，毕竟需要较为 扎实的erlang语言功底才可以。 </p>
<p>然后可以聊聊RocketMQ，是阿里开源的，经过阿里的生产环境的超高并发、 高吞吐的考验，性能卓越，同时还支持分布式事务等特殊场景。 </p>
<p>而且RocketMQ是基于Java语言开发的，适合深入阅读源码，有需要可以站在 源码层面解决线上生产问题，包括源码的二次开发和改造。 </p>
<p>另外就是Kafka。Kafka提供的消息中间件的功能明显较少一些，相对上述几款 MQ中间件要少很多。 </p>
<p>但是Kafka的优势在于专为超高吞吐量的实时日志采集、实时数据同步、实时数 据计算等场景来设计。 </p>
<p>因此Kafka在大数据领域中配合实时计算技术（比如Spark Streaming、 Storm、Flink）使用的较多。但是在传统的MQ中间件使用场景中较少采用。 </p>
<h2 id="Kafka、ActiveMQ、RabbitMQ、RocketMQ-有-什么优缺点？"><a href="#Kafka、ActiveMQ、RabbitMQ、RocketMQ-有-什么优缺点？" class="headerlink" title="Kafka、ActiveMQ、RabbitMQ、RocketMQ 有 什么优缺点？"></a>Kafka、ActiveMQ、RabbitMQ、RocketMQ 有 什么优缺点？</h2><table>
<thead>
<tr>
<th>ActiveMQ</th>
<th>RabbitMQ</th>
<th>RocketMQ</th>
<th>Kafka</th>
<th>ZeroMQ</th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>单机吞吐 量</td>
<td>比 RabbitM Q低</td>
<td>2.6w&#x2F;s（ 消息做持 久化）</td>
<td>11.6w&#x2F;s</td>
<td>17.3w&#x2F;s</td>
<td>29w&#x2F;s</td>
</tr>
<tr>
<td>开发语言</td>
<td>Java</td>
<td>Erlang</td>
<td>Java</td>
<td>Scala&#x2F;Java</td>
<td>C</td>
</tr>
<tr>
<td>主要维护者</td>
<td>Apache</td>
<td>Mozilla&#x2F;Spring</td>
<td>Alibaba</td>
<td>Apache</td>
<td>iMatix创始人已去世</td>
</tr>
<tr>
<td>成熟度</td>
<td>成熟</td>
<td>成熟</td>
<td>开源版本不够成熟</td>
<td>比较成熟</td>
<td>只有C、PHP等版本成熟</td>
</tr>
<tr>
<td>订阅形式</td>
<td>点对点 (p2p)、广 播（发布订阅）</td>
<td>提供了4 种： direct,  topic,Headers 和 fanout。 fanout就 是广播模 式</td>
<td>基于 topic&#x2F;me ssageTag 以及按照消息类 型、属性 进行正则 匹配的发 布订阅模 式</td>
<td>基于topic 以及按照 topic进行 正则匹配的发布订 阅模式</td>
<td>点对点(P2P)</td>
</tr>
<tr>
<td>持久化</td>
<td>支持少量 堆积</td>
<td>支持少量 堆积</td>
<td>支持大量 堆积</td>
<td>支持大量 堆积</td>
<td>不支持</td>
</tr>
<tr>
<td>顺序消息</td>
<td>不支持</td>
<td>不支持</td>
<td>支持</td>
<td>支持</td>
<td>不支持</td>
</tr>
<tr>
<td>性能稳定 性</td>
<td>好</td>
<td>好</td>
<td>一般</td>
<td>较差</td>
<td>很好</td>
</tr>
<tr>
<td>集群方式</td>
<td>支持简单 集群模 式，比 如’主备’，对 高级集群 模式支持 不好。</td>
<td>支持简单 集群，’复 制’模 式，对高 级集群模 式支持不 好。</td>
<td>常用 多 对’Mast erSlave’ 模 式，开源 版本需手 动切换 Slave变成 Master</td>
<td>天然 的‘Lead erSlave’无 状态集 群，每台 服务器既 是Master 也是Slave</td>
<td>不支持</td>
</tr>
<tr>
<td>管理界面</td>
<td>一般</td>
<td>较好</td>
<td>一般</td>
<td>无</td>
<td>无</td>
</tr>
</tbody></table>
<p>综上，各种对比之后，有如下建议： </p>
<p>一般的业务系统要引入 MQ，最早大家都用 ActiveMQ，但是现在确实大家用 的不多了，没经过大规模吞吐量场景的验证，社区也不是很活跃，所以大家还是 算了吧，我个人不推荐用这个了； </p>
<p>后来大家开始用 RabbitMQ，但是确实 erlang 语言阻止了大量的 Java 工程师 去深入研究和掌控它，对公司而言，几乎处于不可控的状态，但是确实人家是开 源的，比较稳定的支持，活跃度也高； </p>
<p>不过现在确实越来越多的公司会去用 RocketMQ，确实很不错，毕竟是阿里出 品，但社区可能有突然黄掉的风险（目前 RocketMQ 已捐给 <a target="_blank" rel="noopener" href="https://github.com/apache/rocketmq">Apache</a>，但  GitHub 上的活跃度其实不算高）对自己公司技术实力有绝对自信的，推荐用  RocketMQ，否则回去老老实实用 RabbitMQ 吧，人家有活跃的开源社区，绝 对不会黄。 </p>
<p>所以<strong>中小型公司</strong>，技术实力较为一般，技术挑战不是特别高，用 RabbitMQ 是 不错的选择；<strong>大型公司</strong>，基础架构研发实力较强，用 RocketMQ 是很好的选 择。</p>
<p>如果是<strong>大数据领域</strong>的实时计算、日志采集等场景，用 Kafka 是业内标准的，绝 对没问题，社区活跃度很高，绝对不会黄，何况几乎是全世界这个领域的事实性 规范。 </p>
<h2 id="MQ-有哪些常见问题？如何解决这些问题？"><a href="#MQ-有哪些常见问题？如何解决这些问题？" class="headerlink" title="MQ 有哪些常见问题？如何解决这些问题？"></a>MQ 有哪些常见问题？如何解决这些问题？</h2><p>MQ 的常见问题有： </p>
<ol>
<li>消息的顺序问题 </li>
<li>消息的重复问题</li>
</ol>
<p>**消息的顺序问题 **</p>
<p>消息有序指的是可以按照消息的发送顺序来消费。 </p>
<p>假如生产者产生了 2 条消息：M1、M2，假定 M1 发送到 S1，M2 发送到  S2，如果要保证 M1 先于 M2 被消费，怎么做？</p>
<p><img src="/15-%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6MQ%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%882020%E6%9C%80%E6%96%B0%E7%89%88%EF%BC%89.assets/%E6%B6%88%E6%81%AF%E7%9A%84%E9%A1%BA%E5%BA%8F%E9%97%AE%E9%A2%98.png" alt="消息的顺序问题"></p>
<p>解决方案： （1）保证生产者 - MQServer - 消费者是一对一对一的关系</p>
<p><img src="/15-%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6MQ%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%882020%E6%9C%80%E6%96%B0%E7%89%88%EF%BC%89.assets/%E6%B6%88%E6%81%AF%E7%9A%84%E9%A1%BA%E5%BA%8F%E9%97%AE%E9%A2%982.png" alt="消息的顺序问题2"></p>
<p>缺陷：</p>
<ul>
<li>并行度就会成为消息系统的瓶颈（吞吐量不够） </li>
<li>更多的异常处理，比如：只要消费端出现问题，就会导致整个处理流程阻塞，我 们不得不花费更多的精力来解决阻塞的问题。（2）通过合理的设计或者将问题分解 来规避。 </li>
<li>不关注乱序的应用实际大量存在 </li>
<li>队列无序并不意味着消息无序 所以从业务层面来保证消息的顺序而不仅仅是依 赖于消息系统，是一种更合理的方式。</li>
</ul>
<p>**消息的重复问题 **</p>
<p>造成消息重复的根本原因是：网络不可达。 </p>
<p>所以解决这个问题的办法就是绕过这个问题。那么问题就变成了：如果消费端收 到两条一样的消息，应该怎样处理？ </p>
<p>消费端处理消息的业务逻辑保持幂等性。只要保持幂等性，不管来多少条重复消 息，最后处理的结果都一样。保证每条消息都有唯一编号且保证消息处理成功与 去重表的日志同时出现。利用一张日志表来记录已经处理成功的消息的 ID，如 果新到的消息 ID 已经在日志表中，那么就不再处理这条消息。 </p>
<h2 id="什么是RabbitMQ？"><a href="#什么是RabbitMQ？" class="headerlink" title="什么是RabbitMQ？"></a>什么是RabbitMQ？</h2><p>RabbitMQ是一款开源的，Erlang编写的，基于AMQP协议的消息中间件 </p>
<h2 id="Rabbitmq-的使用场景"><a href="#Rabbitmq-的使用场景" class="headerlink" title="Rabbitmq 的使用场景"></a>Rabbitmq 的使用场景</h2><p>（1）服务间异步通信</p>
<p>（2）顺序消费 </p>
<p>（3）定时任务 </p>
<p>（4）请求削峰 </p>
<h2 id="RabbitMQ基本概念"><a href="#RabbitMQ基本概念" class="headerlink" title="RabbitMQ基本概念"></a>RabbitMQ基本概念</h2><ul>
<li>Broker： 简单来说就是消息队列服务器实体 </li>
<li>Exchange： 消息交换机，它指定消息按什么规则，路由到哪个队列 </li>
<li>Queue： 消息队列载体，每个消息都会被投入到一个或多个队列 </li>
<li>Binding： 绑定，它的作用就是把exchange和queue按照路由规则绑定起来 </li>
<li>Routing Key： 路由关键字，exchange根据这个关键字进行消息投递 </li>
<li>VHost： vhost 可以理解为虚拟 broker ，即 mini-RabbitMQ server。其内部 均含有独立的 queue、exchange 和 binding 等，但最最重要的是，其拥有独立的 权限系统，可以做到 vhost 范围的用户控制。当然，从 RabbitMQ 的全局角度， vhost 可以作为不同权限隔离的手段（一个典型的例子就是不同的应用可以跑在不同 的 vhost 中）。 </li>
<li>Producer： 消息生产者，就是投递消息的程序 </li>
<li>Consumer： 消息消费者，就是接受消息的程序 </li>
<li>Channel： 消息通道，在客户端的每个连接里，可建立多个channel，每个 channel代表一个会话任务</li>
</ul>
<p>由Exchange、Queue、RoutingKey三个才能决定一个从Exchange到Queue的 唯一的线路。 </p>
<h2 id="RabbitMQ的工作模式"><a href="#RabbitMQ的工作模式" class="headerlink" title="RabbitMQ的工作模式"></a>RabbitMQ的工作模式</h2><h3 id="一-simple模式（即最简单的收发模式）"><a href="#一-simple模式（即最简单的收发模式）" class="headerlink" title="一.simple模式（即最简单的收发模式）"></a>一.simple模式（即最简单的收发模式）</h3><p><img src="/15-%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6MQ%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%882020%E6%9C%80%E6%96%B0%E7%89%88%EF%BC%89.assets/simple%E6%A8%A1%E5%BC%8F.png" alt="simple模式"></p>
<p>1.消息产生消息，将消息放入队列 </p>
<p>2.消息的消费者(consumer) 监听 消息队列,如果队列中有消息,就消费掉,消息被 拿走后,自动从队列中删除(隐患 消息可能没有被消费者正确处理,已经从队列中消失了,造成消息的丢失，这里可以设置成手动的ack,但如果设置成手动ack，处 理完后要及时发送ack消息给队列，否则会造成内存溢出)。 </p>
<h3 id="二-work工作模式-资源的竞争"><a href="#二-work工作模式-资源的竞争" class="headerlink" title="二.work工作模式(资源的竞争)"></a>二.work工作模式(资源的竞争)</h3><p><img src="/15-%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6MQ%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%882020%E6%9C%80%E6%96%B0%E7%89%88%EF%BC%89.assets/work%E5%B7%A5%E4%BD%9C%E6%A8%A1%E5%BC%8F.png" alt="work工作模式"></p>
<p>1.消息产生者将消息放入队列消费者可以有多个,消费者1,消费者2同时监听同一 个队列,消息被消费。C1 C2共同争抢当前的消息队列内容,谁先拿到谁负责消费 消息(隐患：高并发情况下,默认会产生某一个消息被多个消费者共同使用,可以设 置一个开关(syncronize) 保证一条消息只能被一个消费者使用)。 </p>
<h3 id="三-publish-x2F-subscribe发布订阅-共享资源"><a href="#三-publish-x2F-subscribe发布订阅-共享资源" class="headerlink" title="三.publish&#x2F;subscribe发布订阅(共享资源)"></a>三.publish&#x2F;subscribe发布订阅(共享资源)</h3><p><img src="/15-%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6MQ%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%882020%E6%9C%80%E6%96%B0%E7%89%88%EF%BC%89.assets/publish_subscribe%E5%8F%91%E5%B8%83%E8%AE%A2%E9%98%85(%E5%85%B1%E4%BA%AB%E8%B5%84%E6%BA%90).png" alt="publish_subscribe发布订阅(共享资源)">1、每个消费者监听自己的队列； </p>
<p>2、生产者将消息发给broker，由交换机将消息转发到绑定此交换机的每个队 列，每个绑定交换机的队列都将接收到消息。 </p>
<h3 id="四-routing路由模式"><a href="#四-routing路由模式" class="headerlink" title="四.routing路由模式"></a>四.routing路由模式</h3><p><img src="/15-%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6MQ%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%882020%E6%9C%80%E6%96%B0%E7%89%88%EF%BC%89.assets/routing%E8%B7%AF%E7%94%B1%E6%A8%A1%E5%BC%8F.png" alt="routing路由模式">1.消息生产者将消息发送给交换机按照路由判断,路由是字符串(info) 当前产生的 消息携带路由字符(对象的方法),交换机根据路由的key,只能匹配上路由key对应的消息队列,对应的消费者才能消费消息; </p>
<p>2.根据业务功能定义路由字符串 </p>
<p>3.从系统的代码逻辑中获取对应的功能字符串,将消息任务扔到对应的队列中。</p>
<p>4.业务场景:error 通知;EXCEPTION;错误通知的功能;传统意义的错误通知;客户 通知;利用key路由,可以将程序中的错误封装成消息传入到消息队列中,开发者可 以自定义消费者,实时接收错误;</p>
<h3 id="五-topic-主题模式-路由模式的一种"><a href="#五-topic-主题模式-路由模式的一种" class="headerlink" title="五.topic 主题模式(路由模式的一种)"></a>五.topic 主题模式(路由模式的一种)</h3><p>![topic 主题模式(路由模式的一种)](15-消息中间件MQ面试题（2020最新版）.assets&#x2F;topic 主题模式(路由模式的一种).png)<br>1.星号井号代表通配符 </p>
<p>2.星号代表多个单词,井号代表一个单词 </p>
<p>3.路由功能添加模糊匹配 </p>
<p>4.消息产生者产生消息,把消息交给交换机 </p>
<p>5.交换机根据key的规则模糊匹配到对应的队列,由队列的监听消费者接收消息消 费 </p>
<p>（在我的理解看来就是routing查询的一种模糊匹配，就类似sql的模糊查询方 式） </p>
<h2 id="如何保证RabbitMQ消息的顺序性？"><a href="#如何保证RabbitMQ消息的顺序性？" class="headerlink" title="如何保证RabbitMQ消息的顺序性？"></a>如何保证RabbitMQ消息的顺序性？</h2><p>拆分多个 queue，每个 queue 一个 consumer，就是多一些 queue 而已，确 实是麻烦点；或者就一个 queue 但是对应一个 consumer，然后这个  consumer 内部用内存队列做排队，然后分发给底层不同的 worker 来处理。 </p>
<h1 id="消息如何分发？"><a href="#消息如何分发？" class="headerlink" title="消息如何分发？"></a>消息如何分发？</h1><p>若该队列至少有一个消费者订阅，消息将以循环（round-robin）的方式发送给消费者。每条消息只会分发给一个订阅的消费者（前提是消费者能够正常处理消息并进行确认）。通过路由可实现多消费的功能</p>
<h1 id="消息怎么路由？"><a href="#消息怎么路由？" class="headerlink" title="消息怎么路由？"></a>消息怎么路由？</h1><p>消息提供方-&gt;路由-&gt;一至多个队列消息发布到交换器时，消息将拥有一个路由键（routing key），在消息创建时设定。通过队列路由键，可以把队列绑定到交换器上。消息到达交换器后，RabbitMQ 会将消息的路由键与队列的路由键进行匹配（针对不同的交换器有不同的路由规则）；常用的交换器主要分为一下三种： fanout：如果交换器收到消息，将会广播到所有绑定的队列上 direct：如果路由键完全匹配，消息就被投递到相应的队列</p>
<p>topic：可以使来自不同源头的消息能够到达同一个队列。 使用 topic 交换器时，可以使用通配符</p>
<h1 id="消息基于什么传输？"><a href="#消息基于什么传输？" class="headerlink" title="消息基于什么传输？"></a>消息基于什么传输？</h1><p>由于 TCP 连接的创建和销毁开销较大，且并发数受系统资源限制，会造成性能瓶颈。RabbitMQ 使用信道的方式来传输数据。信道是建立在真实的 TCP 连接内的虚拟连接，且每条 TCP 连接上的信道数量没有限制。</p>
<h1 id="如何保证消息不被重复消费？或者说，如何保证消息消费时的幂等性？"><a href="#如何保证消息不被重复消费？或者说，如何保证消息消费时的幂等性？" class="headerlink" title="如何保证消息不被重复消费？或者说，如何保证消息消费时的幂等性？"></a>如何保证消息不被重复消费？或者说，如何保证消息消费时的幂等性？</h1><p>先说为什么会重复消费：正常情况下，消费者在消费消息的时候，消费完毕后，会发送一个确认消息给消息队列，消息队列就知道该消息被消费了，就会将该消息从消息队列中删除；但是因为网络传输等等故障，确认信息没有传送到消息队列，导致消息队列不知道自己已经消费过该消息了，再次将消息分发给其他的消费者。</p>
<p>针对以上问题，一个解决思路是：保证消息的唯一性，就算是多次传输，不要让消息的多次消费带来影响；保证消息等幂性；比如：在写入消息队列的数据做唯一标示，消费消息时，根据唯一标识判断是否消费过；假设你有个系统，消费一条消息就往数据库里插入一条数据，要是你一个消息重复两次，你不就插入了两条，这数据不就错了？但是你要是消费到第二次的时据，从而保证了数据的正确性。</p>
<h1 id="候，自己判断一下是否已经消费过了，若是就直接扔了，这样不就保留了一条数如何确保消息正确地发送至-RabbitMQ？-如何确保消息接收方消费了消息？"><a href="#候，自己判断一下是否已经消费过了，若是就直接扔了，这样不就保留了一条数如何确保消息正确地发送至-RabbitMQ？-如何确保消息接收方消费了消息？" class="headerlink" title="候，自己判断一下是否已经消费过了，若是就直接扔了，这样不就保留了一条数如何确保消息正确地发送至 RabbitMQ？ 如何确保消息接收方消费了消息？"></a>候，自己判断一下是否已经消费过了，若是就直接扔了，这样不就保留了一条数如何确保消息正确地发送至 RabbitMQ？ 如何确保消息接收方消费了消息？</h1><p>发送方确认模式将信道设置成 confirm 模式（发送方确认模式），则所有在信道上发布的消息都会被指派一个唯一的 ID。</p>
<p>一旦消息被投递到目的队列后，或者消息被写入磁盘后（可持久化的消息），信道会发送一个确认给生产者（包含消息唯一 ID）。</p>
<p>如果 RabbitMQ 发生内部错误从而导致消息丢失，会发送一条 nack（notacknowledged，未确认）消息。</p>
<p>发送方确认模式是异步的，生产者应用程序在等待确认的同时，可以继续发送消息。当确认消息到达生产者应用程序，生产者应用程序的回调方法就会被触发来处理确认消息。接收方确认机制消费者接收每一条消息后都必须进行确认（消息接收和消息确认是两个不同操作）。只有消费者确认了消息，RabbitMQ 才能安全地把消息从队列中删除。</p>
<p>这里并没有用到超时机制，RabbitMQ 仅通过 Consumer 的连接中断来确认是否需要重新发送消息。也就是说，只要连接不中断，RabbitMQ 给了 </p>
<p>Consumer 足够长的时间来处理消息。保证数据的最终一致性；下面罗列几种特殊情况</p>
<ul>
<li>如果消费者接收到消息，在确认之前断开了连接或取消订阅，RabbitMQ 会认为消息没有被分发，然后重新分发给下一个订阅的消费者。（可能存在消息重复消费的隐患，需要去重）</li>
<li>如果消费者接收到消息却没有确认消息，连接也未断开，则 RabbitMQ 认为该消费者繁忙，将不会给该消费者分发更多的消息。</li>
</ul>
<h1 id="如何保证RabbitMQ消息的可靠传输？"><a href="#如何保证RabbitMQ消息的可靠传输？" class="headerlink" title="如何保证RabbitMQ消息的可靠传输？"></a>如何保证RabbitMQ消息的可靠传输？</h1><p>消息不可靠的情况可能是消息丢失，劫持等原因；丢失又分为：生产者丢失消息、消息列表丢失消息、消费者丢失消息；生产者丢失消息：从生产者弄丢数据这个角度来看，RabbitMQ提供 transaction和confirm模式来确保生产者不丢消息；</p>
<p>transaction机制就是说：发送消息前，开启事务（channel.txSelect()）,然后发送消息，如果发送过程中出现什么异常，事务就会回滚</p>
<p>（channel.txRollback()）,如果发送成功则提交事务</p>
<p>（channel.txCommit()）。然而，这种方式有个缺点：吞吐量下降；</p>
<p>confirm模式用的居多：一旦channel进入confirm模式，所有在该信道上发布的消息都将会被指派一个唯一的ID（从1开始），一旦消息被投递到所有匹配的队列之后；</p>
<p>rabbitMQ就会发送一个ACK给生产者（包含消息的唯一ID），这就使得生产者知道消息已经正确到达目的队列了；</p>
<p>如果rabbitMQ没能处理该消息，则会发送一个Nack消息给你，你可以进行重试操作。</p>
<p>消息队列丢数据：消息持久化。</p>
<p>处理消息队列丢数据的情况，一般是开启持久化磁盘的配置。</p>
<p>这个持久化配置可以和confirm机制配合使用，你可以在消息持久化磁盘后，再给生产者发送一个Ack信号。</p>
<p>这样，如果消息持久化磁盘之前，rabbitMQ阵亡了，那么生产者收不到Ack信号，生产者会自动重发。</p>
<p>那么如何持久化呢？</p>
<p>这里顺便说一下吧，其实也很容易，就下面两步</p>
<p>\1. 将queue的持久化标识durable设置为true,则代表是一个持久的队列</p>
<p>\2. 发送消息的时候将deliveryMode&#x3D;2</p>
<p>这样设置以后，即使rabbitMQ挂了，重启后也能恢复数据消费者丢失消息：消费者丢数据一般是因为采用了自动确认消息模式，改为手动确认消息即可！消费者在收到消息之后，处理消息之前，会自动回复RabbitMQ已收到消息；如果这时处理消息失败，就会丢失该消息；解决方案：处理消息成功后，手动回复确认消息。</p>
<h1 id="为什么不应该对所有的-message-都使用持久化机制？"><a href="#为什么不应该对所有的-message-都使用持久化机制？" class="headerlink" title="为什么不应该对所有的 message 都使用持久化机制？"></a>为什么不应该对所有的 message 都使用持久化机制？</h1><p>首先，必然导致性能的下降，因为写磁盘比写 RAM 慢的多，message 的吞吐量可能有 10 倍的差距。</p>
<p>其次，message 的持久化机制用在 RabbitMQ 的内置 cluster 方案时会出现“坑爹”问题。矛盾点在于，若 message 设置了 persistent 属性，但 queue 未设置 durable 属性，那么当该 queue 的 owner node 出现异常后，在未重建该 queue 前，发往该 queue 的 message 将被 blackholed ；若 message 设置了 persistent 属性，同时 queue 也设置了 durable 属性，那么当 queue 的 owner node 异常且无法重启的情况下，则该 queue 无法在其他 node 上重建，只能等待其 owner node 重启后，才能恢复该 queue 的使用，而在这段时间内发送给该 queue 的 message 将被 blackholed 。</p>
<p>所以，是否要对 message 进行持久化，需要综合考虑性能需要，以及可能遇到的问题。若想达到 100,000 条&#x2F;秒以上的消息吞吐量（单 RabbitMQ 服务</p>
<p>器），则要么使用其他的方式来确保 message 的可靠 delivery ，要么使用非常快速的存储系统以支持全持久化（例如使用 SSD）。另外一种处理原则是：</p>
<p>仅对关键消息作持久化处理（根据业务重要程度），且应该保证关键消息的量不会导致性能瓶颈。</p>
<h1 id="如何保证高可用的？RabbitMQ-的集群"><a href="#如何保证高可用的？RabbitMQ-的集群" class="headerlink" title="如何保证高可用的？RabbitMQ 的集群"></a>如何保证高可用的？RabbitMQ 的集群</h1><p>RabbitMQ 是比较有代表性的，因为是基于主从（非分布式）做高可用性的，</p>
<p>我们就以 RabbitMQ 为例子讲解第一种 MQ 的高可用性怎么实现。RabbitMQ 有三种模式：单机模式、普通集群模式、镜像集群模式。</p>
<p>单机模式，就是 Demo 级别的，一般就是你本地启动了玩玩儿的?，没人生产用单机模式普通集群模式，意思就是在多台机器上启动多个 RabbitMQ 实例，每个机器启动一个。你创建的 queue，只会放在一个 RabbitMQ 实例上，但是每个实例都同步 queue 的元数据（元数据可以认为是 queue 的一些配置信息，通过元数据，可以找到 queue 所在实例）。你消费的时候，实际上如果连接到了另外一个实例，那么那个实例会从 queue 所在实例上拉取数据过来。这方案主要是提高吞吐量的，就是说让集群中多个节点来服务某个 queue 的读写操作。</p>
<p>镜像集群模式：这种模式，才是所谓的 RabbitMQ 的高可用模式。跟普通集群模式不一样的是，在镜像集群模式下，你创建的 queue，无论元数据还是 queue 里的消息都会存在于多个实例上，就是说，每个 RabbitMQ 节点都有这个 queue 的一个完整镜像，包含 queue 的全部数据的意思。然后每次你写消息到 queue 的时候，都会自动把消息同步到多个实例的 queue 上。</p>
<p>RabbitMQ 有很好的管理控制台，就是在后台新增一个策略，这个策略是镜像集群模式的策略，指定的时候是可以要求数据同步到所有节点的，也可以要求同步到指定数量的节点，再次创建 queue 的时候，应用这个策略，就会自动将数据同步到其他的节点上去了。这样的话，好处在于，你任何一个机器宕机了，没事儿，其它机器（节点）还包含了这个 queue 的完整数据，别的 consumer 都可以到其它节点上去消费数据。坏处在于，第一，这个性能开销也太大了吧，消息需要同步到所有机器上，导致网络带宽压力和消耗很重！RabbitMQ 一个 queue 的数据都是放在一个节点里的，镜像集群下，也是每个节点都放这个queue 的完整数据。 </p>
<p>如何解决消息队列的延时以及过期失效问题？消息队列满了以后该怎么处理？有几百万消息持续积压几小时，说说怎么解决？</p>
<p>消息积压处理办法：临时紧急扩容：</p>
<p>先修复 consumer 的问题，确保其恢复消费速度，然后将现有 cnosumer 都停掉。</p>
<p>新建一个 topic，partition 是原来的 10 倍，临时建立好原先 10 倍的 queue 数量。</p>
<p>然后写一个临时的分发数据的 consumer 程序，这个程序部署上去消费积压的</p>
<p>数据，消费之后不做耗时的处理，直接均匀轮询写入临时建立好的 10 倍数量的 queue。</p>
<p>接着临时征用 10 倍的机器来部署 consumer，每一批 consumer 消费一个临时 queue 的数据。这种做法相当于是临时将 queue 资源和 consumer 资源扩大 10 倍，以正常的 10 倍速度来消费数据。</p>
<p>等快速消费完积压数据之后，得恢复原先部署的架构，重新用原先的 consumer 机器来消费消息。</p>
<p>MQ中消息失效：假设你用的是 RabbitMQ，RabbtiMQ 是可以设置过期时间</p>
<p>的，也就是 TTL。如果消息在 queue 中积压超过一定的时间就会被 RabbitMQ 给清理掉，这个数据就没了。那这就是第二个坑了。这就不是说数据会大量积压在 mq 里，而是大量的数据会直接搞丢。我们可以采取一个方案，就是批量重导，这个我们之前线上也有类似的场景干过。就是大量积压的时候，我们当时就直接丢弃数据了，然后等过了高峰期以后，比如大家一起喝咖啡熬夜到晚上12 点以后，用户都睡觉了。这个时候我们就开始写程序，将丢失的那批数据，写个临时程序，一点一点的查出来，然后重新灌入 mq 里面去，把白天丢的数据给他补回来。也只能是这样了。假设 1 万个订单积压在 mq 里面，没有处理，其中 1000 个订单都丢了，你只能手动写程序把那 1000 个订单给查出来，手动发到 mq 里去再补一次。</p>
<p>mq消息队列块满了：如果消息积压在 mq 里，你很长时间都没有处理掉，此时导致 mq 都快写满了，咋办？这个还有别的办法吗？没有，谁让你第一个方案执行的太慢了，你临时写程序，接入数据来消费，消费一个丢弃一个，都不要</p>
<p>了，快速消费掉所有的消息。然后走第二个方案，到了晚上再补数据吧。</p>
<h1 id="设计MQ思路"><a href="#设计MQ思路" class="headerlink" title="设计MQ思路"></a>设计MQ思路</h1><p>比如说这个消息队列系统，我们从以下几个角度来考虑一下：首先这个 mq 得支持可伸缩性吧，就是需要的时候快速扩容，就可以增加吞吐量和容量，那怎么搞？设计个分布式的系统呗，参照一下 kafka 的设计理念，</p>
<p>broker -&gt; topic -&gt; partition，每个 partition 放一个机器，就存一部分数据。</p>
<p>如果现在资源不够了，简单啊，给 topic 增加 partition，然后做数据迁移，增加机器，不就可以存放更多数据，提供更高的吞吐量了？其次你得考虑一下这个 mq 的数据要不要落地磁盘吧？那肯定要了，落磁盘才能保证别进程挂了数据就丢了。那落磁盘的时候怎么落啊？顺序写，这样就没有</p>
<p>磁盘随机读写的寻址开销，磁盘顺序读写的性能是很高的，这就是 kafka 的思路。</p>
<p>其次你考虑一下你的 mq 的可用性啊？这个事儿，具体参考之前可用性那个环节讲解的 kafka 的高可用保障机制。多副本 -&gt; leader &amp; follower -&gt; broker 挂了重新选举 leader 即可对外服务。</p>
<p>能不能支持数据 0 丢失啊？可以的，参考我们之前说的那个 kafka 数据零丢失方案。</p>

      
    </div>

    
    
    

       
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/10/12/14-Dubbo%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%882020%E6%9C%80%E6%96%B0%E7%89%88%EF%BC%89/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="善善332">
      <meta itemprop="description" content="运气和努力一样重要">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="和善寺">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/10/12/14-Dubbo%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%882020%E6%9C%80%E6%96%B0%E7%89%88%EF%BC%89/" class="post-title-link" itemprop="url">未命名</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-10-12 15:01:16" itemprop="dateCreated datePublished" datetime="2022-10-12T15:01:16+08:00">2022-10-12</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-03-03 13:51:32" itemprop="dateModified" datetime="2021-03-03T13:51:32+08:00">2021-03-03</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h1><h2 id="为什么要用-Dubbo？"><a href="#为什么要用-Dubbo？" class="headerlink" title="为什么要用 Dubbo？"></a>为什么要用 Dubbo？</h2><p>随着服务化的进一步发展，服务越来越多，服务之间的调用和依赖关系也越来越 复杂，诞生了面向服务的架构体系(SOA)，也因此衍生出了一系列相应的技术，如对服务提供、服务调用、连接处理、通信协议、序列化方式、服务发现、服务 路由、日志输出等行为进行封装的服务框架。就这样为分布式系统的服务治理框 架就出现了，Dubbo 也就这样产生了。 </p>
<h2 id="Dubbo-是什么？"><a href="#Dubbo-是什么？" class="headerlink" title="Dubbo 是什么？"></a>Dubbo 是什么？</h2><p>Dubbo 是一款高性能、轻量级的开源 RPC 框架，提供服务自动注册、自动发 现等高效服务治理方案， 可以和 Spring 框架无缝集成。 </p>
<h2 id="Dubbo-的使用场景有哪些？"><a href="#Dubbo-的使用场景有哪些？" class="headerlink" title="Dubbo 的使用场景有哪些？"></a>Dubbo 的使用场景有哪些？</h2><ul>
<li>透明化的远程方法调用：就像调用本地方法一样调用远程方法，只需简单配置， 没有任何API侵入。 </li>
<li>软负载均衡及容错机制：可在内网替代 F5 等硬件负载均衡器，降低成本，减少 单点。 </li>
<li>服务自动注册与发现：不再需要写死服务提供方地址，注册中心基于接口名查询 服务提供者的IP地址，并且能够平滑添加或删除服务提供者。</li>
</ul>
<h2 id="Dubbo-核心功能有哪些？"><a href="#Dubbo-核心功能有哪些？" class="headerlink" title="Dubbo 核心功能有哪些？"></a>Dubbo 核心功能有哪些？</h2><ul>
<li>Remoting：网络通信框架，提供对多种NIO框架抽象封装，包括“同步转异 步”和“请求-响应”模式的信息交换方式。 </li>
<li>Cluster：服务框架，提供基于接口方法的透明远程过程调用，包括多协议支 持，以及软负载均衡，失败容错，地址路由，动态配置等集群支持。 </li>
<li>Registry：服务注册，基于注册中心目录服务，使服务消费方能动态的查找服务 提供方，使地址透明，使服务提供方可以平滑增加或减少机器。</li>
</ul>
<h1 id="架构设计"><a href="#架构设计" class="headerlink" title="架构设计"></a>架构设计</h1><h2 id="Dubbo-核心组件有哪些？"><a href="#Dubbo-核心组件有哪些？" class="headerlink" title="Dubbo 核心组件有哪些？"></a>Dubbo 核心组件有哪些？</h2><p>![Dubbo Architecture](14-Dubbo面试题（2020最新版）.assets&#x2F;Dubbo Architecture.png)</p>
<ul>
<li>Provider：暴露服务的服务提供方 </li>
<li>Consumer：调用远程服务消费方 </li>
<li>Registry：服务注册与发现注册中心 </li>
<li>Monitor：监控中心和访问调用统计 </li>
<li>Container：服务运行容器</li>
</ul>
<h2 id="Dubbo-服务器注册与发现的流程？"><a href="#Dubbo-服务器注册与发现的流程？" class="headerlink" title="Dubbo 服务器注册与发现的流程？"></a>Dubbo 服务器注册与发现的流程？</h2><p><strong>服务容器Container</strong>负责启动，加载，运行服务提供者。 </p>
<p><strong>服务提供者Provider</strong>在启动时，向注册中心注册自己提供的服务。 </p>
<p><strong>服务消费者Consumer</strong>在启动时，向注册中心订阅自己所需的服务。 </p>
<p><strong>中心Registry</strong>返回服务提供者地址列表给消费者，如果有变更，注册中心 将基于长连接推送变更数据给消费者。 </p>
<p><strong>服务消费者Consumer</strong>，从提供者地址列表中，基于软负载均衡算法，选一台 提供者进行调用，如果调用失败，再选另一台调用。 </p>
<p><strong>服务消费者Consumer和提供者Provider</strong>，在内存中累计调用次数和调用时 间，定时每分钟发送一次统计数据到监控中心Monitor。</p>
<h2 id="Dubbo-的整体架构设计有哪些分层"><a href="#Dubbo-的整体架构设计有哪些分层" class="headerlink" title="Dubbo 的整体架构设计有哪些分层?"></a>Dubbo 的整体架构设计有哪些分层?</h2><p><img src="/14-Dubbo%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%882020%E6%9C%80%E6%96%B0%E7%89%88%EF%BC%89.assets/Dubbo%E6%95%B4%E4%BD%93%E6%9E%B6%E6%9E%84%E5%88%86%E5%B1%82.png" alt="Dubbo整体架构分层"></p>
<p><strong>接口服务层（Service）：</strong>该层与业务逻辑相关，根据 provider 和 consumer  的业务设计对应的接口和实现 </p>
<p><strong>配置层（Config）：</strong>对外配置接口，以 ServiceConfig 和 ReferenceConfig 为 中心 </p>
<p><strong>服务代理层（Proxy）：</strong>服务接口透明代理，生成服务的客户端 Stub 和 服务端 的 Skeleton，以 ServiceProxy 为中心，扩展接口为 ProxyFactory </p>
<p><strong>服务注册层（Registry）：</strong>封装服务地址的注册和发现，以服务 URL 为中心， 扩展接口为 RegistryFactory、Registry、RegistryService </p>
<p><strong>路由层（Cluster）：</strong>封装多个提供者的路由和负载均衡，并桥接注册中心，以 Invoker 为中心，扩展接口为 Cluster、Directory、Router 和 LoadBlancce </p>
<p><strong>监控层（Monitor）：</strong>RPC 调用次数和调用时间监控，以 Statistics 为中心， 扩展接口为 MonitorFactory、Monitor 和 MonitorService </p>
<p><strong>远程调用层（Protocal）：</strong>封装 RPC 调用，以 Invocation 和 Result 为中心， 扩展接口为 Protocal、Invoker 和 Exporter</p>
<p><strong>信息交换层（Exchange）：</strong>封装请求响应模式，同步转异步。以 Request 和 Response 为中心，扩展接口为 Exchanger、ExchangeChannel、 ExchangeClient 和 ExchangeServer </p>
<p><strong>网络传输层（Transport）：</strong>抽象 mina 和 netty 为统一接口，以 Message  为中心，扩展接口为 Channel、Transporter、Client、Server 和 Codec </p>
<p><strong>数据序列化层（Serialize）：</strong>可复用的一些工具，扩展接口为 Serialization、 ObjectInput、ObjectOutput 和 ThreadPool Dubbo </p>
<h2 id="Monitor-实现原理？"><a href="#Monitor-实现原理？" class="headerlink" title="Monitor 实现原理？"></a>Monitor 实现原理？</h2><p>Consumer 端在发起调用之前会先走 filter 链；provider 端在接收到请求时也 是先走 filter 链，然后才进行真正的业务逻辑处理。默认情况下，在 consumer  和 provider 的 filter 链中都会有 Monitorfilter。 </p>
<ol>
<li>MonitorFilter 向 DubboMonitor 发送数据 </li>
<li>DubboMonitor 将数据进行聚合后（默认聚合 1min 中的统计数据）暂存 到ConcurrentMap statisticsMap，然后使用一个含有 3 个线程（线程名字： DubboMonitorSendTimer）的线程池每隔 1min 钟，调用  SimpleMonitorService 遍历发送 statisticsMap 中的统计数据，每发送完毕一 个，就重置当前的 Statistics 的 AtomicReference </li>
<li>SimpleMonitorService 将这些聚合数据塞入 BlockingQueue queue 中 （队列大写为 100000） </li>
<li>SimpleMonitorService 使用一个后台线程（线程名为： DubboMonitorAsyncWriteLogThread）将 queue 中的数据写入文件（该线 程以死循环的形式来写） </li>
<li>SimpleMonitorService 还会使用一个含有 1 个线程（线程名字： DubboMonitorTimer）的线程池每隔 5min 钟，将文件中的统计数据画成图表</li>
</ol>
<p>分布式框架</p>
<h2 id="Dubbo-类似的分布式框架还有哪些？"><a href="#Dubbo-类似的分布式框架还有哪些？" class="headerlink" title="Dubbo 类似的分布式框架还有哪些？"></a>Dubbo 类似的分布式框架还有哪些？</h2><p>比较著名的就是 Spring Cloud。 </p>
<h2 id="Dubbo-和-Spring-Cloud-有什么关系？"><a href="#Dubbo-和-Spring-Cloud-有什么关系？" class="headerlink" title="Dubbo 和 Spring Cloud 有什么关系？"></a>Dubbo 和 Spring Cloud 有什么关系？</h2><p>Dubbo 是 SOA 时代的产物，它的关注点主要在于服务的调用，流量分发、流 量监控和熔断。而 Spring Cloud 诞生于微服务架构时代，考虑的是微服务治理 的方方面面，另外由于依托了 Spring、Spring Boot 的优势之上，两个框架在 开始目标就不一致，Dubbo 定位服务治理、Spring Cloud 是打造一个生态。 </p>
<h2 id="Dubbo-和-Spring-Cloud-有什么哪些区别？"><a href="#Dubbo-和-Spring-Cloud-有什么哪些区别？" class="headerlink" title="Dubbo 和 Spring Cloud 有什么哪些区别？"></a>Dubbo 和 Spring Cloud 有什么哪些区别？</h2><p>Dubbo 底层是使用 Netty 这样的 NIO 框架，是基于 TCP 协议传输的，配合以 </p>
<p>Hession 序列化完成 RPC 通信。</p>
<p>Spring Cloud 是基于 Http 协议 Rest 接口调用远程过程的通信，相对来说 </p>
<p>Http 请求会有更大的报文，占的带宽也会更多。但是 REST 相比 RPC 更为灵</p>
<p>活，服务提供方和调用方的依赖只依靠一纸契约，不存在代码级别的强依赖，这在强调快速演化的微服务环境下，显得更为合适，至于注重通信速度还是方便灵活性，具体情况具体考虑。</p>
<h2 id="Dubbo-和-Dubbox-之间的区别？"><a href="#Dubbo-和-Dubbox-之间的区别？" class="headerlink" title="Dubbo 和 Dubbox 之间的区别？"></a>Dubbo 和 Dubbox 之间的区别？</h2><p>Dubbox 是继 Dubbo 停止维护后，当当网基于 Dubbo 做的一个扩展项目，如加了服务可 Restful 调用，更新了开源组件等。</p>
<h1 id="注册中心"><a href="#注册中心" class="headerlink" title="注册中心"></a>注册中心</h1><h2 id="Dubbo-有哪些注册中心？"><a href="#Dubbo-有哪些注册中心？" class="headerlink" title="Dubbo 有哪些注册中心？"></a>Dubbo 有哪些注册中心？</h2><ul>
<li>Multicast 注册中心：Multicast 注册中心不需要任何中心节点，只要广播地址，就能进行服务注册和发现,基于网络中组播传输实现。</li>
<li>Zookeeper 注册中心：基于分布式协调系统 Zookeeper 实现，采用 Zookeeper 的 watch 机制实现数据变更。</li>
<li>Redis 注册中心：基于 Redis 实现，采用 key&#x2F;map 存储，key 存储服务名和类型，map 中 key 存储服务 url，value 服务过期时间。基于 Redis 的发布&#x2F;订阅模式通知数据变更。</li>
<li>Simple 注册中心。</li>
</ul>
<p>推荐使用 Zookeeper 作为注册中心</p>
<h2 id="Dubbo-的注册中心集群挂掉，发布者和订阅者之间还能通信么？"><a href="#Dubbo-的注册中心集群挂掉，发布者和订阅者之间还能通信么？" class="headerlink" title="Dubbo 的注册中心集群挂掉，发布者和订阅者之间还能通信么？"></a>Dubbo 的注册中心集群挂掉，发布者和订阅者之间还能通信么？</h2><p>可以通讯。启动 Dubbo 时，消费者会从 Zookeeper 拉取注册的生产者的地址接口等数据，缓存在本地。每次调用时，按照本地存储的地址进行调用。</p>
<h1 id="集群"><a href="#集群" class="headerlink" title="集群"></a>集群</h1><h2 id="Dubbo集群提供了哪些负载均衡策略？"><a href="#Dubbo集群提供了哪些负载均衡策略？" class="headerlink" title="Dubbo集群提供了哪些负载均衡策略？"></a>Dubbo集群提供了哪些负载均衡策略？</h2><ul>
<li>Random LoadBalance: 随机选取提供者策略，有利于动态调整提供者权重。截面碰撞率高，调用次数越多，分布越均匀。</li>
<li>RoundRobin LoadBalance: 轮循选取提供者策略，平均分布，但是存在请求累积的问题。</li>
<li>LeastActive LoadBalance: 少活跃调用策略，解决慢提供者接收更少的请求。</li>
<li>ConstantHash LoadBalance: 一致性 Hash 策略，使相同参数请求总是发到同一提供者，一台机器宕机，可以基于虚拟节点，分摊至其他提供者，避免引起提供者的剧烈变动。</li>
</ul>
<p>默认为 Random 随机调用。</p>
<h2 id="Dubbo的集群容错方案有哪些？"><a href="#Dubbo的集群容错方案有哪些？" class="headerlink" title="Dubbo的集群容错方案有哪些？"></a>Dubbo的集群容错方案有哪些？</h2><ul>
<li>Failover Cluster：失败自动切换，当出现失败，重试其它服务器。通常用于读操作，但重试会带来更长延迟。</li>
<li>Failfast Cluster：快速失败，只发起一次调用，失败立即报错。通常用于非幂等性的写操作，比如新增记录。</li>
<li>Failsafe Cluster：失败安全，出现异常时，直接忽略。通常用于写入审计日志等操作。</li>
<li>Failback Cluster：失败自动恢复，后台记录失败请求，定时重发。通常用于消息通知操作。</li>
<li>Forking Cluster：并行调用多个服务器，只要一个成功即返回。通常用于实时性要求较高的读操作，但需要浪费更多服务资源。可通过 forks&#x3D;”2″ 来设置 大并行数。</li>
<li>Broadcast Cluster：广播调用所有提供者，逐个调用，任意一台报错则报错 。通常用于通知所有提供者更新缓存或日志等本地资源信息。</li>
</ul>
<p>默认的容错方案是 Failover Cluster。</p>
<h1 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h1><h2 id="Dubbo-配置文件是如何加载到-Spring-中的？"><a href="#Dubbo-配置文件是如何加载到-Spring-中的？" class="headerlink" title="Dubbo 配置文件是如何加载到 Spring 中的？"></a>Dubbo 配置文件是如何加载到 Spring 中的？</h2><p>Spring 容器在启动的时候，会读取到 Spring 默认的一些 schema 以及 Dubbo 自定义的 schema，每个 schema 都会对应一个自己的 NamespaceHandler， NamespaceHandler 里面通过 BeanDefinitionParser 来解析配置信息并转化为需要加载的 bean 对象！</p>
<h2 id="说说核心的配置有哪些？"><a href="#说说核心的配置有哪些？" class="headerlink" title="说说核心的配置有哪些？"></a>说说核心的配置有哪些？</h2><table>
<thead>
<tr>
<th>标签</th>
<th>用途</th>
<th>解释</th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>服务配置</td>
<td>用于暴露一个服务，定义服务的元信息，一个服务可以用多个协议暴露，一个服务也可以注册到多个注册中心</td>
</tr>
<tr>
<td></td>
<td>引用配置</td>
<td>用于创建一个远程服务代理，一个引用可以指向多个注册中心</td>
</tr>
<tr>
<td></td>
<td>协议配置</td>
<td>用于配置提供服务的协议信息，协议由提供方指定，消费方被动接受</td>
</tr>
<tr>
<td></td>
<td>应用配置</td>
<td>用于配置当前应用信息，不管该应用是提供者还是消费者</td>
</tr>
<tr>
<td></td>
<td>模块配置</td>
<td>用于配置当前模块信息，可选</td>
</tr>
<tr>
<td></td>
<td>模块配置</td>
<td>用于配置当前模块信息，可选</td>
</tr>
<tr>
<td></td>
<td>注册中心配置</td>
<td>用于配置连接注册中心相关信息</td>
</tr>
<tr>
<td></td>
<td>监控中心配置</td>
<td>用于配置连接监控中心相关信息，可选</td>
</tr>
<tr>
<td></td>
<td>提供方配置</td>
<td>当   ProtocolC onfig 和 ServiceCo nfig 某属  性没有配置时，采用此缺省值，可选</td>
</tr>
<tr>
<td></td>
<td>消费方配置</td>
<td>当   Reference  Config 某属性没有配置时，采用此缺省值，可选</td>
</tr>
<tr>
<td></td>
<td>方法配置</td>
<td>用于   ServiceCo nfig 和 Reference Config 指  定方法级的配置信息</td>
</tr>
<tr>
<td></td>
<td>参数配置</td>
<td>用于指定方法参数配置</td>
</tr>
</tbody></table>
<h2 id="Dubbo-超时设置有哪些方式？"><a href="#Dubbo-超时设置有哪些方式？" class="headerlink" title="Dubbo 超时设置有哪些方式？"></a>Dubbo 超时设置有哪些方式？</h2><p>Dubbo 超时设置有两种方式：</p>
<ul>
<li>服务提供者端设置超时时间，在Dubbo的用户文档中，推荐如果能在服务端多配置就尽量多配置，因为服务提供者比消费者更清楚自己提供的服务特性。</li>
<li>服务消费者端设置超时时间，如果在消费者端设置了超时时间，以消费者端为主，即优先级更高。因为服务调用方设置超时时间控制性更灵活。如果消费方超时，服务端线程不会定制，会产生警告。</li>
</ul>
<h2 id="服务调用超时会怎么样？"><a href="#服务调用超时会怎么样？" class="headerlink" title="服务调用超时会怎么样？"></a>服务调用超时会怎么样？</h2><p>dubbo 在调用服务不成功时，默认是会重试两次。</p>
<h1 id="通信协议"><a href="#通信协议" class="headerlink" title="通信协议"></a>通信协议</h1><h2 id="Dubbo-使用的是什么通信框架"><a href="#Dubbo-使用的是什么通信框架" class="headerlink" title="Dubbo 使用的是什么通信框架?"></a>Dubbo 使用的是什么通信框架?</h2><p>默认使用 Netty 作为通讯框架。</p>
<h2 id="Dubbo-支持哪些协议，它们的优缺点有哪些？"><a href="#Dubbo-支持哪些协议，它们的优缺点有哪些？" class="headerlink" title="Dubbo 支持哪些协议，它们的优缺点有哪些？"></a>Dubbo 支持哪些协议，它们的优缺点有哪些？</h2><ul>
<li>Dubbo： 单一长连接和 NIO 异步通讯，适合大并发小数据量的服务调用，以及消费者远大于提供者。传输协议 TCP，异步 Hessian 序列化。Dubbo推荐使用 dubbo协议。</li>
<li>RMI： 采用 JDK 标准的 RMI 协议实现，传输参数和返回参数对象需要实现</li>
<li>Serializable 接口，使用 Java 标准序列化机制，使用阻塞式短连接，传输数据包大小混合，消费者和提供者个数差不多，可传文件，传输协议 TCP。 多个短连接 TCP </li>
<li>协议传输，同步传输，适用常规的远程服务调用和 RMI 互操作。在依赖低版本的 Common-Collections 包，Java 序列化存在安全漏洞。</li>
<li>WebService：基于 WebService 的远程调用协议，集成 CXF 实现，提供和原生 WebService 的互操作。多个短连接，基于 HTTP 传输，同步传输，适用系统集成和跨语言调用。</li>
<li>HTTP： 基于 Http 表单提交的远程调用协议，使用 Spring 的 HttpInvoke 实现。多个短连接，传输协议 HTTP，传入参数大小混合，提供者个数多于消费者，需要给应用程序和浏览器 JS 调用。</li>
<li>Hessian：集成 Hessian 服务，基于 HTTP 通讯，采用 Servlet 暴露服务，Dubbo 内嵌 Jetty 作为服务器时默认实现，提供与 Hession 服务互操作。多个短连接，同步 HTTP 传输，Hessian 序列化，传入参数较大，提供者大于消费者，提供者压力较大，可传文件。</li>
<li>Memcache：基于 Memcache实现的 RPC 协议。</li>
</ul>
<p>Redis：基于 Redis 实现的RPC协议。</p>
<h1 id="设计模式"><a href="#设计模式" class="headerlink" title="设计模式"></a>设计模式</h1><h2 id="Dubbo-用到哪些设计模式？"><a href="#Dubbo-用到哪些设计模式？" class="headerlink" title="Dubbo 用到哪些设计模式？"></a>Dubbo 用到哪些设计模式？</h2><p>Dubbo 框架在初始化和通信过程中使用了多种设计模式，可灵活控制类加载、权限控制等功能。</p>
<p>工厂模式</p>
<p>Provider 在 export 服务时，会调用 ServiceConfig 的 export 方法。</p>
<p>ServiceConfig中有个字段：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1	private static final Protocol protocol =</span><br><span class="line">2	ExtensionLoader.getExtensionLoader(Protocol.class).getAdaptiveExtensi</span><br><span class="line">3	on();</span><br></pre></td></tr></table></figure>

<p>Dubbo 里有很多这种代码。这也是一种工厂模式，只是实现类的获取采用了</p>
<p>JDKSPI 的机制。这么实现的优点是可扩展性强，想要扩展实现，只需要在</p>
<p>classpath下增加个文件就可以了，代码零侵入。另外，像上面的 Adaptive 实现，可以做到调用时动态决定调用哪个实现，但是由于这种实现采用了动态代理，会造成代码调试比较麻烦，需要分析出实际调用的实现类。</p>
<p>装饰器模式</p>
<p>Dubbo 在启动和调用阶段都大量使用了装饰器模式。以 Provider 提供的调用链为例，具体的调用链代码是在 ProtocolFilterWrapper 的 </p>
<p>buildInvokerChain 完成的，具体是将注解中含有 group&#x3D;provider 的 Filter 实现，按照 order 排序，   后的调用顺序是：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1 EchoFilter ‐&gt; ClassLoaderFilter ‐&gt; GenericFilter ‐&gt; ContextFilter ‐&gt;</span><br><span class="line">2 ExecuteLimitFilter ‐&gt; TraceFilter ‐&gt; TimeoutFilter ‐&gt; MonitorFilter ‐&gt;</span><br><span class="line">3 ExceptionFilter</span><br></pre></td></tr></table></figure>

<p>更确切地说，这里是装饰器和责任链模式的混合使用。例如，EchoFilter 的作用是判断是否是回声测试请求，是的话直接返回内容，这是一种责任链的体现。而像ClassLoaderFilter 则只是在主功能上添加了功能，更改当前线程的 </p>
<p>ClassLoader，这是典型的装饰器模式。</p>
<p>观察者模式</p>
<p>Dubbo 的 Provider 启动时，需要与注册中心交互，先注册自己的服务，再订阅自己的服务，订阅时，采用了观察者模式，开启一个 listener。注册中心会每 5 秒定时检查是否有服务更新，如果有更新，向该服务的提供者发送一个 notify 消息，provider 接受到 notify 消息后，运行 NotifyListener 的 notify 方法，执行监听器方法。</p>
<p>动态代理模式</p>
<p>Dubbo 扩展 JDK SPI 的类 ExtensionLoader 的 Adaptive 实现是典型的动态代理实现。Dubbo 需要灵活地控制实现类，即在调用阶段动态地根据参数决定调用哪个实现类，所以采用先生成代理类的方法，能够做到灵活的调用。生成代理类的代码是 ExtensionLoader 的 createAdaptiveExtensionClassCode 方法。代理类主要逻辑是，获取 URL 参数中指定参数的值作为获取实现类的key。</p>
<h1 id="运维管理"><a href="#运维管理" class="headerlink" title="运维管理"></a>运维管理</h1><h2 id="服务上线怎么兼容旧版本？"><a href="#服务上线怎么兼容旧版本？" class="headerlink" title="服务上线怎么兼容旧版本？"></a>服务上线怎么兼容旧版本？</h2><p>可以用版本号（version）过渡，多个不同版本的服务注册到注册中心，版本号不同的服务相互间不引用。这个和服务分组的概念有一点类似。</p>
<h2 id="Dubbo-telnet-命令能做什么？"><a href="#Dubbo-telnet-命令能做什么？" class="headerlink" title="Dubbo telnet 命令能做什么？"></a>Dubbo telnet 命令能做什么？</h2><p>dubbo 服务发布之后，我们可以利用 telnet 命令进行调试、管理。</p>
<p>Dubbo2.0.5 以上版本服务提供端口支持 telnet 命令</p>
<h2 id="Dubbo-支持服务降级吗？"><a href="#Dubbo-支持服务降级吗？" class="headerlink" title="Dubbo 支持服务降级吗？"></a>Dubbo 支持服务降级吗？</h2><p>以通过 dubbo:reference 中设置 mock&#x3D;“return null”。mock 的值也可以</p>
<p>修改为 true，然后再跟接口同一个路径下实现一个 Mock 类，命名规则是 “接口名称+Mock” 后缀。然后在 Mock 类里实现自己的降级逻辑</p>
<h2 id="Dubbo-如何优雅停机？"><a href="#Dubbo-如何优雅停机？" class="headerlink" title="Dubbo 如何优雅停机？"></a>Dubbo 如何优雅停机？</h2><p>Dubbo 是通过 JDK 的 ShutdownHook 来完成优雅停机的，所以如果使用kill </p>
<p>-9 PID 等强制关闭指令，是不会执行优雅停机的，只有通过 kill PID 时，才会执行。</p>
<h1 id="SPI"><a href="#SPI" class="headerlink" title="SPI"></a>SPI</h1><h2 id="Dubbo-SPI-和-Java-SPI-区别？"><a href="#Dubbo-SPI-和-Java-SPI-区别？" class="headerlink" title="Dubbo SPI 和 Java SPI 区别？"></a>Dubbo SPI 和 Java SPI 区别？</h2><p>JDK SPI：</p>
<p>JDK 标准的 SPI 会一次性加载所有的扩展实现，如果有的扩展很耗时，但也没用上，很浪费资源。所以只希望加载某个的实现，就不现实了</p>
<p>DUBBO SPI：</p>
<p>1、     对 Dubbo 进行扩展，不需要改动 Dubbo 的源码</p>
<p>2、     延迟加载，可以一次只加载自己想要加载的扩展实现。</p>
<p>3、     增加了对扩展点 IOC 和 AOP 的支持，一个扩展点可以直接 setter 注入其它扩展点。</p>
<p>4、     Dubbo 的扩展机制能很好的支持第三方 IoC 容器，默认支持 Spring </p>
<p>Bean。其他</p>
<h2 id="Dubbo-支持分布式事务吗？"><a href="#Dubbo-支持分布式事务吗？" class="headerlink" title="Dubbo 支持分布式事务吗？"></a>Dubbo 支持分布式事务吗？</h2><p>目前暂时不支持，可与通过 tcc-transaction 框架实现介绍：tcc-transaction 是开源的 TCC 补偿性分布式事务框架</p>
<p>TCC-Transaction 通过 Dubbo 隐式传参的功能，避免自己对业务代码的入侵。</p>
<h2 id="Dubbo-可以对结果进行缓存吗？"><a href="#Dubbo-可以对结果进行缓存吗？" class="headerlink" title="Dubbo 可以对结果进行缓存吗？"></a>Dubbo 可以对结果进行缓存吗？</h2><p>为了提高数据访问的速度。Dubbo 提供了声明式缓存，以减少用户加缓存的工作量</p>
<p>其实比普通的配置文件就多了一个标签 cache&#x3D;“true”</p>
<p>Dubbo 必须依赖的包有哪些？</p>
<p>Dubbo 必须依赖 JDK，其他为可选。</p>
<p>Dubbo 支持哪些序列化方式？</p>
<p>默认使用 Hessian 序列化，还有 Duddo、FastJson、Java 自带序列化。</p>
<h2 id="Dubbo-在安全方面有哪些措施？"><a href="#Dubbo-在安全方面有哪些措施？" class="headerlink" title="Dubbo 在安全方面有哪些措施？"></a>Dubbo 在安全方面有哪些措施？</h2><ul>
<li>Dubbo 通过 Token 令牌防止用户绕过注册中心直连，然后在注册中心上管理授权。</li>
<li>Dubbo 还提供服务黑白名单，来控制服务所允许的调用方。</li>
</ul>
<h2 id="服务调用是阻塞的吗？"><a href="#服务调用是阻塞的吗？" class="headerlink" title="服务调用是阻塞的吗？"></a>服务调用是阻塞的吗？</h2><p>默认是阻塞的，可以异步调用，没有返回值的可以这么做。Dubbo 是基于 NIO 的非阻塞实现并行调用，客户端不需要启动多线程即可完成并行调用多个远程服务，相对多线程开销较小，异步调用会返回一个 Future 对象。</p>
<h2 id="服务提供者能实现失效踢出是什么原理？"><a href="#服务提供者能实现失效踢出是什么原理？" class="headerlink" title="服务提供者能实现失效踢出是什么原理？"></a>服务提供者能实现失效踢出是什么原理？</h2><p>服务失效踢出基于 zookeeper 的临时节点原理。</p>
<h2 id="同一个服务多个注册的情况下可以直-连某一个服务吗？"><a href="#同一个服务多个注册的情况下可以直-连某一个服务吗？" class="headerlink" title="同一个服务多个注册的情况下可以直()连某一个服务吗？"></a>同一个服务多个注册的情况下可以直()连某一个服务吗？</h2><p>可以点对点直连，修改配置即可，也可以通过 telnet 直接某个服务。</p>
<h2 id="Dubbo-服务降级，失败重试怎么做？"><a href="#Dubbo-服务降级，失败重试怎么做？" class="headerlink" title="Dubbo 服务降级，失败重试怎么做？"></a>Dubbo 服务降级，失败重试怎么做？</h2><p>可以通过 dubbo:reference 中设置 mock&#x3D;“return null”。mock 的值也可以修改为 true，然后再跟接口同一个路径下实现一个 Mock 类，命名规则是 </p>
<p>“接口名称+Mock” 后缀。然后在 Mock 类里实现自己的降级逻辑</p>
<h2 id="Dubbo-使用过程中都遇到了些什么问题？"><a href="#Dubbo-使用过程中都遇到了些什么问题？" class="headerlink" title="Dubbo 使用过程中都遇到了些什么问题？"></a>Dubbo 使用过程中都遇到了些什么问题？</h2><p>在注册中心找不到对应的服务,检查 service 实现类是否添加了@service 注解无法连接到注册中心,检查配置文件中的对应的测试 ip 是否正确</p>
<h1 id="RPC"><a href="#RPC" class="headerlink" title="RPC"></a>RPC</h1><h2 id="为什么要有RPC"><a href="#为什么要有RPC" class="headerlink" title="为什么要有RPC"></a>为什么要有RPC</h2><p>http接口是在接口不多、系统与系统交互较少的情况下，解决信息孤岛初期常使用的一种通信手段；优点就是简单、直接、开发方便。利用现成的http协议进行传输。但是如果是一个大型的网站，内部子系统较多、接口非常多的情况下，</p>
<p>RPC框架的好处就显示出来了，首先就是长链接，不必每次通信都要像http一样去3次握手什么的，减少了网络开销；其次就是RPC框架一般都有注册中心，有丰富的监控管理；发布、下线接口、动态扩展等，对调用方来说是无感知、统一化的操作。第三个来说就是安全性。  后就是   近流行的服务化架构、服务化治理，RPC框架是一个强力的支撑。</p>
<p>socket只是一个简单的网络通信方式，只是创建通信双方的通信通道，而要实现rpc的功能，还需要对其进行封装，以实现更多的功能。</p>
<p>RPC一般配合netty框架、spring自定义注解来编写轻量级框架，其实netty内部是封装了socket的，较新的jdk的IO一般是NIO，即非阻塞IO，在高并发网站中，RPC的优势会很明显</p>
<h2 id="什么是RPC"><a href="#什么是RPC" class="headerlink" title="什么是RPC"></a>什么是RPC</h2><p>RPC（Remote Procedure Call Protocol）远程过程调用协议，它是一种通过网络从远程计算机程序上请求服务，而不需要了解底层网络技术的协议。简言之，RPC使得程序能够像访问本地系统资源一样，去访问远端系统资源。比较关键的一些方面包括：通讯协议、序列化、资源（接口）描述、服务框架、性能、语言支持等。</p>
<p><img src="/14-Dubbo%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%882020%E6%9C%80%E6%96%B0%E7%89%88%EF%BC%89.assets/RPC.jpg" alt="RPC"></p>
<p>简单的说，RPC就是从一台机器(客户端)上通过参数传递的方式调用另一台机器</p>
<p>(服务器)上的一个函数或方法(可以统称为服务)并得到返回的结果。</p>
<h2 id="PRC架构组件"><a href="#PRC架构组件" class="headerlink" title="PRC架构组件"></a>PRC架构组件</h2><p>一个基本的RPC架构里面应该至少包含以下4个组件：</p>
<p>1、     客户端（Client）:服务调用方（服务消费者）</p>
<p>2、     客户端存根（Client Stub）:存放服务端地址信息，将客户端的请求参数数据信息打包成网络消息，再通过网络传输发送给服务端</p>
<p>3、     服务端存根（Server Stub）:接收客户端发送过来的请求消息并进行解包，然后再调用本地服务进行处理</p>
<p>4、     服务端（Server）:服务的真正提供者</p>
<p><img src="/14-Dubbo%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%882020%E6%9C%80%E6%96%B0%E7%89%88%EF%BC%89.assets/RPC%E6%9E%B6%E6%9E%84%E7%BB%84%E4%BB%B6.jpg" alt="RPC架构组件"></p>
<p>具体调用过程：</p>
<p>1、     服务消费者（client客户端）通过调用本地服务的方式调用需要消费的服务；</p>
<p>2、     客户端存根（client stub）接收到调用请求后负责将方法、入参等信息序列化（组装）成能够进行网络传输的消息体；</p>
<p>3、     客户端存根（client stub）找到远程的服务地址，并且将消息通过网络发送给服务端；</p>
<p>4、     服务端存根（server stub）收到消息后进行解码（反序列化操作）；</p>
<p>5、     服务端存根（server stub）根据解码结果调用本地的服务进行相关处理；</p>
<p>6、     本地服务执行具体业务逻辑并将处理结果返回给服务端存根（server stub）；</p>
<p>7、     服务端存根（server stub）将返回结果重新打包成消息（序列化）并通过网络发送至消费方；</p>
<p>8、     客户端存根（client stub）接收到消息，并进行解码（反序列化）；</p>
<p>9、     服务消费方得到 终结果；而RPC框架的实现目标则是将上面的第2-10步完好地封装起来，也就是把调用、编码&#x2F;解码的过程给封装起来，让用户感觉上像调用本地服务一样的调用远程服务。</p>
<h2 id="RPC和SOA、SOAP、REST的区别"><a href="#RPC和SOA、SOAP、REST的区别" class="headerlink" title="RPC和SOA、SOAP、REST的区别"></a>RPC和SOA、SOAP、REST的区别</h2><p>1、REST</p>
<p>可以看着是HTTP协议的一种直接应用，默认基于JSON作为传输格式,使用简单, 学习成本低效率高,但是安全性较低。</p>
<p>2、SOAP</p>
<p>SOAP是一种数据交换协议规范,是一种轻量的、简单的、基于XML的协议的规范。而SOAP可以看着是一个重量级的协议，基于XML、SOAP在安全方面是通过使用XML-Security和XML-Signature两个规范组成了WS-Security来实现安全控制的,当前已经得到了各个厂商的支持 。</p>
<p>它有什么优点？简单总结为：易用、灵活、跨语言、跨平台。</p>
<p>3、SOA</p>
<p>面向服务架构，它可以根据需求通过网络对松散耦合的粗粒度应用组件进行分布式部署、组合和使用。服务层是SOA的基础，可以直接被应用调用，从而有效控制系统中与软件代理交互的人为依赖性。</p>
<p>SOA是一种粗粒度、松耦合服务架构，服务之间通过简单、精确定义接口进行通讯，不涉及底层编程接口和通讯模型。SOA可以看作是B&#x2F;S模型、XML（标准通用标记语言的子集）&#x2F;Web Service技术之后的自然延伸。</p>
<p>4、REST 和 SOAP、RPC 有何区别呢?</p>
<p>没什么太大区别，他们的本质都是提供可支持分布式的基础服务， 大的区别在于他们各自的的特点所带来的不同应用场景 。</p>
<h2 id="RPC框架需要解决的问题？"><a href="#RPC框架需要解决的问题？" class="headerlink" title="RPC框架需要解决的问题？"></a>RPC框架需要解决的问题？</h2><p>1、     如何确定客户端和服务端之间的通信协议？</p>
<p>2、     如何更高效地进行网络通信？</p>
<p>3、     服务端提供的服务如何暴露给客户端？</p>
<p>4、     客户端如何发现这些暴露的服务？</p>
<p>5、     如何更高效地对请求对象和响应结果进行序列化和反序列化操作？</p>
<h2 id="RPC的实现基础？"><a href="#RPC的实现基础？" class="headerlink" title="RPC的实现基础？"></a>RPC的实现基础？</h2><p>1、     需要有非常高效的网络通信，比如一般选择Netty作为网络通信框架；</p>
<p>2、     需要有比较高效的序列化框架，比如谷歌的Protobuf序列化框架；</p>
<p>3、     可靠的寻址方式（主要是提供服务的发现），比如可以使用Zookeeper来注册服务等等；</p>
<p>4、     如果是带会话（状态）的RPC调用，还需要有会话和状态保持的功能；</p>
<h2 id="RPC使用了哪些关键技术？"><a href="#RPC使用了哪些关键技术？" class="headerlink" title="RPC使用了哪些关键技术？"></a>RPC使用了哪些关键技术？</h2><p>1、动态代理</p>
<p>生成Client Stub（客户端存根）和Server Stub（服务端存根）的时候需要用到 Java动态代理技术，可以使用JDK提供的原生的动态代理机制，也可以使用开源的：CGLib代理，Javassist字节码生成技术。</p>
<p>2、序列化和反序列化在网络中，所有的数据都将会被转化为字节进行传送，所以为了能够使参数对象在网络中进行传输，需要对这些参数进行序列化和反序列化操作。</p>
<ul>
<li>序列化：把对象转换为字节序列的过程称为对象的序列化，也就是编码的过程。</li>
<li>反序列化：把字节序列恢复为对象的过程称为对象的反序列化，也就是解码的过程。</li>
</ul>
<p>目前比较高效的开源序列化框架：如Kryo、FastJson和Protobuf等。</p>
<p>1、NIO通信</p>
<p>出于并发性能的考虑，传统的阻塞式 IO 显然不太合适，因此我们需要异步的 </p>
<p>IO，即 NIO。Java 提供了 NIO 的解决方案，Java 7 也提供了更优秀的 NIO.2 支持。可以选择Netty或者MINA来解决NIO数据传输的问题。</p>
<p>2、服务注册中心</p>
<p>可选：Redis、Zookeeper、Consul 、Etcd。一般使用ZooKeeper提供服务注册与发现功能，解决单点故障以及分布式部署的问题(注册中心)。</p>
<h2 id="主流RPC框架有哪些"><a href="#主流RPC框架有哪些" class="headerlink" title="主流RPC框架有哪些"></a>主流RPC框架有哪些</h2><p>1、RMI</p>
<p>利用java.rmi包实现，基于Java远程方法协议(Java Remote Method Protocol) 和java的原生序列化。</p>
<p>2、Hessian</p>
<p>是一个轻量级的remoting onhttp工具，使用简单的方法提供了RMI的功能。 基于HTTP协议，采用二进制编解码。</p>
<p>3、protobuf-rpc-pro是一个Java类库，提供了基于 Google 的 Protocol Buffers 协议的远程方法调用的框架。基于 Netty 底层的 NIO 技术。支持 TCP 重用&#x2F; keep-alive、SSL加密、RPC 调用取消操作、嵌入式日志等功能。</p>
<p>4、Thrift</p>
<p>是一种可伸缩的跨语言服务的软件框架。它拥有功能强大的代码生成引擎，无缝地支持C + +，C#，Java，Python和PHP和Ruby。thrift允许你定义一个描述</p>
<p>文件，描述数据类型和服务接口。依据该文件，编译器方便地生成RPC客户端和服务器通信代码。</p>
<p>初由facebook开发用做系统内个语言之间的RPC通信，2007年由facebook 贡献到apache基金 ，现在是apache下的opensource之一 。支持多种语言之间的RPC方式的通信：php语言client可以构造一个对象，调用相应的服务方法</p>
<p>来调用java语言的服务，跨越语言的C&#x2F;S RPC调用。底层通讯基于SOCKET。</p>
<p>5、Avro</p>
<p>出自Hadoop之父Doug Cutting, 在Thrift已经相当流行的情况下推出Avro的目标不仅是提供一套类似Thrift的通讯中间件,更是要建立一个新的，标准性的云计算的数据交换和存储的Protocol。支持HTTP，TCP两种协议。</p>
<p>6、Dubbo</p>
<p>Dubbo是 阿里巴巴公司开源的一个高性能优秀的服务框架，使得应用可通过高</p>
<p>性能的 RPC 实现服务的输出和输入功能，可以和 Spring框架无缝集成。</p>
<h2 id="RPC的实现原理架构图"><a href="#RPC的实现原理架构图" class="headerlink" title="RPC的实现原理架构图"></a>RPC的实现原理架构图</h2><p><img src="/14-Dubbo%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%882020%E6%9C%80%E6%96%B0%E7%89%88%EF%BC%89.assets/RPC%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86.jpg" alt="RPC的实现原理"></p>
<p><img src="/14-Dubbo%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%882020%E6%9C%80%E6%96%B0%E7%89%88%EF%BC%89.assets/RPC%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86.jpg" alt="RPC的基本原理"></p>
<p>PS：这张图非常重点，是PRC的基本原理，请大家一定记住！也就是说两台服务器A，B，一个应用部署在A服务器上，想要调用B服务器上应用提供的函数&#x2F;方法，由于不在一个内存空间，不能直接调用，需要通过网络来表达调用的语义和传达调用的数据。</p>
<p>比如说，A服务器想调用B服务器上的一个方法：</p>
<p>User getUserByName(String userName)</p>
<p>1、建立通信首先要解决通讯的问题：即A机器想要调用B机器，首先得建立起通信连接。</p>
<p>主要是通过在客户端和服务器之间建立TCP连接，远程过程调用的所有交换的数据都在这个连接里传输。连接可以是按需连接，调用结束后就断掉，也可以是长连接，多个远程过程调用共享同一个连接。</p>
<p>通常这个连接可以是按需连接（需要调用的时候就先建立连接，调用结束后就立马断掉），也可以是长连接（客户端和服务器建立起连接之后保持长期持有，不管此时有无数据包的发送，可以配合心跳检测机制定期检测建立的连接是否存活有效），多个远程过程调用共享同一个连接。</p>
<p>2、服务寻址要解决寻址的问题，也就是说，A服务器上的应用怎么告诉底层的RPC框架，如何连接到B服务器（如主机或IP地址）以及特定的端口，方法的名称名称是什么。</p>
<p>通常情况下我们需要提供B机器（主机名或IP地址）以及特定的端口，然后指定调用的方法或者函数的名称以及入参出参等信息，这样才能完成服务的一个调用。</p>
<p>可靠的寻址方式（主要是提供服务的发现）是RPC的实现基石，比如可以采用</p>
<p>Redis或者Zookeeper来注册服务等等。</p>
<p><img src="/14-Dubbo%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%882020%E6%9C%80%E6%96%B0%E7%89%88%EF%BC%89.assets/RPC.jpg" alt="RPC"></p>
<p>2.1、   从服务提供者的角度看：当服务提供者启动的时候，需要将自己提供的服务注册到指定的注册中心，以便服务消费者能够通过服务注册中心进行查找；当服务提供者由于各种原因致使提供的服务停止时，需要向注册中心注销停止的服务；服务的提供者需要定期向服务注册中心发送心跳检测，服务注册中心如果一段时间未收到来自服务提供者的心跳后，认为该服务提供者已经停止服务，则将该服务从注册中心上去掉。</p>
<p>2.2、   从调用者的角度看：服务的调用者启动的时候根据自己订阅的服务向服务注册中心查找服务提供者的地址等信息；当服务调用者消费的服务上线或者下线的时候，注册中心会告知该服务的调用者；服务调用者下线的时候，则取消订阅。</p>
<p>3、网络传输3.1、序列化</p>
<p>当A机器上的应用发起一个RPC调用时，调用方法和其入参等信息需要通过底层的网络协议如TCP传输到B机器，由于网络协议是基于二进制的，所有我们传输的参数数据都需要先进行序列化（Serialize）或者编组（marshal）成二进制的形式才能在网络中进行传输。然后通过寻址操作和网络传输将序列化或者编组之后的二进制数据发送给B机器。</p>
<p>3.2、反序列化</p>
<p>当B机器接收到A机器的应用发来的请求之后，又需要对接收到的参数等信息进行反序列化操作（序列化的逆操作），即将二进制信息恢复为内存中的表达方</p>
<p>式，然后再找到对应的方法（寻址的一部分）进行本地调用（一般是通过生成代理Proxy去调用,</p>
<p>通常会有JDK动态代理、CGLIB动态代理、Javassist生成字节码技术等），之后得到调用的返回值。</p>
<p>4、服务调用</p>
<p>B机器进行本地调用（通过代理Proxy和反射调用）之后得到了返回值，此时还需要再把返回值发送回A机器，同样也需要经过序列化操作，然后再经过网络传输将二进制数据发送回A机器，而当A机器接收到这些返回值之后，则再次进行反序列化操作，恢复为内存中的表达方式，  后再交给A机器上的应用进行相关处理（一般是业务逻辑处理操作）。通常，经过以上四个步骤之后，一次完整的RPC调用算是完成了，另外可能因为网络抖动等原因需要重试等。</p>

      
    </div>

    
    
    

       
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/10/12/13-ZooKeeper%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%882020%E6%9C%80%E6%96%B0%E7%89%88%EF%BC%89-%E9%87%8D%E7%82%B9/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="善善332">
      <meta itemprop="description" content="运气和努力一样重要">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="和善寺">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/10/12/13-ZooKeeper%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%882020%E6%9C%80%E6%96%B0%E7%89%88%EF%BC%89-%E9%87%8D%E7%82%B9/" class="post-title-link" itemprop="url">未命名</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-10-12 15:01:16" itemprop="dateCreated datePublished" datetime="2022-10-12T15:01:16+08:00">2022-10-12</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-03-03 13:51:31" itemprop="dateModified" datetime="2021-03-03T13:51:31+08:00">2021-03-03</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="1-ZooKeeper-是什么？"><a href="#1-ZooKeeper-是什么？" class="headerlink" title="1. ZooKeeper 是什么？"></a>1. ZooKeeper 是什么？</h2><p>ZooKeeper 是一个开源的分布式协调服务。它是一个为分布式应用提供一致性 服务的软件，分布式应用程序可以基于 Zookeeper 实现诸如数据发布&#x2F;订阅、 负载均衡、命名服务、分布式协调&#x2F;通知、集群管理、Master 选举、分布式锁和 分布式队列等功能。 </p>
<p>ZooKeeper 的目标就是封装好复杂易出错的关键服务，将简单易用的接口和性 能高效、功能稳定的系统提供给用户。 </p>
<p>Zookeeper 保证了如下分布式一致性特性： </p>
<p>（1）顺序一致性 </p>
<p>（2）原子性 </p>
<p>（3）单一视图 </p>
<p>（4）可靠性 </p>
<p>（5）实时性（最终一致性） </p>
<p>客户端的读请求可以被集群中的任意一台机器处理，如果读请求在节点上注册了 监听器，这个监听器也是由所连接的 zookeeper 机器来处理。对于写请求，这 些请求会同时发给其他 zookeeper 机器并且达成一致后，请求才会返回成功。</p>
<p>因此，随着 zookeeper 的集群机器增多，读请求的吞吐会提高但是写请求的吞 吐会下降。 </p>
<p>有序性是 zookeeper 中非常重要的一个特性，所有的更新都是全局有序的，每 个更新都有一个唯一的时间戳，这个时间戳称为 zxid（Zookeeper  Transaction Id）。而读请求只会相对于更新有序，也就是读请求的返回结果中 会带有这个zookeeper 最新的 zxid。 </p>
<h2 id="2-ZooKeeper-提供了什么？"><a href="#2-ZooKeeper-提供了什么？" class="headerlink" title="2. ZooKeeper 提供了什么？"></a>2. ZooKeeper 提供了什么？</h2><ul>
<li>文件系统 </li>
<li>通知机制</li>
</ul>
<h2 id="3-Zookeeper-文件系统"><a href="#3-Zookeeper-文件系统" class="headerlink" title="3. Zookeeper 文件系统"></a>3. Zookeeper 文件系统</h2><p>Zookeeper 提供一个多层级的节点命名空间（节点称为 znode）。与文件系统 不同的是，这些节点都可以设置关联的数据，而文件系统中只有文件节点可以存 放数据而目录节点不行。 </p>
<p>Zookeeper 为了保证高吞吐和低延迟，在内存中维护了这个树状的目录结构， 这种特性使得 Zookeeper 不能用于存放大量的数据，每个节点的存放数据上限 为1M。 </p>
<h2 id="4-Zookeeper-怎么保证主从节点的状态同步？"><a href="#4-Zookeeper-怎么保证主从节点的状态同步？" class="headerlink" title="4. Zookeeper 怎么保证主从节点的状态同步？"></a>4. Zookeeper 怎么保证主从节点的状态同步？</h2><p>Zookeeper 的核心是原子广播机制，这个机制保证了各个 server 之间的同步。 实现这个机制的协议叫做 Zab 协议。Zab 协议有两种模式，它们分别是恢复模 式和广播模式。 </p>
<p>恢复模式 </p>
<p>当服务启动或者在领导者崩溃后，Zab就进入了恢复模式，当领导者被选举出 来，且大多数 server 完成了和 leader 的状态同步以后，恢复模式就结束了。状 态同步保证了 leader 和 server 具有相同的系统状态。 </p>
<p>广播模式 </p>
<p>一旦 leader 已经和多数的 follower 进行了状态同步后，它就可以开始广播消息 了，即进入广播状态。这时候当一个 server 加入 ZooKeeper 服务中，它会在 恢复模式下启动，发现 leader，并和 leader 进行状态同步。待到同步结束，它也参与消息广播。ZooKeeper 服务一直维持在 Broadcast 状态，直到 leader  崩溃了或者 leader 失去了大部分的 followers 支持。 </p>
<h2 id="5-四种类型的数据节点-Znode"><a href="#5-四种类型的数据节点-Znode" class="headerlink" title="5. 四种类型的数据节点 Znode"></a>5. 四种类型的数据节点 Znode</h2><p>（1）PERSISTENT-持久节点<br>除非手动删除，否则节点一直存在于 Zookeeper 上 </p>
<p>（2）EPHEMERAL-临时节点<br>临时节点的生命周期与客户端会话绑定，一旦客户端会话失效（客户端与 zookeeper 连接断开不一定会话失效），那么这个客户端创建的所有临时节点 都会被移除。 </p>
<p>（3）PERSISTENT_SEQUENTIAL-持久顺序节点<br>基本特性同持久节点，只是增加了顺序属性，节点名后边会追加一个由父节点维 护的自增整型数字。 </p>
<p>（4）EPHEMERAL_SEQUENTIAL-临时顺序节点<br>基本特性同临时节点，增加了顺序属性，节点名后边会追加一个由父节点维护的 自增整型数字。 </p>
<h2 id="6-Zookeeper-Watcher-机制-–-数据变更通知"><a href="#6-Zookeeper-Watcher-机制-–-数据变更通知" class="headerlink" title="6. Zookeeper Watcher 机制 – 数据变更通知"></a>6. Zookeeper Watcher 机制 – 数据变更通知</h2><p>Zookeeper 允许客户端向服务端的某个 Znode 注册一个 Watcher 监听，当服 务端的一些指定事件触发了这个 Watcher，服务端会向指定客户端发送一个事 件通知来实现分布式的通知功能，然后客户端根据 Watcher 通知状态和事件类 型做出业务上的改变。 </p>
<p>工作机制： </p>
<p>（1）客户端注册 watcher </p>
<p>（2）服务端处理 watcher </p>
<p>（3）客户端回调 watcher </p>
<p>Watcher 特性总结：</p>
<p>（1）一次性 </p>
<p>无论是服务端还是客户端，一旦一个 Watcher 被 触 发 ，Zookeeper 都会将其 从相应的存储中移除。这样的设计有效的减轻了服务端的压力，不然对于更新非常频繁的节点，服务端会不断的向客户端发送事件通知，无论对于网络还是服务 端的压力都非常大。</p>
<p> （2）客户端串行执行 客户端 Watcher 回调的过程是一个串行同步的过程。 </p>
<p>（3）轻量 </p>
<p>3.1、Watcher 通知非常简单，只会告诉客户端发生了事件，而不会说明事件的 具体内容。 </p>
<p>3.2、客户端向服务端注册 Watcher 的时候，并不会把客户端真实的 Watcher  对象实体传递到服务端，仅仅是在客户端请求中使用 boolean 类型属性进行了 标记。 </p>
<p>（4）watcher event 异步发送 watcher 的通知事件从 server 发送到 client 是 异步的，这就存在一个问题，不同的客户端和服务器之间通过 socket 进行通 信，由于网络延迟或其他因素导致客户端在不通的时刻监听到事件，由于  Zookeeper 本身提供了 ordering guarantee，即客户端监听事件后，才会感知 它所监视 znode发生了变化。所以我们使用 Zookeeper 不能期望能够监控到节 点每次的变化。Zookeeper 只能保证最终的一致性，而无法保证强一致性。 </p>
<p>（5）注册 watcher getData、exists、getChildren </p>
<p>（6）触发 watcher create、delete、setData </p>
<p>（7）当一个客户端连接到一个新的服务器上时，watch 将会被以任意会话事件 触发。当与一个服务器失去连接的时候，是无法接收到 watch 的。而当 client  重新连接时，如果需要的话，所有先前注册过的 watch，都会被重新注册。通 常这是完全透明的。只有在一个特殊情况下，watch 可能会丢失：对于一个未 创建的 znode的 exist watch，如果在客户端断开连接期间被创建了，并且随后 在客户端连接上之前又删除了，这种情况下，这个 watch 事件可能会被丢失。 </p>
<h2 id="7-客户端注册-Watcher-实现"><a href="#7-客户端注册-Watcher-实现" class="headerlink" title="7. 客户端注册 Watcher 实现"></a>7. 客户端注册 Watcher 实现</h2><p>（1）调用 getData()&#x2F;getChildren()&#x2F;exist()三个 API，传入 Watcher 对象 </p>
<p>（2）标记请求 request，封装 Watcher 到 WatchRegistration </p>
<p>（3）封装成 Packet 对象，发服务端发送 request </p>
<p>（4）收到服务端响应后，将 Watcher 注册到 ZKWatcherManager 中进行管 理</p>
<p>（5）请求返回，完成注册。</p>
<h2 id="8-服务端处理-Watcher-实现"><a href="#8-服务端处理-Watcher-实现" class="headerlink" title="8. 服务端处理 Watcher 实现"></a>8. 服务端处理 Watcher 实现</h2><p>（1）服务端接收 Watcher 并存储<br>接收到客户端请求，处理请求判断是否需要注册 Watcher，需要的话将数据节 点的节点路径和 ServerCnxn（ServerCnxn 代表一个客户端和服务端的连接， 实现了 Watcher 的 process 接口，此时可以看成一个 Watcher 对象）存储在 WatcherManager 的 WatchTable 和 watch2Paths 中去。 </p>
<p>（2）Watcher 触发<br>以服务端接收到 setData() 事务请求触发 NodeDataChanged 事件为例： </p>
<p>2.1 封装 WatchedEvent 将通知状态（SyncConnected）、事件类型（NodeDataChanged）以及节点 路径封装成一个 WatchedEvent 对象 </p>
<p>2.2 查询 Watcher 从 WatchTable 中根据节点路径查找 Watcher 2.3 没找到；说明没有客户端在该数据节点上注册过 Watcher 2.4 找到；提取并从 WatchTable 和 Watch2Paths 中删除对应 Watcher（从 这里可以看出 Watcher 在服务端是一次性的，触发一次就失效了） </p>
<p>（3）调用 process 方法来触发 Watcher 这里 process 主要就是通过 ServerCnxn 对应的 TCP 连接发送 Watcher 事件 通知。</p>
<h2 id="9-客户端回调-Watcher"><a href="#9-客户端回调-Watcher" class="headerlink" title="9. 客户端回调 Watcher"></a>9. 客户端回调 Watcher</h2><p>客户端 SendThread 线程接收事件通知，交由 EventThread 线程回调  Watcher。 </p>
<p>客户端的 Watcher 机制同样是一次性的，一旦被触发后，该 Watcher 就失效 了。 </p>
<h2 id="10-ACL-权限控制机制"><a href="#10-ACL-权限控制机制" class="headerlink" title="10. ACL 权限控制机制"></a>10. ACL 权限控制机制</h2><p>UGO（User&#x2F;Group&#x2F;Others） </p>
<p>目前在 Linux&#x2F;Unix 文件系统中使用，也是使用最广泛的权限控制方式。是一种 粗粒度的文件系统权限控制模式。</p>
<p>ACL（Access Control List）访问控制列表 </p>
<p>包括三个方面： </p>
<p>**权限模式（Scheme） **</p>
<p>（1）IP：从 IP 地址粒度进行权限控制 </p>
<p>（2）Digest：最常用，用类似于 username:password 的权限标识来进行权限 配置，便于区分不同应用来进行权限控制 </p>
<p>（3）World：最开放的权限控制方式，是一种特殊的 digest 模式，只有一个 权限标识“world:anyone” </p>
<p>（4）Super：超级用户 </p>
<p>**授权对象 **</p>
<p>授权对象指的是权限赋予的用户或一个指定实体，例如 IP 地址或是机器灯。 </p>
<p>**权限 Permission **</p>
<p>（1）CREATE：数据节点创建权限，允许授权对象在该 Znode 下创建子节点 </p>
<p>（2）DELETE：子节点删除权限，允许授权对象删除该数据节点的子节点 </p>
<p>（3）READ：数据节点的读取权限，允许授权对象访问该数据节点并读取其数 据内容或子节点列表等 </p>
<p>（4）WRITE：数据节点更新权限，允许授权对象对该数据节点进行更新操作 </p>
<p>（5）ADMIN：数据节点管理权限，允许授权对象对该数据节点进行 ACL 相关 设置操作</p>
<h1 id="11-Chroot-特性"><a href="#11-Chroot-特性" class="headerlink" title="11. Chroot 特性"></a>11. Chroot 特性</h1><p>3.2.0 版本后，添加了 Chroot 特性，该特性允许每个客户端为自己设置一个命名空间。如果一个客户端设置了 Chroot，那么该客户端对服务器的任何操作，都将会被限制在其自己的命名空间下。</p>
<p>通过设置 Chroot，能够将一个客户端应用于 Zookeeper 服务端的一颗子树相对应，在那些多个应用公用一个 Zookeeper 进群的场景下，对实现不同应用间的相互隔离非常有帮助。</p>
<h1 id="12-会话管理"><a href="#12-会话管理" class="headerlink" title="12. 会话管理"></a>12. 会话管理</h1><p>分桶策略：将类似的会话放在同一区块中进行管理，以便于 Zookeeper 对会话进行不同区块的隔离处理以及同一区块的统一处理。分配原则：每个会话的“下次超时时间点”（ExpirationTime）</p>
<p>计算公式：</p>
<p>ExpirationTime_ &#x3D; currentTime + sessionTimeout</p>
<p>ExpirationTime &#x3D; (ExpirationTime_ &#x2F; ExpirationInrerval + 1) *</p>
<p>ExpirationInterval , ExpirationInterval 是指 Zookeeper 会话超时检查时间间隔，默认 tickTime</p>
<h1 id="13-服务器角色"><a href="#13-服务器角色" class="headerlink" title="13. 服务器角色"></a>13. 服务器角色</h1><p>Leader</p>
<p>（1）  事务请求的唯一调度和处理者，保证集群事务处理的顺序性</p>
<p>（2）  集群内部各服务的调度者</p>
<p>Follower</p>
<p>（1）  处理客户端的非事务请求，转发事务请求给 Leader 服务器</p>
<p>（2）  参与事务请求 Proposal 的投票</p>
<p>（3）  参与 Leader 选举投票</p>
<p>Observer</p>
<p>（1）3.0 版本以后引入的一个服务器角色，在不影响集群事务处理能力的基础</p>
<p>上提升集群的非事务处理能力</p>
<p>（2）  处理客户端的非事务请求，转发事务请求给 Leader 服务器</p>
<p>（3）  不参与任何形式的投票</p>
<h1 id="14-Zookeeper-下-Server-工作状态"><a href="#14-Zookeeper-下-Server-工作状态" class="headerlink" title="14. Zookeeper 下 Server 工作状态"></a>14. Zookeeper 下 Server 工作状态</h1><p>服务器具有四种状态，分别是 LOOKING、FOLLOWING、LEADING、 OBSERVING。</p>
<p>（1）  LOOKING：寻 找 Leader 状态。当服务器处于该状态时，它会认为当前集群中没有 Leader，因此需要进入 Leader 选举状态。</p>
<p>（2）  FOLLOWING：跟随者状态。表明当前服务器角色是 Follower。（3）LEADING：领导者状态。表明当前服务器角色是 Leader。</p>
<p>（4）OBSERVING：观察者状态。表明当前服务器角色是 Observer。</p>
<h1 id="15-数据同步"><a href="#15-数据同步" class="headerlink" title="15. 数据同步"></a>15. 数据同步</h1><p>整个集群完成 Leader 选举之后，Learner（Follower 和 Observer 的统称）回向Leader 服务器进行注册。当 Learner 服务器想 Leader 服务器完成注册后，进入数据同步环节。数据同步流程：（均以消息传递的方式进行）</p>
<p>Learner 向 Learder 注册</p>
<p>数据同步同步确认</p>
<p>Zookeeper 的数据同步通常分为四类：</p>
<p>（1）  直接差异化同步（DIFF 同步）</p>
<p>（2）  先回滚再差异化同步（TRUNC+DIFF 同步）</p>
<p>（3）  仅回滚同步（TRUNC 同步）（4）全量同步（SNAP 同步）</p>
<p>在进行数据同步前，Leader 服务器会完成数据同步初始化： peerLastZxid：</p>
<p>∙ 从 learner 服务器注册时发送的 ACKEPOCH 消息中提取 lastZxid（该Learner 服务器最后处理的 ZXID）</p>
<p>minCommittedLog：</p>
<p>∙ Leader 服务器 Proposal 缓存队列 committedLog 中最小 </p>
<p>ZXIDmaxCommittedLog：</p>
<p>∙ Leader 服务器 Proposal 缓存队列 committedLog 中最大 ZXID直接差异化同步（DIFF 同步）</p>
<p>∙ 场景：peerLastZxid 介于 minCommittedLog 和 maxCommittedLog之间先回滚再差异化同步（TRUNC+DIFF 同步）</p>
<p>∙ 场景：当新的 Leader 服务器发现某个 Learner 服务器包含了一条自己没有的事务记录，那么就需要让该 Learner 服务器进行事务回滚–回滚到 Leader服务器上存在的，同时也是最接近于 peerLastZxid 的 ZXID仅回滚同步（TRUNC 同步）</p>
<p>∙ 场景：peerLastZxid 大于 maxCommittedLog 全量同步（SNAP 同步）</p>
<p>∙ 场景一：peerLastZxid 小于 minCommittedLog</p>
<p>∙ 场景二：Leader 服务器上没有 Proposal 缓存队列且 peerLastZxid 不等于 lastProcessZxid</p>
<h1 id="16-zookeeper-是如何保证事务的顺序一致性的？"><a href="#16-zookeeper-是如何保证事务的顺序一致性的？" class="headerlink" title="16. zookeeper 是如何保证事务的顺序一致性的？"></a>16. zookeeper 是如何保证事务的顺序一致性的？</h1><p>zookeeper 采用了全局递增的事务 Id 来标识，所有的 proposal（提议）都在被提出的时候加上了 zxid，zxid 实际上是一个 64 位的数字，高 32 位是 </p>
<p>epoch（ 时期; 纪元; 世; 新时代）用来标识 leader 周期，如果有新的 leader 产生出来，epoch会自增，低 32 位用来递增计数。当新产生 proposal 的时候，会依据数据库的两阶段过程，首先会向其他的 server 发出事务执行请求，如果超过半数的机器都能执行并且能够成功，那么就会开始执行。</p>
<h1 id="17-分布式集群中为什么会有-Master主节点？"><a href="#17-分布式集群中为什么会有-Master主节点？" class="headerlink" title="17. 分布式集群中为什么会有 Master主节点？"></a>17. 分布式集群中为什么会有 Master主节点？</h1><p>在分布式环境中，有些业务逻辑只需要集群中的某一台机器进行执行，其他的机器可以共享这个结果，这样可以大大减少重复计算，提高性能，于是就需要进行 leader 选举。</p>
<h1 id="18-zk-节点宕机如何处理？"><a href="#18-zk-节点宕机如何处理？" class="headerlink" title="18. zk 节点宕机如何处理？"></a>18. zk 节点宕机如何处理？</h1><p>Zookeeper 本身也是集群，推荐配置不少于 3 个服务器。Zookeeper 自身也要保证当一个节点宕机时，其他节点会继续提供服务。</p>
<p>如果是一个 Follower 宕机，还有 2 台服务器提供访问，因为 Zookeeper 上的数据是有多个副本的，数据并不会丢失；</p>
<p>如果是一个 Leader 宕机，Zookeeper 会选举出新的 Leader。</p>
<p>ZK 集群的机制是只要超过半数的节点正常，集群就能正常提供服务。只有在</p>
<p>ZK节点挂得太多，只剩一半或不到一半节点能工作，集群才失效。</p>
<p>所以</p>
<p>3 个节点的 cluster 可以挂掉 1 个节点(leader 可以得到 2 票&gt;1.5)</p>
<p>2 个节点的 cluster 就不能挂掉任何 1 个节点了(leader 可以得到 1 票&lt;&#x3D;1) 19. zookeeper 负载均衡和 nginx 负载均衡区别</p>
<p>zk 的负载均衡是可以调控，nginx 只是能调权重，其他需要可控的都需要自己写插件；但是 nginx 的吞吐量比 zk 大很多，应该说按业务选择用哪种方式。</p>
<h1 id="20-Zookeeper-有哪几种几种部署模式？"><a href="#20-Zookeeper-有哪几种几种部署模式？" class="headerlink" title="20. Zookeeper 有哪几种几种部署模式？"></a>20. Zookeeper 有哪几种几种部署模式？</h1><p>Zookeeper 有三种部署模式：</p>
<ol>
<li><p>单机部署：一台集群上运行；</p>
</li>
<li><p>集群部署：多台集群运行；</p>
</li>
<li><p>伪集群部署：一台集群启动多个 Zookeeper 实例运行。</p>
</li>
</ol>
<h1 id="21-集群最少要几台机器，集群规则是怎样的？集群中有-3-台服务器，其中一个节点宕机，这个时候-Zookeeper-还可以使用吗？"><a href="#21-集群最少要几台机器，集群规则是怎样的？集群中有-3-台服务器，其中一个节点宕机，这个时候-Zookeeper-还可以使用吗？" class="headerlink" title="21. 集群最少要几台机器，集群规则是怎样的？集群中有 3 台服务器，其中一个节点宕机，这个时候 Zookeeper 还可以使用吗？"></a>21. 集群最少要几台机器，集群规则是怎样的？集群中有 3 台服务器，其中一个节点宕机，这个时候 Zookeeper 还可以使用吗？</h1><p>集群规则为 2N+1 台，N&gt;0，即 3 台。可以继续使用，单数服务器只要没超过一半的服务器宕机就可以继续使用。</p>
<h1 id="22-集群支持动态添加机器吗？"><a href="#22-集群支持动态添加机器吗？" class="headerlink" title="22. 集群支持动态添加机器吗？"></a>22. 集群支持动态添加机器吗？</h1><p>其实就是水平扩容了，Zookeeper 在这方面不太好。两种方式：</p>
<p>全部重启：关闭所有 Zookeeper 服务，修改配置之后启动。不影响之前客户端的会话。</p>
<p>逐个重启：在过半存活即可用的原则下，一台机器重启不影响整个集群对外提供服务。这是比较常用的方式。</p>
<p>3.5 版本开始支持动态扩容。</p>
<ol start="23">
<li><h1 id="Zookeeper-对节点的-watch-监听通知是永久的吗？为什么不是永久的"><a href="#Zookeeper-对节点的-watch-监听通知是永久的吗？为什么不是永久的" class="headerlink" title="Zookeeper 对节点的 watch 监听通知是永久的吗？为什么不是永久的?"></a>Zookeeper 对节点的 watch 监听通知是永久的吗？为什么不是永久的?</h1></li>
</ol>
<p>不是。官方声明：一个 Watch 事件是一个一次性的触发器，当被设置了 Watch 的数据发生了改变的时候，则服务器将这个改变发送给设置了 Watch 的客户端，以便通知它们。</p>
<p>为什么不是永久的，举个例子，如果服务端变动频繁，而监听的客户端很多情况</p>
<p>下，每次变动都要通知到所有的客户端，给网络和服务器造成很大压力。</p>
<p>一般是客户端执行 getData(“&#x2F;节点 A”,true)，如果节点 A 发生了变更或删除，客户端会得到它的 watch 事件，但是在之后节点 A 又发生了变更，而客户端又没有设置 watch 事件，就不再给客户端发送。在实际应用中，很多情况下，我们的客户端不需要知道服务端的每一次变动，我只要最新的数据即可。</p>
<h1 id="24-Zookeeper-的-java-客户端都有哪些？"><a href="#24-Zookeeper-的-java-客户端都有哪些？" class="headerlink" title="24. Zookeeper 的 java 客户端都有哪些？"></a>24. Zookeeper 的 java 客户端都有哪些？</h1><p>java 客户端：zk 自带的 zkclient 及 Apache 开源的 Curator。</p>
<h1 id="25-chubby-是什么，和-zookeeper-比你怎么看？"><a href="#25-chubby-是什么，和-zookeeper-比你怎么看？" class="headerlink" title="25. chubby 是什么，和 zookeeper 比你怎么看？"></a>25. chubby 是什么，和 zookeeper 比你怎么看？</h1><p>chubby 是 google 的，完全实现 paxos 算法，不开源。zookeeper 是 chubby的开源实现，使用 zab 协议，paxos 算法的变种。</p>
<h1 id="26-说几个-zookeeper-常用的命令。"><a href="#26-说几个-zookeeper-常用的命令。" class="headerlink" title="26. 说几个 zookeeper 常用的命令。"></a>26. 说几个 zookeeper 常用的命令。</h1><p>常用命令：ls get set create delete 等。</p>
<h1 id="27-ZAB-和-Paxos-算法的联系与区别？"><a href="#27-ZAB-和-Paxos-算法的联系与区别？" class="headerlink" title="27. ZAB 和 Paxos 算法的联系与区别？"></a>27. ZAB 和 Paxos 算法的联系与区别？</h1><p>相同点：</p>
<p>（1）  两者都存在一个类似于 Leader 进程的角色，由其负责协调多个 Follower 进程的运行</p>
<p>（2）  Leader 进程都会等待超过半数的 Follower 做出正确的反馈后，才会将一个提案进行提交</p>
<p>（3）  ZAB 协议中，每个 Proposal 中都包含一个 epoch 值来代表当前的 </p>
<p>Leader周期，Paxos 中名字为 Ballot 不同点：</p>
<p>ZAB 用来构建高可用的分布式数据主备系统（Zookeeper），Paxos 是用来构建分布式一致性状态机系统。</p>
<h1 id="28-Zookeeper-的典型应用场景"><a href="#28-Zookeeper-的典型应用场景" class="headerlink" title="28. Zookeeper 的典型应用场景"></a>28. Zookeeper 的典型应用场景</h1><p>Zookeeper 是一个典型的发布&#x2F;订阅模式的分布式数据管理与协调框架，开发人员可以使用它来进行分布式数据的发布和订阅。</p>
<p>通过对 Zookeeper 中丰富的数据节点进行交叉使用，配合 Watcher 事件通知机制，可以非常方便的构建一系列分布式应用中年都会涉及的核心功能，如：</p>
<p>（1）  数据发布&#x2F;订阅</p>
<p>（2）  负载均衡</p>
<p>（3）  命名服务</p>
<p>（4）  分布式协调&#x2F;通知</p>
<p>（5）  集群管理</p>
<p>（6）  Master 选举</p>
<p>（7）  分布式锁</p>
<p>（8）  分布式队列数据发布&#x2F;订阅介绍数据发布&#x2F;订阅系统，即所谓的配置中心，顾名思义就是发布者发布数据供订阅者进行数据订阅。</p>
<p>目的动态获取数据（配置信息）实现数据（配置信息）的集中式管理和数据的动态更新设计模式</p>
<p>Push 模式</p>
<p>Pull 模式</p>
<p>数据（配置信息）特性</p>
<p>（1）  数据量通常比较小</p>
<p>（2）  数据内容在运行时会发生动态更新</p>
<p>（3）  集群中各机器共享，配置一致</p>
<p>如：机器列表信息、运行时开关配置、数据库配置信息等基于 Zookeeper 的实现方式</p>
<p>∙ 数据存储：将数据（配置信息）存储到 Zookeeper 上的一个数据节点</p>
<p>∙ 数据获取：应用在启动初始化节点从 Zookeeper 数据节点读取数据，并在该节点上注册一个数据变更 Watcher</p>
<p>∙ 数据变更：当变更数据时，更新 Zookeeper 对应节点数据，Zookeeper会将数据变更通知发到各客户端，客户端接到通知后重新读取变更后的数据即可。</p>
<p>负载均衡</p>
<p>zk 的命名服务命名服务是指通过指定的名字来获取资源或者服务的地址，利用 zk 创建一个全局的路径，这个路径就可以作为一个名字，指向集群中的集群，提供的服务的地址，或者一个远程的对象等等。</p>
<p>分布式通知和协调</p>
<p>对于系统调度来说：操作人员发送通知实际是通过控制台改变某个节点的状态，然后 zk 将这些变化发送给注册了这个节点的 watcher 的所有客户端。</p>
<p>对于执行情况汇报：每个工作进程都在某个目录下创建一个临时节点。并携带工作的进度数据，这样汇总的进程可以监控目录子节点的变化获得工作进度的实时的全局情况。</p>
<p>zk 的命名服务（文件系统）命名服务是指通过指定的名字来获取资源或者服务的地址，利用 zk 创建一个全局的路径，即是唯一的路径，这个路径就可以作为一个名字，指向集群中的集群，提供的服务的地址，或者一个远程的对象等等。</p>
<p>zk 的配置管理（文件系统、通知机制）程序分布式的部署在不同的机器上，将程序的配置信息放在 zk 的 znode 下，当有配置发生改变时，也就是 znode 发生变化时，可以通过改变 zk 中某个目录节点的内容，利用 watcher 通知给各个客户端，从而更改配置。</p>
<p>Zookeeper 集群管理（文件系统、通知机制）</p>
<p>所谓集群管理无在乎两点：是否有机器退出和加入、选举 master。</p>
<p>对于第一点，所有机器约定在父目录下创建临时目录节点，然后监听父目录节点的子节点变化消息。一旦有机器挂掉，该机器与 zookeeper 的连接断开，其所创建的临时目录节点被删除，所有其他机器都收到通知：某个兄弟目录被删除，于是，所有人都知道：它上船了。</p>
<p>新机器加入也是类似，所有机器收到通知：新兄弟目录加入，highcount 又有</p>
<p>了，对于第二点，我们稍微改变一下，所有机器创建临时顺序编号目录节点，每次选取编号最小的机器作为 master 就好。</p>
<p>Zookeeper 分布式锁（文件系统、通知机制）</p>
<p>有了 zookeeper 的一致性文件系统，锁的问题变得容易。锁服务可以分为两类，一个是保持独占，另一个是控制时序。</p>
<p>对于第一类，我们将 zookeeper 上的一个 znode 看作是一把锁，通过 createznode的方式来实现。所有客户端都去创建 &#x2F;distribute_lock 节点，最终成功创建的那个客户端也即拥有了这把锁。用完删除掉自己创建的 distribute_lock 节点就释放出锁。</p>
<p>对于第二类， &#x2F;distribute_lock 已经预先存在，所有客户端在它下面创建临时顺</p>
<p>序编号目录节点，和选 master 一样，编号最小的获得锁，用完删除，依次方便。</p>
<p>Zookeeper 队列管理（文件系统、通知机制）两种类型的队列：</p>
<p>（1）  同步队列，当一个队列的成员都聚齐时，这个队列才可用，否则一直等待所有成员到达。</p>
<p>（2）  队列按照 FIFO 方式进行入队和出队操作。</p>
<p>第一类，在约定目录下创建临时目录节点，监听节点数目是否是我们要求的数目。</p>
<p>第二类，和分布式锁服务中的控制时序场景基本原理一致，入列有编号，出列按编号。在特定的目录下创建 PERSISTENT_SEQUENTIAL 节点，创建成功时 Watcher 通知等待的队列，队列删除序列号最小的节点用以消费。此场景下</p>
<p>Zookeeper 的 znode 用于消息存储，znode 存储的数据就是消息队列中的消息内容，SEQUENTIAL 序列号就是消息的编号，按序取出即可。由于创建的节点是持久化的，所以不必担心队列消息的丢失问题。</p>
<h1 id="29-Zookeeper-都有哪些功能？"><a href="#29-Zookeeper-都有哪些功能？" class="headerlink" title="29. Zookeeper 都有哪些功能？"></a>29. Zookeeper 都有哪些功能？</h1><ol>
<li><p>集群管理：监控节点存活状态、运行请求等；</p>
</li>
<li><p>主节点选举：主节点挂掉了之后可以从备用的节点开始新一轮选主，主节点选举说的就是这个选举的过程，使用 Zookeeper 可以协助完成这个过程；</p>
</li>
<li><p>分布式锁：Zookeeper 提供两种锁：独占锁、共享锁。独占锁即一次只能有一个线程使用资源，共享锁是读锁共享，读写互斥，即可以有多线</p>
</li>
</ol>
<p>线程同时读同一个资源，如果要使用写锁也只能有一个线程使用。</p>
<p>Zookeeper 可以对分布式锁进行控制。</p>
<ol start="4">
<li>命名服务：在分布式系统中，通过使用命名服务，客户端应用能够根据指定名字来获取资源或服务的地址，提供者等信息。</li>
</ol>
<h1 id="30-说一下-Zookeeper-的通知机制？"><a href="#30-说一下-Zookeeper-的通知机制？" class="headerlink" title="30. 说一下 Zookeeper 的通知机制？"></a>30. 说一下 Zookeeper 的通知机制？</h1><p>client 端会对某个 znode 建立一个 watcher 事件，当该 znode 发生变化时，这些 client 会收到 zk 的通知，然后 client 可以根据 znode 变化来做出业务上的改变等。</p>
<h1 id="31-Zookeeper-和-Dubbo-的关系？"><a href="#31-Zookeeper-和-Dubbo-的关系？" class="headerlink" title="31. Zookeeper 和 Dubbo 的关系？"></a>31. Zookeeper 和 Dubbo 的关系？</h1><p>Zookeeper的作用：</p>
<p>zookeeper用来注册服务和进行负载均衡，哪一个服务由哪一个机器来提供必需让调用者知道，简单来说就是ip地址和服务名称的对应关系。当然也可以通过硬编码的方式把这种对应关系在调用方业务代码中实现，但是如果提供服务的机器</p>
<p>挂掉调用者无法知晓，如果不更改代码会继续请求挂掉的机器提供服务。</p>
<p>zookeeper通过心跳机制可以检测挂掉的机器并将挂掉机器的ip和服务对应关系从列表中删除。至于支持高并发，简单来说就是横向扩展，在不更改代码的情况通过添加机器来提高运算能力。通过添加新的机器向zookeeper注册服务，服务的提供者多了能服务的客户就多了。</p>
<p>dubbo：</p>
<p>是管理中间层的工具，在业务层到数据仓库间有非常多服务的接入和服务提供者需要调度，dubbo提供一个框架解决这个问题。</p>
<p>注意这里的dubbo只是一个框架，至于你架子上放什么是完全取决于你的，就像一个汽车骨架，你需要配你的轮子引擎。这个框架中要完成调度必须要有一个分布式的注册中心，储存所有服务的元数据，你可以用zk，也可以用别的，只是大家都用zk。</p>
<p>zookeeper和dubbo的关系：</p>
<p>Dubbo 的将注册中心进行抽象，它可以外接不同的存储媒介给注册中心提供服务，有 ZooKeeper，Memcached，Redis 等。</p>
<p>引入了 ZooKeeper 作为存储媒介，也就把 ZooKeeper 的特性引进来。首先是负载均衡，单注册中心的承载能力是有限的，在流量达到一定程度的时 候就需要分流，负载均衡就是为了分流而存在的，一个 ZooKeeper 群配合相应的 </p>
<p>Web 应用就可以很容易达到负载均衡；资源同步，单单有负载均衡还不 够，节点之间的数据和资源需要同步，ZooKeeper 集群就天然具备有这样的功能；命名服务，将树状结构用于维护全局的服务地址列表，服务提供者在启动 的时</p>
<p>候，向 ZooKeeper 上的指定节点 &#x2F;dubbo&#x2F;${serviceName}&#x2F;providers 目录下写入自己的 URL 地址，这个操作就完成了服务的发布。 其他特性还有 Mast 选举，分布式锁等。</p>
<p><img src="/13-ZooKeeper%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%882020%E6%9C%80%E6%96%B0%E7%89%88%EF%BC%89-%E9%87%8D%E7%82%B9.assets/ZooKeeper.jpg" alt="ZooKeeper"></p>

      
    </div>

    
    
    

       
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/10/12/12-Redis%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%882020%E6%9C%80%E6%96%B0%E7%89%88%EF%BC%89-%E9%87%8D%E7%82%B9/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="善善332">
      <meta itemprop="description" content="运气和努力一样重要">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="和善寺">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/10/12/12-Redis%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%882020%E6%9C%80%E6%96%B0%E7%89%88%EF%BC%89-%E9%87%8D%E7%82%B9/" class="post-title-link" itemprop="url">未命名</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-10-12 15:01:16" itemprop="dateCreated datePublished" datetime="2022-10-12T15:01:16+08:00">2022-10-12</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-03-03 13:51:30" itemprop="dateModified" datetime="2021-03-03T13:51:30+08:00">2021-03-03</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><h2 id="什么是Redis"><a href="#什么是Redis" class="headerlink" title="什么是Redis"></a>什么是Redis</h2><p>Redis(Remote Dictionary Server) 是一个使用 C 语言编写的，开源的（BSD许 可）高性能非关系型（NoSQL）的键值对数据库。 </p>
<p>Redis 可以存储键和五种不同类型的值之间的映射。键的类型只能为字符串，值 支持五种数据类型：字符串、列表、集合、散列表、有序集合。 </p>
<p>与传统数据库不同的是 Redis 的数据是存在内存中的，所以读写速度非常快， 因此 redis 被广泛应用于缓存方向，每秒可以处理超过 10万次读写操作，是已<br>知性能快的Key-Value DB。</p>
<p>另外，Redis 也经常用来做分布式锁。除此之 外，Redis 支持事务 、持久化、LUA脚本、LRU驱动事件、多种集群方案。 </p>
<h2 id="Redis有哪些优缺点"><a href="#Redis有哪些优缺点" class="headerlink" title="Redis有哪些优缺点"></a>Redis有哪些优缺点</h2><p>**优点 **</p>
<ul>
<li>读写性能优异， Redis能读的速度是110000次&#x2F;s，写的速度是81000次&#x2F;s。 </li>
<li>支持数据持久化，支持AOF和RDB两种持久化方式。 </li>
<li>支持事务，Redis的所有操作都是原子性的，同时Redis还支持对几个操作合并 后的原子性执行。 </li>
<li>数据结构丰富，除了支持string类型的value外还支持hash、set、zset、list等 数据结构。 </li>
<li>支持主从复制，主机会自动将数据同步到从机，可以进行读写分离。</li>
</ul>
<p>**缺点 **</p>
<ul>
<li>数据库容量受到物理内存的限制，不能用作海量数据的高性能读写，因此Redis 适合的场景主要局限在较小数据量的高性能操作和运算上。 </li>
<li>Redis 不具备自动容错和恢复功能，主机从机的宕机都会导致前端部分读写请求 失败，需要等待机器重启或者手动切换前端的IP才能恢复。 </li>
<li>主机宕机，宕机前有部分数据未能及时同步到从机，切换IP后还会引入数据不一 致的问题，降低了系统的可用性。 </li>
<li>Redis 较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂。为避 免这一问题，运维人员在系统上线时必须确保有足够的空间，这对资源造成了很大的 浪费。</li>
</ul>
<h2 id="为什么要用-Redis-x2F-为什么要用缓存"><a href="#为什么要用-Redis-x2F-为什么要用缓存" class="headerlink" title="为什么要用 Redis &#x2F;为什么要用缓存"></a>为什么要用 Redis &#x2F;为什么要用缓存</h2><p>主要从“高性能”和“高并发”这两点来看待这个问题。 </p>
<p>高性能： </p>
<p>假如用户第一次访问数据库中的某些数据。这个过程会比较慢，因为是从硬盘上 读取的。将该用户访问的数据存在数缓存中，这样下一次再访问这些数据的时候 就可以直接从缓存中获取了。操作缓存就是直接操作内存，所以速度相当快。如 果数据库中的对应数据改变的之后，同步改变缓存中相应的数据即可！</p>
<p><img src="/12-Redis%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%882020%E6%9C%80%E6%96%B0%E7%89%88%EF%BC%89-%E9%87%8D%E7%82%B9.assets/%E9%AB%98%E6%80%A7%E8%83%BD.png" alt="高性能"></p>
<p>高并发： </p>
<p>直接操作缓存能够承受的请求是远远大于直接访问数据库的，所以我们可以考虑 把数据库中的部分数据转移到缓存中去，这样用户的一部分请求会直接到缓存这 里而不用经过数据库。</p>
<p><img src="/12-Redis%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%882020%E6%9C%80%E6%96%B0%E7%89%88%EF%BC%89-%E9%87%8D%E7%82%B9.assets/%E9%AB%98%E5%B9%B6%E5%8F%91.png" alt="高并发"></p>
<h2 id="为什么要用-Redis-而不用-map-x2F-guava-做缓存"><a href="#为什么要用-Redis-而不用-map-x2F-guava-做缓存" class="headerlink" title="为什么要用 Redis 而不用 map&#x2F;guava 做缓存?"></a>为什么要用 Redis 而不用 map&#x2F;guava 做缓存?</h2><p>缓存分为本地缓存和分布式缓存。以 Java 为例，使用自带的 map 或者 guava  实现的是本地缓存，主要的特点是轻量以及快速，生命周期随着 jvm 的销毁 而结束，并且在多实例的情况下，每个实例都需要各自保存一份缓存，缓存不具 有一致性。 </p>
<p>使用 redis 或 memcached 之类的称为分布式缓存，在多实例的情况下，各实 例共用一份缓存数据，缓存具有一致性。缺点是需要保持 redis 或 memcached 服务的高可用，整个程序架构上较为复杂。 </p>
<h2 id="Redis为什么这么快"><a href="#Redis为什么这么快" class="headerlink" title="Redis为什么这么快"></a>Redis为什么这么快</h2><ol>
<li>完全基于内存，绝大部分请求是纯粹的内存操作，非常快速。数据存在内存 中，类似于 HashMap，HashMap 的优势就是查找和操作的时间复杂度都是 O(1)； </li>
<li>数据结构简单，对数据操作也简单，Redis 中的数据结构是专门进行设计 的；</li>
<li>采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者 多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁 操作，没有因为可能出现死锁而导致的性能消耗； </li>
<li>使用多路 I&#x2F;O 复用模型，非阻塞 IO； </li>
<li>使用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协 议不一样，Redis 直接自己构建了 VM 机制 ，因为一般的系统调用系统函数的 话，会浪费一定的时间去移动和请求；</li>
</ol>
<h1 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h1><h2 id="Redis有哪些数据类型"><a href="#Redis有哪些数据类型" class="headerlink" title="Redis有哪些数据类型"></a>Redis有哪些数据类型</h2><p>Redis主要有5种数据类型，包括String，List，Set，Zset，Hash，满足大部分 的使用要求 数据类型 可以存储 的值 操作 应用场景</p>
<table>
<thead>
<tr>
<th align="center">数据类型</th>
<th align="left">可以存储 的值</th>
<th align="left">操作</th>
<th align="left">应用场景</th>
</tr>
</thead>
<tbody><tr>
<td align="center">STRING</td>
<td align="left">字符串、 整数或者 浮点数</td>
<td align="left">对整个字 符串或者 字符串的 其中一部 分执行操 作 对整数和 浮点数执 行自增或 者自减操 作</td>
<td align="left">做简单的 键值对缓 存</td>
</tr>
<tr>
<td align="center">LIST</td>
<td align="left">列表</td>
<td align="left">从两端压 入或者弹 出元素 对单个或 者多个元 素进行修 剪， 只保留一 个范围内 的元素</td>
<td align="left">存储一些 列表型的 数据结 构，类似 粉丝列 表、文章 的评论列 表之类的 数据</td>
</tr>
<tr>
<td align="center">SET</td>
<td align="left">无序集合</td>
<td align="left">添加、获 取、移除 单个元素 检查一个 元素是否 存在于集 合中</td>
<td align="left">交集、并 集、差集 的操作， 比如交 集，可以 把两个人 的粉丝列</td>
</tr>
<tr>
<td align="center">HASH</td>
<td align="left">包含键值 对的无序 散列表</td>
<td align="left">添加、获 取、移除 单个键值 对 获取所有 键值对  检查某个 键是否存 在</td>
<td align="left">结构化的 数据，比 如一个对 象</td>
</tr>
<tr>
<td align="center">ZSET</td>
<td align="left">有序集合</td>
<td align="left">添加、获 取、删除 元素 根据分值 范围或者 成员来获 取元素  计算一个 键的排名</td>
<td align="left">去重但可 以排序， 如获取排 名前几名 的用户</td>
</tr>
</tbody></table>
<h2 id="7Redis的应用场景"><a href="#7Redis的应用场景" class="headerlink" title="7Redis的应用场景"></a>7Redis的应用场景</h2><h3 id="总结一"><a href="#总结一" class="headerlink" title="总结一"></a>总结一</h3><p>计数器 </p>
<p>可以对 String 进行自增自减运算，从而实现计数器功能。Redis 这种内存型数 据库的读写性能非常高，很适合存储频繁读写的计数量。 </p>
<p>缓存 </p>
<p>将热点数据放到内存中，设置内存的大使用量以及淘汰策略来保证缓存的命中率。 </p>
<p>会话缓存 </p>
<p>可以使用 Redis 来统一存储多台应用服务器的会话信息。当应用服务器不再存 储用户的会话信息，也就不再具有状态，一个用户可以请求任意一个应用服务 器，从而更容易实现高可用性以及可伸缩性。 </p>
<p>全页缓存（FPC） </p>
<p>除基本的会话token之外，Redis还提供很简便的FPC平台。以Magento为例， Magento提供一个插件来使用Redis作为全页缓存后端。此外，对WordPress的用户来说，Pantheon有一个非常好的插件 wp-redis，这个插件能帮助你以 快速度加载你曾浏览过的页面。 </p>
<p>查找表 </p>
<p>例如 DNS 记录就很适合使用 Redis 进行存储。查找表和缓存类似，也是利用了  Redis 快速的查找特性。但是查找表的内容不能失效，而缓存的内容可以失效， 因为缓存不作为可靠的数据来源。 </p>
<p>消息队列(发布&#x2F;订阅功能) </p>
<p>List 是一个双向链表，可以通过 lpush 和 rpop 写入和读取消息。不过好使用  Kafka、RabbitMQ 等消息中间件。 </p>
<p>分布式锁实现 在分布式场景下，无法使用单机环境下的锁来对多个节点上的进程进行同步。可 以使用 Redis 自带的 SETNX 命令实现分布式锁，除此之外，还可以使用官方提 供的 RedLock 分布式锁实现。 </p>
<p>其它 </p>
<p>Set 可以实现交集、并集等操作，从而实现共同好友等功能。ZSet 可以实现有 序性操作，从而实现排行榜等功能。 </p>
<h3 id="总结二"><a href="#总结二" class="headerlink" title="总结二"></a>总结二</h3><p>Redis相比其他缓存，有一个非常大的优势，就是支持多种数据类型。 </p>
<p>数据类型说明string字符串，简单的k-v存储hashhash格式，value为field和 value，适合ID-Detail这样的场景。list简单的list，顺序列表，支持首位或者末 尾插入数据set无序list，查找速度快，适合交集、并集、差集处理sorted set有 序的set </p>
<p>其实，通过上面的数据类型的特性，基本就能想到合适的应用场景了。 </p>
<p>string——适合简单的k-v存储，类似于memcached的存储结构，短信验证 码，配置信息等，就用这种类型来存储。 </p>
<p>hash——一般key为ID或者唯一标示，value对应的就是详情了。如商品详情， 个人信息详情，新闻详情等。</p>
<p>list——因为list是有序的，比较适合存储一些有序且数据相对固定的数据。如省 市区表、字典表等。因为list是有序的，适合根据写入的时间来排序，如：新 的***，消息队列等。</p>
<p>set——可以简单的理解为ID-List的模式，如微博中一个人有哪些好友，set 牛的地方在于，可以对两个set提供交集、并集、差集操作。例如：查找两个人 共同的好友等。 </p>
<p>Sorted Set——是set的增强版本，增加了一个score参数，自动会根据score的 值进行排序。比较适合类似于top 10等不根据插入的时间来排序的数据。 如上所述，虽然Redis不像关系数据库那么复杂的数据结构，但是，也能适合很 多场景，比一般的缓存数据结构要多。了解每种数据结构适合的业务场景，不仅 有利于提升开发效率，也能有效利用Redis的性能。</p>
<h1 id="持久化"><a href="#持久化" class="headerlink" title="持久化"></a>持久化</h1><h2 id="什么是Redis持久化？"><a href="#什么是Redis持久化？" class="headerlink" title="什么是Redis持久化？"></a>什么是Redis持久化？</h2><p>持久化就是把内存的数据写到磁盘中去，防止服务宕机了内存数据丢失。 </p>
<h2 id="9Redis-的持久化机制是什么？各自的优缺点？"><a href="#9Redis-的持久化机制是什么？各自的优缺点？" class="headerlink" title="9Redis 的持久化机制是什么？各自的优缺点？"></a>9Redis 的持久化机制是什么？各自的优缺点？</h2><p>Redis 提供两种持久化机制 RDB（默认） 和 AOF 机制: </p>
<h3 id="RDB：是Redis-DataBase缩写快照"><a href="#RDB：是Redis-DataBase缩写快照" class="headerlink" title="RDB：是Redis DataBase缩写快照"></a>RDB：是Redis DataBase缩写快照</h3><p>RDB是Redis默认的持久化方式。按照一定的时间将内存的数据以快照的形式保 存到硬盘中，对应产生的数据文件为dump.rdb。通过配置文件中的save参数来 定义快照的周期。</p>
<p><img src="/12-Redis%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%882020%E6%9C%80%E6%96%B0%E7%89%88%EF%BC%89-%E9%87%8D%E7%82%B9.assets/RDB.png" alt="RDB"></p>
<h4 id="优点："><a href="#优点：" class="headerlink" title="优点："></a>优点：</h4><ol>
<li>只有一个文件 dump.rdb，方便持久化。 </li>
<li>容灾性好，一个文件可以保存到安全的磁盘。 </li>
<li>性能大化，fork 子进程来完成写操作，让主进程继续处理命令，所以是  IO 大化。使用单独子进程来进行持久化，主进程不会进行任何 IO 操作，保证了  redis 的高性能 </li>
<li>相对于数据集大时，比 AOF 的启动效率更高。</li>
</ol>
<h4 id="缺点："><a href="#缺点：" class="headerlink" title="缺点："></a>缺点：</h4><ol>
<li>数据安全性低。RDB 是间隔一段时间进行持久化，如果持久化之间 redis 发 生故障，会发生数据丢失。所以这种方式更适合数据要求不严谨的时候) </li>
<li>AOF（Append-only file)持久化方式： 是指所有的命令行记录以 redis 命 令请 求协议的格式完全持久化存储)保存为 aof 文件。</li>
</ol>
<h3 id="AOF：持久化"><a href="#AOF：持久化" class="headerlink" title="AOF：持久化"></a>AOF：持久化</h3><p>AOF持久化(即Append Only File持久化)，则是将Redis执行的每次写命令记录 到单独的日志文件中，当重启Redis会重新将持久化的日志中文件恢复数据。 当两种方式同时开启时，数据恢复Redis会优先选择AOF恢复。</p>
<p><img src="/12-Redis%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%882020%E6%9C%80%E6%96%B0%E7%89%88%EF%BC%89-%E9%87%8D%E7%82%B9.assets/AOF.png" alt="AOF"></p>
<h4 id="优点：-1"><a href="#优点：-1" class="headerlink" title="优点："></a>优点：</h4><ol>
<li>数据安全，aof 持久化可以配置 appendfsync 属性，有 always，每进行一 次 命令操作就记录到 aof 文件中一次。 </li>
<li>通过 append 模式写文件，即使中途服务器宕机，可以通过 redis-checkaof 工具解决数据一致性问题。 </li>
<li>AOF 机制的 rewrite 模式。AOF 文件没被 rewrite 之前（文件过大时会对命 令 进行合并重写），可以删除其中的某些命令（比如误操作的 flushall）)</li>
</ol>
<h4 id="缺点：-1"><a href="#缺点：-1" class="headerlink" title="缺点："></a>缺点：</h4><ol>
<li>AOF 文件比 RDB 文件大，且恢复速度慢。 </li>
<li>数据集大的时候，比 rdb 启动效率低。</li>
</ol>
<h3 id="优缺点是什么？"><a href="#优缺点是什么？" class="headerlink" title="优缺点是什么？"></a>优缺点是什么？</h3><ul>
<li>AOF文件比RDB更新频率高，优先使用AOF还原数据。 </li>
<li>AOF比RDB更安全也更大 </li>
<li>RDB性能比AOF好 </li>
<li>如果两个都配了优先加载AOF</li>
</ul>
<h2 id="如何选择合适的持久化方式"><a href="#如何选择合适的持久化方式" class="headerlink" title="如何选择合适的持久化方式"></a>如何选择合适的持久化方式</h2><ul>
<li>一般来说， 如果想达到足以媲美PostgreSQL的数据安全性，你应该 同时使用两种持久化功能。在这种情况下，当 Redis 重启的时候会优先载 入AOF文件来恢复原始的数据，因为在通常情况下AOF文件保存的数据集 要比RDB文件保存的数据集要完整。 </li>
<li>如果你非常关心你的数据， 但仍然可以承受数分钟以内的数据丢失， 那么你可以只使用RDB持久化。 </li>
<li>有很多用户都只使用AOF持久化，但并不推荐这种方式，因为定时生 成RDB快照（snapshot）非常便于进行数据库备份， 并且 RDB 恢复数据 集的速度也要比AOF恢复的速度要快，除此之外，使用RDB还可以避免 AOF程序的bug。 </li>
<li>如果你只希望你的数据在服务器运行的时候存在，你也可以不使用任 何持久化方式。</li>
</ul>
<h2 id="Redis持久化数据和缓存怎么做扩容？"><a href="#Redis持久化数据和缓存怎么做扩容？" class="headerlink" title="Redis持久化数据和缓存怎么做扩容？"></a>Redis持久化数据和缓存怎么做扩容？</h2><p>如果Redis被当做缓存使用，使用一致性哈希实现动态扩容缩容。</p>
<p>如果Redis被当做一个持久化存储使用，必须使用固定的keys-tonodes映射关系，节点的数量一旦确定不能变化。否则的话(即Redis节点需要动态变化的情况），必须使用可以在运行时进行数据再平衡的一套系统，而当前只有Redis集群可以做到这样。</p>
<h1 id="过期键的删除策略"><a href="#过期键的删除策略" class="headerlink" title="过期键的删除策略"></a>过期键的删除策略</h1><h2 id="Redis的过期键的删除策略"><a href="#Redis的过期键的删除策略" class="headerlink" title="Redis的过期键的删除策略"></a>Redis的过期键的删除策略</h2><p>我们都知道，Redis是key-value数据库，我们可以设置Redis中缓存的key的过</p>
<p>期时间。Redis的过期策略就是指当Redis中缓存的key过期了，Redis如何处理。</p>
<p>过期策略通常有以下三种：</p>
<p> 定时过期：每个设置过期时间的key都需要创建一个定时器，到过期时间就会立即清除。该策略可以立即清除过期的数据，对内存很友好；但是会占用大量的CPU资源去处理过期的数据，从而影响缓存的响应时间和吞吐量。</p>
<p>​          惰性过期：只有当访问一个key时，才会判断该key是否已过期，过期则清除。</p>
<p>该策略可以  大化地节省CPU资源，却对内存非常不友好。极端情况可能出现大量的过期key没有再次被访问，从而不会被清除，占用大量内存。定期过期：每隔一定的时间，会扫描一定数量的数据库的expires字典中一定数量的key，并清除其中已过期的key。该策略是前两者的一个折中方案。通过调整定</p>
<p>时扫描的时间间隔和每次扫描的限定耗时，可以在不同情况下使得CPU和内存资源达到 优的平衡效果。</p>
<p>(expires字典会保存所有设置了过期时间的key的过期时间数据，其中，key是指向键空间中的某个键的指针，value是该键的毫秒精度的UNIX时间戳表示的过期时间。键空间是指该</p>
<p>Redis集群中保存的所有键。)</p>
<p>Redis中同时使用了惰性过期和定期过期两种过期策略。</p>
<h2 id="Redis-key的过期时间和永久有效分别怎么设置？"><a href="#Redis-key的过期时间和永久有效分别怎么设置？" class="headerlink" title="Redis key的过期时间和永久有效分别怎么设置？"></a>Redis key的过期时间和永久有效分别怎么设置？</h2><p>EXPIRE和PERSIST命令。</p>
<h3 id="我们知道通过expire来设置key-的过期时间，那么对过期的数据怎么处理呢"><a href="#我们知道通过expire来设置key-的过期时间，那么对过期的数据怎么处理呢" class="headerlink" title="我们知道通过expire来设置key 的过期时间，那么对过期的数据怎么处理呢?"></a>我们知道通过expire来设置key 的过期时间，那么对过期的数据怎么处理呢?</h3><p>除了缓存服务器自带的缓存失效策略之外（Redis默认的有6中策略可供选择），我们还可以根据具体的业务需求进行自定义的缓存淘汰，常见的策略有两种：</p>
<ol>
<li><p>定时去清理过期的缓存；</p>
</li>
<li><p>当有用户请求过来时，再判断这个请求所用到的缓存是否过期，过期的话就去底层系统得到新数据并更新缓存。</p>
</li>
</ol>
<p>两者各有优劣，第一种的缺点是维护大量缓存的key是比较麻烦的，第二种的缺点就是每次用户请求过来都要判断缓存失效，逻辑相对比较复杂！具体用哪种方案，大家可以根据自己的应用场景来权衡。</p>
<h1 id="内存相关"><a href="#内存相关" class="headerlink" title="内存相关"></a>内存相关</h1><p>MySQL里有2000w数据，redis中只存20w的数据，如何保证redis中的数据都是热点数据</p>
<p>redis内存数据集大小上升到一定大小的时候，就会施行数据淘汰策略。</p>
<h2 id="Redis的内存淘汰策略有哪些"><a href="#Redis的内存淘汰策略有哪些" class="headerlink" title="Redis的内存淘汰策略有哪些"></a>Redis的内存淘汰策略有哪些</h2><p>Redis的内存淘汰策略是指在Redis的用于缓存的内存不足时，怎么处理需要新写入且需要申请额外空间的数据。</p>
<p>全局的键空间选择性移除</p>
<p>noeviction：当内存不足以容纳新写入数据时，新写入操作会报错。</p>
<p> allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除  近 少使用的key。（这个是最常用的）</p>
<p> allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个key。</p>
<p>设置过期时间的键空间选择性移除</p>
<p> volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除   近  少使用的key。</p>
<p> volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个key。</p>
<p> volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的key优先移除。</p>
<p>总结</p>
<p>Redis的内存淘汰策略的选取并不会影响过期的key的处理。内存淘汰策略用于处理内存不足时的需要申请额外空间的数据；过期策略用于处理过期的缓存数据。</p>
<h3 id="Redis主要消耗什么物理资源？"><a href="#Redis主要消耗什么物理资源？" class="headerlink" title="Redis主要消耗什么物理资源？"></a>Redis主要消耗什么物理资源？</h3><p>内存。</p>
<h2 id="Redis的内存用完了会发生什么？"><a href="#Redis的内存用完了会发生什么？" class="headerlink" title="Redis的内存用完了会发生什么？"></a>Redis的内存用完了会发生什么？</h2><p>如果达到设置的上限，Redis的写命令会返回错误信息（但是读命令还可以正常返回。）或者你可以配置内存淘汰机制，当Redis达到内存上限时会冲刷掉旧的内容。</p>
<h2 id="Redis如何做内存优化？"><a href="#Redis如何做内存优化？" class="headerlink" title="Redis如何做内存优化？"></a>Redis如何做内存优化？</h2><p>可以好好利用Hash,list,sorted set,set等集合类型数据，因为通常情况下很多小的Key-Value可以用更紧凑的方式存放到一起。尽可能使用散列表</p>
<p>（hashes），散列表（是说散列表里面存储的数少）使用的内存非常小，所以你应该尽可能的将你的数据模型抽象到一个散列表里面。比如你的web系统中有一个用户对象，不要为这个用户的名称，姓氏，邮箱，密码设置单独的key，而是应该把这个用户的所有信息存储到一张散列表里面线程模型</p>
<h2 id="Redis线程模型"><a href="#Redis线程模型" class="headerlink" title="Redis线程模型"></a>Redis线程模型</h2><p>Redis基于Reactor模式开发了网络事件处理器，这个处理器被称为文件事件处</p>
<p>理器（file event handler）。它的组成结构为4部分：多个套接字、IO多路复用程序、文件事件分派器、事件处理器。因为文件事件分派器队列的消费是单线程的，所以Redis才叫单线程模型。</p>
<p>文件事件处理器使用 I&#x2F;O 多路复用（multiplexing）程序来同时监听多个套接字， 并根据套接字目前执行的任务来为套接字关联不同的事件处理器。</p>
<p>​         当被监听的套接字准备好执行连接应答（accept）、读取（read）、写入</p>
<p>（write）、关闭（close）等操作时， 与操作相对应的文件事件就会产生， 这时文件事件处理器就会调用套接字之前关联好的事件处理器来处理这些事件。</p>
<p>虽然文件事件处理器以单线程方式运行， 但通过使用 I&#x2F;O 多路复用程序来监听多个套接字， 文件事件处理器既实现了高性能的网络通信模型， 又可以很好地与 redis 服务器中其他同样以单线程方式运行的模块进行对接， 这保持了 </p>
<p>Redis 内部单线程设计的简单性。</p>
<h2 id="什么是事务？"><a href="#什么是事务？" class="headerlink" title="什么是事务？"></a>什么是事务？</h2><p>事务是一个单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。</p>
<p>事务是一个原子操作：事务中的命令要么全部被执行，要么全部都不执行。</p>
<h2 id="Redis事务的概念"><a href="#Redis事务的概念" class="headerlink" title="Redis事务的概念"></a>Redis事务的概念</h2><p>Redis 事务的本质是通过MULTI、EXEC、WATCH等一组命令的集合。事务支</p>
<p>持一次执行多个命令，一个事务中所有命令都会被序列化。在事务执行过程，会按照顺序串行化执行队列中的命令，其他客户端提交的命令请求不会插入到事务执行命令序列中。</p>
<p>总结说：redis事务就是一次性、顺序性、排他性的执行一个队列中的一系列命令。</p>
<h2 id="Redis事务的三个阶段"><a href="#Redis事务的三个阶段" class="headerlink" title="Redis事务的三个阶段"></a>Redis事务的三个阶段</h2><p>\1. 事务开始 MULTI</p>
<p>\2. 命令入队</p>
<p>\3. 事务执行 EXEC</p>
<p>事务执行过程中，如果服务端收到有EXEC、DISCARD、WATCH、MULTI之外的请求，将会把请求放入队列中排队</p>
<h2 id="Redis事务相关命令"><a href="#Redis事务相关命令" class="headerlink" title="Redis事务相关命令"></a>Redis事务相关命令</h2><p>Redis事务功能是通过MULTI、EXEC、DISCARD和WATCH 四个原语实现的</p>
<p>Redis会将一个事务中的所有命令序列化，然后按顺序执行。</p>
<p>\1.  redis 不支持回滚，“Redis 在事务失败时不进行回滚，而是继续执行余下的命令”， 所以 Redis 的内部可以保持简单且快速。</p>
<p>\2.  如果在一个事务中的命令出现错误，那么所有的命令都不会执行；</p>
<p>\3.  如果在一个事务中出现运行错误，那么正确的命令会被执行。</p>
<p> WATCH 命令是一个乐观锁，可以为 Redis 事务提供 check-and-set （CAS）行为。 可以监控一个或多个键，一旦其中有一个键被修改（或删除），之后的事务就不会执行，监控一直持续到EXEC命令。</p>
<p> MULTI命令用于开启一个事务，它总是返回OK。 MULTI执行之后，客户端可以继续向服务器发送任意多条命令，这些命令不会立即被执行，而是被放到一个队列中，当EXEC命令被调用时，所有队列中的命令才会被执行。</p>
<p> EXEC：执行所有事务块内的命令。返回事务块内所有命令的返回值，按命令执行的先后顺序排列。 当操作被打断时，返回空值 nil 。</p>
<p> 通过调用DISCARD，客户端可以清空事务队列，并放弃执行事务， 并且客户端会从事务状态中退出。</p>
<p>​          UNWATCH命令可以取消watch对所有key的监控。</p>
<h2 id="事务管理（ACID）概述"><a href="#事务管理（ACID）概述" class="headerlink" title="事务管理（ACID）概述"></a>事务管理（ACID）概述</h2><p>原子性（Atomicity）</p>
<p>原子性是指事务是一个不可分割的工作单位，事务中的操作要么都发生，要么都不发生。</p>
<p>一致性（Consistency）</p>
<p>事务前后数据的完整性必须保持一致。</p>
<p>隔离性（Isolation）</p>
<p>多个事务并发执行时，一个事务的执行不应影响其他事务的执行持久性（Durability）持久性是指一个事务一旦被提交，它对数据库中数据的改变就是永久性的，接下来即使数据库发生故障也不应该对其有任何影响</p>
<p>Redis的事务总是具有ACID中的一致性和隔离性，其他特性是不支持的。当服务器运行在AOF持久化模式下，并且appendfsync选项的值为always时，事务也具有耐久性。</p>
<h2 id="Redis事务支持隔离性吗"><a href="#Redis事务支持隔离性吗" class="headerlink" title="Redis事务支持隔离性吗"></a>Redis事务支持隔离性吗</h2><p>Redis 是单进程程序，并且它保证在执行事务时，不会对事务进行中断，事务可以运行直到执行完所有事务队列中的命令为止。因此，Redis 的事务是总是带有隔离性的。</p>
<h2 id="Redis事务保证原子性吗，支持回滚吗"><a href="#Redis事务保证原子性吗，支持回滚吗" class="headerlink" title="Redis事务保证原子性吗，支持回滚吗"></a>Redis事务保证原子性吗，支持回滚吗</h2><p>Redis中，单条命令是原子性执行的，但事务不保证原子性，且没有回滚。事务中任意命令执行失败，其余的命令仍会被执行。</p>
<h2 id="Redis事务其他实现"><a href="#Redis事务其他实现" class="headerlink" title="Redis事务其他实现"></a>Redis事务其他实现</h2><p> 基于Lua脚本，Redis可以保证脚本内的命令一次性、按顺序地执行，其同时也不提供事务运行错误的回滚，执行过程中如果部分命令运行错误，剩下的命令还是会继续运行完</p>
<p> 基于中间标记变量，通过另外的标记变量来标识事务是否执行完成，读取数据时先读取该标记变量判断是否事务执行完成。但这样会需要额外写代码实现，比较繁琐集群方案哨兵模式</p>
<p><img src="/12-Redis%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%882020%E6%9C%80%E6%96%B0%E7%89%88%EF%BC%89-%E9%87%8D%E7%82%B9.assets/%E9%9B%86%E7%BE%A4%E5%93%A8%E5%85%B5.jpg" alt="集群哨兵"></p>
<p>哨兵的介绍</p>
<p>sentinel，中文名是哨兵。哨兵是 redis 集群机构中非常重要的一个组件，主要有以下功能：</p>
<p>集群监控：负责监控 redis master 和 slave 进程是否正常工作。</p>
<p>消息通知：如果某个 redis 实例有故障，那么哨兵负责发送消息作为报警通知给管理员。</p>
<p>故障转移：如果 master node 挂掉了，会自动转移到 slave node 上。</p>
<p>配置中心：如果故障转移发生了，通知 client 客户端新的 master 地址。</p>
<p>哨兵用于实现 redis 集群的高可用，本身也是分布式的，作为一个哨兵集群去运行，互相协同工作。</p>
<p> 故障转移时，判断一个 master node 是否宕机了，需要大部分的哨兵都同意才行，涉及到了分布式选举的问题。</p>
<p> 即使部分哨兵节点挂掉了，哨兵集群还是能正常工作的，因为如果一个作为高可用机制重要组成部分的故障转移系统本身是单点的，那就很坑爹了。</p>
<p>哨兵的核心知识</p>
<p>  哨兵至少需要 3 个实例，来保证自己的健壮性。</p>
<p> 哨兵 + redis 主从的部署架构，是不保证数据零丢失的，只能保证 redis 集群的高可用性。</p>
<p> 对于哨兵 + redis 主从这种复杂的部署架构，尽量在测试环境和生产环境，都进行充足的测试和演练。</p>
<h3 id="官方Redis-Cluster-方案-服务端路由查询"><a href="#官方Redis-Cluster-方案-服务端路由查询" class="headerlink" title="官方Redis Cluster 方案(服务端路由查询)"></a>官方Redis Cluster 方案(服务端路由查询)</h3><p><img src="/12-Redis%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%882020%E6%9C%80%E6%96%B0%E7%89%88%EF%BC%89-%E9%87%8D%E7%82%B9.assets/Redis_Cluster%E6%96%B9%E6%A1%88.jpg" alt="Redis_Cluster方案"></p>
<p>redis 集群模式的工作原理能说一下么？在集群模式下，redis 的 key 是如何寻址的？分布式寻址都有哪些算法？了解一致性 hash 算法吗？简介</p>
<p>Redis Cluster是一种服务端Sharding技术，3.0版本开始正式提供。Redis </p>
<p>Cluster并没有使用一致性hash，而是采用slot(槽)的概念，一共分成16384个</p>
<p>槽。将请求发送到任意节点，接收到请求的节点会将查询请求发送到正确的节点上执行</p>
<p>方案说明</p>
<ol>
<li><p>通过哈希的方式，将数据分片，每个节点均分存储一定哈希槽(哈希值) 区间的数据，默认分配了16384 个槽位</p>
</li>
<li><p>每份数据分片会存储在多个互为主从的多节点上</p>
</li>
<li><p>数据写入先写主节点，再同步到从节点(支持配置为阻塞同步)</p>
</li>
<li><p>同一分片多个节点间的数据不保持一致性</p>
</li>
<li><p>读取数据时，当客户端操作的key没有分配在该节点上时，redis会返回转向指令，指向正确的节点</p>
</li>
<li><p>扩容时时需要需要把旧节点的数据迁移一部分到新节点</p>
</li>
</ol>
<p>在 redis cluster 架构下，每个 redis 要放开两个端口号，比如一个是 6379，另外一个就是 加1w 的端口号，比如 16379。</p>
<p>16379 端口号是用来进行节点间通信的，也就是 cluster bus 的东西，cluster bus 的通信，用来进行故障检测、配置更新、故障转移授权。cluster bus 用了另外一种二进制的协议，gossip 协议，用于节点间进行高效的数据交换，占用更少的网络带宽和处理时间。</p>
<p>节点间的内部通信机制</p>
<p>基本通信原理</p>
<p>集群元数据的维护有两种方式：集中式、Gossip 协议。redis cluster 节点间采用 gossip 协议进行通信。</p>
<p>分布式寻址算法</p>
<p>hash 算法（大量缓存重建）</p>
<p>一致性 hash 算法（自动缓存迁移）+ 虚拟节点（自动负载均衡） redis cluster 的 hash slot 算法优点</p>
<p>无中心架构，支持动态扩容，对业务透明</p>
<p>具备Sentinel的监控和自动Failover(故障转移)能力</p>
<p>客户端不需要连接集群所有节点，连接集群中任何一个可用节点即可高性能，客户端直连redis运维也很复杂，数据迁移需要人工干预只能使用0号数据库</p>
<p>不支持批量操作(pipeline管道操作) 分布式逻辑和存储模块耦合等基于客户端分配</p>
<p><img src="/12-Redis%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%882020%E6%9C%80%E6%96%B0%E7%89%88%EF%BC%89-%E9%87%8D%E7%82%B9.assets/%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%88%86%E9%85%8D.jpg" alt="客户端分配"></p>
<p>简介</p>
<p>Redis Sharding是Redis Cluster出来之前，业界普遍使用的多Redis实例集群方法。其主要思想是采用哈希算法将Redis数据的key进行散列，通过hash函数，特定的key会映射到特定的Redis节点上。Java redis客户端驱动jedis，支持</p>
<p>Redis Sharding功能，即ShardedJedis以及结合缓存池的ShardedJedisPool 优点</p>
<p>优势在于非常简单，服务端的Redis实例彼此独立，相互无关联，每个Redis实例像单服务器一样运行，非常容易线性扩展，系统的灵活性很强缺点</p>
<p>由于sharding处理放到客户端，规模进一步扩大时给运维带来挑战。</p>
<p>客户端sharding不支持动态增删节点。服务端Redis实例群拓扑结构有变化时，每个客户端都需要更新调整。连接不能共享，当应用规模增大时，资源浪费制约优化基于代理服务器分片</p>
<p><img src="/12-Redis%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%882020%E6%9C%80%E6%96%B0%E7%89%88%EF%BC%89-%E9%87%8D%E7%82%B9.assets/%E4%BB%A3%E9%87%8C%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%88%86%E7%89%87.jpg" alt="代里服务器分片"></p>
<p>简介客户端发送请求到一个代理组件，代理解析客户端的数据，并将请求转发至正确的节点， 后将结果回复给客户端特征</p>
<p>透明接入，业务程序不用关心后端Redis实例，切换成本低</p>
<p>Proxy 的逻辑和存储的逻辑是隔离的代理层多了一次转发，性能有所损耗业界开源方案</p>
<p>Twtter开源的Twemproxy 豌豆荚开源的Codis</p>
<h2 id="Redis-主从架构"><a href="#Redis-主从架构" class="headerlink" title="Redis 主从架构"></a>Redis 主从架构</h2><p>单机的 redis，能够承载的 QPS 大概就在上万到几万不等。对于缓存来说，一般都是用来支撑读高并发的。因此架构做成主从(master-slave)架构，一主多</p>
<p>从，主负责写，并且将数据复制到其它的 slave 节点，从节点负责读。所有的读请求全部走从节点。这样也可以很轻松实现水平扩容，支撑读高</p>
<p><img src="/12-Redis%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%882020%E6%9C%80%E6%96%B0%E7%89%88%EF%BC%89-%E9%87%8D%E7%82%B9.assets/%E4%B8%BB%E4%BB%8E%E6%9E%B6%E6%9E%84.png" alt="主从架构"></p>
<p>redis replication -&gt; 主从架构 -&gt; 读写分离 -(redis­master­slave)&gt; 水平扩容支撑读高并发 redis replication 的核心机制</p>
<p> redis 采用异步方式复制数据到 slave 节点，不过 redis2.8 开始，slave node 会周期性地确认自己每次复制的数据量；</p>
<p>一个 master node 是可以配置多个 slave node 的； slave node 也可以连接其他的 slave node；</p>
<p>slave node 做复制的时候，不会 block master node 的正常工作；</p>
<p>slave node 在做复制的时候，也不会 block 对自己的查询操作，它会用旧的数据集来提供服务；但是复制完成的时候，需要删除旧数据集，加载新数据集，这个时候就会暂停对外服务了；</p>
<p> slave node 主要用来进行横向扩容，做读写分离，扩容的 slave node 可以提高读的吞吐量。</p>
<p>注意，如果采用了主从架构，那么建议必须开启 master node 的持久化，不建议用 slave node 作为 master node 的数据热备，因为那样的话，如果你关掉 master 的持久化，可能在 master 宕机重启的时候数据是空的，然后可能一经过复制， slave node 的数据也丢了。</p>
<p>另外，master 的各种备份方案，也需要做。万一本地的所有文件丢失了，从备份中挑选一份 rdb 去恢复 master，这样才能确保启动的时候，是有数据的，即使采用了后续讲解的高可用机制，slave node 可以自动接管 master node，但也可能 sentinel 还没检测到 master failure，master node 就自动重启了，还是可能导致上面所有的 slave node 数据被清空。</p>
<p>redis 主从复制的核心原理当启动一个 slave node 的时候，它会发送一个 PSYNC 命令给 master node。</p>
<p>如果这是 slave node 初次连接到 master node，那么会触发一次 full </p>
<p>resynchronization 全量复制。此时 master 会启动一个后台线程，开始生成一份 </p>
<p>RDB 快照文件，</p>
<p>同时还会将从客户端 client 新收到的所有写命令缓存在内存中。RDB 文件生成完毕后， master 会将这个 RDB 发送给 slave，slave 会先写入本地磁盘，然后再从本地磁盘加载到内存中，</p>
<p>接着 master 会将内存中缓存的写命令发送到 slave，slave 也会同步这些数据。</p>
<p>slave node 如果跟 master node 有网络故障，断开了连接，会自动重连，连接之后 master node 仅会复制给 slave 部分缺少的数据。</p>
<p><img src="/12-Redis%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%882020%E6%9C%80%E6%96%B0%E7%89%88%EF%BC%89-%E9%87%8D%E7%82%B9.assets/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E5%8E%9F%E7%90%86.png" alt="主从复制原理"></p>
<ol>
<li><p>当从库和主库建立MS关系后，会向主数据库发送SYNC命令</p>
</li>
<li><p>主库接收到SYNC命令后会开始在后台保存快照(RDB持久化过程)，并将期间接收到的写命令存起来</p>
</li>
<li><p>当快照完成后，主Redis会将快照文件和所有缓存的写命令发送给从</p>
</li>
</ol>
<p>Redis</p>
<ol start="4">
<li><p>从Redis接收到后，会载入快照文件并且执行收到的缓存的命令</p>
</li>
<li><p>之后，主Redis每当接收到写命令时就会将命令发送从Redis，从而保证数据的一致</p>
</li>
</ol>
<p>缺点</p>
<p>所有的slave节点数据的复制和同步都由master节点来处理，会照成master节点压力太大，使用主从从结构来解决</p>
<h2 id="Redis集群的主从复制模型是怎样的？"><a href="#Redis集群的主从复制模型是怎样的？" class="headerlink" title="Redis集群的主从复制模型是怎样的？"></a>Redis集群的主从复制模型是怎样的？</h2><p>为了使在部分节点失败或者大部分节点无法通信的情况下集群仍然可用，所以集群使用了主从复制模型，每个节点都会有N-1个复制品生产环境中的 redis 是怎么部署的？</p>
<p>redis cluster，10 台机器，5 台机器部署了 redis 主实例，另外 5 台机器部署</p>
<p>了 redis 的从实例，每个主实例挂了一个从实例，5 个节点对外提供读写服务，每个节点的读写高峰qps可能可以达到每秒 5 万，5 台机器 多是 25 万读写请求&#x2F;s。</p>
<p>机器是什么配置？32G 内存+ 8 核 CPU + 1T 磁盘，但是分配给 redis 进程的</p>
<p>是10g内存，一般线上生产环境，redis 的内存尽量不要超过 10g，超过 10g 可能会有问题。</p>
<p>5 台机器对外提供读写，一共有 50g 内存。</p>
<p>因为每个主实例都挂了一个从实例，所以是高可用的，任何一个主实例宕机，都会自动故障迁移，redis 从实例会自动变成主实例继续提供读写服务。</p>
<p>你往内存里写的是什么数据？每条数据的大小是多少？商品数据，每条数据是 10kb。100 条数据是 1mb，10 万条数据是 1g。常驻内存的是 200 万条商品数据，占用内存是 20g，仅仅不到总内存的 50%。目前高峰期每秒就是 3500 左右的请求量。</p>
<p>其实大型的公司，会有基础架构的 team 负责缓存集群的运维。</p>
<h2 id="说说Redis哈希槽的概念？"><a href="#说说Redis哈希槽的概念？" class="headerlink" title="说说Redis哈希槽的概念？"></a>说说Redis哈希槽的概念？</h2><p>Redis集群没有使用一致性hash,而是引入了哈希槽的概念，Redis集群有16384 个哈希槽，每个key通过CRC16校验后对16384取模来决定放置哪个槽，集群的每个节点负责一部分hash槽。</p>
<h2 id="Redis集群会有写操作丢失吗？为什么？"><a href="#Redis集群会有写操作丢失吗？为什么？" class="headerlink" title="Redis集群会有写操作丢失吗？为什么？"></a>Redis集群会有写操作丢失吗？为什么？</h2><p>Redis并不能保证数据的强一致性，这意味这在实际中集群在特定的条件下可能会丢失写操作。</p>
<p>Redis集群之间是如何复制的？</p>
<p>异步复制</p>
<p>Redis集群最大节点个数是多少？</p>
<p>16384个</p>
<p>Redis集群如何选择数据库？</p>
<p>Redis集群目前无法做数据库选择，默认在0数据库。</p>
<h1 id="分区"><a href="#分区" class="headerlink" title="分区"></a>分区</h1><h2 id="Redis是单线程的，如何提高多核CPU的利用率？"><a href="#Redis是单线程的，如何提高多核CPU的利用率？" class="headerlink" title="Redis是单线程的，如何提高多核CPU的利用率？"></a>Redis是单线程的，如何提高多核CPU的利用率？</h2><p>可以在同一个服务器部署多个Redis的实例，并把他们当作不同的服务器来使用，在某些时候，无论如何一个服务器是不够的， 所以，如果你想使用多个</p>
<p>CPU，你可以考虑一下分片（shard）。</p>
<h2 id="为什么要做Redis分区？"><a href="#为什么要做Redis分区？" class="headerlink" title="为什么要做Redis分区？"></a>为什么要做Redis分区？</h2><p>分区可以让Redis管理更大的内存，Redis将可以使用所有机器的内存。如果没有分区，你  多只能使用一台机器的内存。分区使Redis的计算能力通过简单地增加计算机得到成倍提升，Redis的网络带宽也会随着计算机和网卡的增加而成倍增长。</p>
<h2 id="你知道有哪些Redis分区实现方案？"><a href="#你知道有哪些Redis分区实现方案？" class="headerlink" title="你知道有哪些Redis分区实现方案？"></a>你知道有哪些Redis分区实现方案？</h2><p> 客户端分区就是在客户端就已经决定数据会被存储到哪个redis节点或者从哪个 redis节点读取。大多数客户端已经实现了客户端分区。</p>
<p> 代理分区 意味着客户端将请求发送给代理，然后代理决定去哪个节点写数据或者读数据。代理根据分区规则决定请求哪些Redis实例，然后根据Redis的响应结果返回给客户端。redis和memcached的一种代理实现就是Twemproxy</p>
<p> 查询路由(Query routing) 的意思是客户端随机地请求任意一个redis实例，然后由Redis将请求转发给正确的Redis节点。Redis Cluster实现了一种混合形式的查询路由，但并不是直接将请求从一个redis节点转发到另一个redis节点，而是在客户端的帮助下直接redirected到正确的redis节点。</p>
<h2 id="Redis分区有什么缺点？"><a href="#Redis分区有什么缺点？" class="headerlink" title="Redis分区有什么缺点？"></a>Redis分区有什么缺点？</h2><p> 涉及多个key的操作通常不会被支持。例如你不能对两个集合求交集，因为他们可能被存储到不同的Redis实例（实际上这种情况也有办法，但是不能直接使用交集指令）。</p>
<p>同时操作多个key,则不能使用Redis事务.</p>
<p>分区使用的粒度是key，不能使用一个非常长的排序key存储一个数据集（The </p>
<p>partitioning granularity is the key, so it is not possible to shard a dataset with a single huge key like a very big sorted set）</p>
<p> 当使用分区的时候，数据处理会非常复杂，例如为了备份你必须从不同的Redis 实例和主机同时收集RDB &#x2F; AOF文件。</p>
<p> 分区时动态扩容或缩容可能非常复杂。Redis集群在运行时增加或者删除Redis 节点，能做到  大程度对用户透明地数据再平衡，但其他一些客户端分区或者代理分区方法则不支持这种特性。然而，有一种预分片的技术也可以较好的解决这个问题。</p>
<h1 id="分布式问题"><a href="#分布式问题" class="headerlink" title="分布式问题"></a>分布式问题</h1><h2 id="Redis实现分布式锁"><a href="#Redis实现分布式锁" class="headerlink" title="Redis实现分布式锁"></a>Redis实现分布式锁</h2><p>Redis为单进程单线程模式，采用队列模式将并发访问变成串行访问，且多客户</p>
<p>端对Redis的连接并不存在竞争关系Redis中可以使用SETNX命令实现分布式锁。</p>
<p>当且仅当 key 不存在，将 key 的值设为 value。 若给定的 key 已经存在，则</p>
<p>SETNX 不做任何动作</p>
<p>SETNX 是『SET if Not eXists』(如果不存在，则 SET)的简写。</p>
<p>返回值：设置成功，返回 1 。设置失败，返回 0 。<img src="/12-Redis%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%882020%E6%9C%80%E6%96%B0%E7%89%88%EF%BC%89-%E9%87%8D%E7%82%B9.assets/img.jpg" alt="img"></p>
<p>使用SETNX完成同步锁的流程及事项如下(img)：使用SETNX命令获取锁，若返回0（key已存在，锁已存在）则获取失败，反之获取成功为了防止获取锁后程序出现异常，导致其他线程&#x2F;进程调用SETNX命令总是返回</p>
<p>0而进入死锁状态，需要为该key设置一个“合理”的过期时间释放锁，使用DEL命令将锁数据删除</p>
<h2 id="如何解决-Redis-的并发竞争-Key-问题"><a href="#如何解决-Redis-的并发竞争-Key-问题" class="headerlink" title="如何解决 Redis 的并发竞争 Key 问题"></a>如何解决 Redis 的并发竞争 Key 问题</h2><p>所谓 Redis 的并发竞争 Key 的问题也就是多个系统同时对一个 key 进行操作，但是 后执行的顺序和我们期望的顺序不同，这样也就导致了结果的不同！</p>
<p>推荐一种方案：分布式锁（zookeeper 和 redis 都可以实现分布式锁）。（如果不存在 Redis 的并发竞争 Key 问题，不要使用分布式锁，这样会影响性能）基于zookeeper临时有序节点可以实现的分布式锁。大致思想为：每个客户端对某个方法加锁时，在zookeeper上的与该方法对应的指定节点的目录下，生成一个唯一的瞬时有序节点。 判断是否获取锁的方式很简单，只需要判断有序节点中序号 小的一个。 当释放锁的时候，只需将这个瞬时节点删除即可。同时，其可以避免服务宕机导致的锁无法释放，而产生的死锁问题。完成业务流程后，删除对应的子节点释放锁。</p>
<p>在实践中，当然是从以可靠性为主。所以首推Zookeeper。</p>
<h2 id="分布式Redis是前期做还是后期规模上来了再做好？为什么？"><a href="#分布式Redis是前期做还是后期规模上来了再做好？为什么？" class="headerlink" title="分布式Redis是前期做还是后期规模上来了再做好？为什么？"></a>分布式Redis是前期做还是后期规模上来了再做好？为什么？</h2><p>既然Redis是如此的轻量（单实例只使用1M内存），为防止以后的扩容， 好的办法就是一开始就启动较多实例。即便你只有一台服务器，你也可以一开始就让Redis以分布式的方式运行，使用分区，在同一台服务器上启动多个实例。</p>
<p>一开始就多设置几个Redis实例，例如32或者64个实例，对大多数用户来说这操作起来可能比较麻烦，但是从长久来看做这点牺牲是值得的。</p>
<p>这样的话，当你的数据不断增长，需要更多的Redis服务器时，你需要做的就是仅仅将Redis实例从一台服务迁移到另外一台服务器而已（而不用考虑重新分区的问题）。一旦你添加了另一台服务器，你需要将你一半的Redis实例从第一台机器迁移到第二台机器。</p>
<h2 id="什么是-RedLock"><a href="#什么是-RedLock" class="headerlink" title="什么是 RedLock"></a>什么是 RedLock</h2><p>Redis 官方站提出了一种权威的基于 Redis 实现分布式锁的方式名叫 </p>
<p>Redlock，此种方式比原先的单节点的方法更安全。它可以保证以下特性：</p>
<ol>
<li><p>安全特性：互斥访问，即永远只有一个 client 能拿到锁</p>
</li>
<li><p>避免死锁： 终 client 都可能拿到锁，不会出现死锁的情况，即使原本锁住某资源的 client crash 了或者出现了网络分区</p>
</li>
<li><p>容错性：只要大部分 Redis 节点存活就可以正常提供服务缓存异常缓存雪崩</p>
</li>
</ol>
<p>缓存雪崩是指缓存同一时间大面积的失效，所以，后面的请求都会落到数据库上，造成数据库短时间内承受大量请求而崩掉。</p>
<p>解决方案</p>
<ol>
<li><p>缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。</p>
</li>
<li><p>一般并发量不是特别多的时候，使用   多的解决方案是加锁排队。</p>
</li>
<li><p>给每一个缓存数据增加相应的缓存标记，记录缓存的是否失效，如果缓存标记失效，则更新数据缓存。</p>
</li>
</ol>
<h2 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h2><p>缓存穿透是指缓存和数据库中都没有的数据，导致所有的请求都落到数据库上，造成数据库短时间内承受大量请求而崩掉。</p>
<p>解决方案</p>
<ol>
<li><p>接口层增加校验，如用户鉴权校验，id做基础校验，id&lt;&#x3D;0的直接拦截；</p>
</li>
<li><p>从缓存取不到的数据，在数据库中也没有取到，这时也可以将key-</p>
</li>
</ol>
<p>value对写为key-null，缓存有效时间可以设置短点，如30秒（设置太长会导致正常情况也没法使用）。这样可以防止攻击用户反复用同一个id暴力攻击</p>
<ol start="3">
<li>采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的 bitmap 中，一个一定不存在的数据会被这个 bitmap 拦截掉，从而避免了对底层存储系统的查询压力附加</li>
</ol>
<p>对于空间的利用到达了一种极致，那就是Bitmap和布隆过滤器(Bloom Filter)。</p>
<p>Bitmap： 典型的就是哈希表缺点是，Bitmap对于每个元素只能记录1bit信息，如果还想完成额外的功能，恐怕只能靠牺牲更多的空间、时间来完成了。</p>
<p>布隆过滤器（推荐）</p>
<p>就是引入了k(k&gt;1)k(k&gt;1)个相互独立的哈希函数，保证在给定的空间、误判率下，完成元素判重的过程。</p>
<p>它的优点是空间效率和查询时间都远远超过一般的算法，缺点是有一定的误识别率和删除困难。</p>
<p>Bloom-Filter算法的核心思想就是利用多个不同的Hash函数来解决“冲突”。</p>
<p>Hash存在一个冲突（碰撞）的问题，用同一个Hash得到的两个URL的值有可能相同。为了减少冲突，我们可以多引入几个Hash，如果通过其中的一个Hash值我们得出某元素不在集合中，那么该元素肯定不在集合中。只有在所有的Hash</p>
<p>函数告诉我们该元素在集合中时，才能确定该元素存在于集合中。这便是</p>
<p>Bloom-Filter的基本思想。</p>
<p>Bloom-Filter一般用于在大数据量的集合中判定某元素是否存在。</p>
<h2 id="缓存击穿"><a href="#缓存击穿" class="headerlink" title="缓存击穿"></a>缓存击穿</h2><p>缓存击穿是指缓存中没有但数据库中有的数据（一般是缓存时间到期），这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力。和缓存雪崩不同的是，缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库。</p>
<p>解决方案</p>
<p>1.设置热点数据永远不过期。</p>
<p>2.加互斥锁，互斥锁缓存预热</p>
<p>缓存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统。这样就可以避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题！用户直接查询事先被预热的缓存数据！解决方案</p>
<ol>
<li><p>直接写个缓存刷新页面，上线时手工操作一下；</p>
</li>
<li><p>数据量不大，可以在项目启动的时候自动进行加载；</p>
</li>
<li><p>定时刷新缓存；</p>
</li>
</ol>
<h2 id="缓存降级"><a href="#缓存降级" class="headerlink" title="缓存降级"></a>缓存降级</h2><p>当访问量剧增、服务出现问题（如响应时间慢或不响应）或非核心服务影响到核心流程的性能时，仍然需要保证服务还是可用的，即使是有损服务。系统可以根据一些关键数据进行自动降级，也可以配置开关实现人工降级。</p>
<p>缓存降级的  终目的是保证核心服务可用，即使是有损的。而且有些服务是无法降级的（如加入购物车、结算）。</p>
<p>在进行降级之前要对系统进行梳理，看看系统是不是可以丢卒保帅；从而梳理出哪些必须誓死保护，哪些可降级；比如可以参考日志级别设置预案：</p>
<ol>
<li><p>一般：比如有些服务偶尔因为网络抖动或者服务正在上线而超时，可以自动降级；</p>
</li>
<li><p>警告：有些服务在一段时间内成功率有波动（如在95~100%之间），可以自动降级或人工降级，并发送告警；</p>
</li>
<li><p>错误：比如可用率低于90%，或者数据库连接池被打爆了，或者访问量突然猛增到系统能承受的 大阀值，此时可以根据情况自动降级或者人工降级；</p>
</li>
<li><p>严重错误：比如因为特殊原因数据错误了，此时需要紧急人工降级。</p>
</li>
</ol>
<p>服务降级的目的，是为了防止Redis服务故障，导致数据库跟着一起发生雪崩问题。因此，对于不重要的缓存数据，可以采取服务降级策略，例如一个比较常见的做法就是，Redis出现问题，不去数据库查询，而是直接返回默认值给用户。</p>
<h2 id="热点数据和冷数据"><a href="#热点数据和冷数据" class="headerlink" title="热点数据和冷数据"></a>热点数据和冷数据</h2><p>热点数据，缓存才有价值对于冷数据而言，大部分数据可能还没有再次访问到就已经被挤出内存，不仅占用内存，而且价值不大。频繁修改的数据，看情况考虑使用缓存对于热点数据，比如我们的某IM产品，生日祝福模块，当天的寿星列表，缓存以后可能读取数十万次。再举个例子，某导航产品，我们将导航信息，缓存以后可能读取数百万次。</p>
<p>数据更新前至少读取两次，缓存才有意义。这个是  基本的策略，如果缓存还没有起作用就失效了，那就没有太大价值了。</p>
<p>那存不存在，修改频率很高，但是又不得不考虑缓存的场景呢？有！比如，这个读取接口对数据库的压力很大，但是又是热点数据，这个时候就需要考虑通过缓存手段，减少数据库的压力，比如我们的某助手产品的，点赞数，收藏数，分享</p>
<p>数等是非常典型的热点数据，但是又不断变化，此时就需要将数据同步保存到</p>
<p>Redis缓存，减少数据库压力。</p>
<h2 id="缓存热点key"><a href="#缓存热点key" class="headerlink" title="缓存热点key"></a>缓存热点key</h2><p>缓存中的一个Key(比如一个促销商品)，在某个时间点过期的时候，恰好在这个时间点对这个Key有大量的并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。</p>
<p>解决方案对缓存查询加锁，如果KEY不存在，就加锁，然后查DB入缓存，然后解锁；其</p>
<p>他进程如果发现有锁就等待，然后等解锁后返回数据或者进入DB查询常用工具</p>
<p>Redis支持的Java客户端都有哪些？官方推荐用哪个？</p>
<p>Redisson、Jedis、lettuce等等，官方推荐使用Redisson。</p>
<h2 id="Redis和Redisson有什么关系？"><a href="#Redis和Redisson有什么关系？" class="headerlink" title="Redis和Redisson有什么关系？"></a>Redis和Redisson有什么关系？</h2><p>Redisson是一个高级的分布式协调Redis客服端，能帮助用户在分布式环境中轻松实现一些Java的对象 (Bloom filter, BitSet, Set, SetMultimap, </p>
<p>ScoredSortedSet, SortedSet, Map, ConcurrentMap, List, ListMultimap, </p>
<p>Queue, BlockingQueue, Deque, BlockingDeque, Semaphore, Lock, </p>
<p>ReadWriteLock, AtomicLong, CountDownLatch, Publish &#x2F; Subscribe, </p>
<p>HyperLogLog)。</p>
<h2 id="Jedis与Redisson对比有什么优缺点？"><a href="#Jedis与Redisson对比有什么优缺点？" class="headerlink" title="Jedis与Redisson对比有什么优缺点？"></a>Jedis与Redisson对比有什么优缺点？</h2><p>Jedis是Redis的Java实现的客户端，其API提供了比较全面的Redis命令的支</p>
<p>持；Redisson实现了分布式和可扩展的Java数据结构，和Jedis相比，功能较为简单，不支持字符串操作，不支持排序、事务、管道、分区等Redis特性。</p>
<p>Redisson的宗旨是促进使用者对Redis的关注分离，从而让使用者能够将精力更集中地放在处理业务逻辑上。</p>
<h1 id="其他问题"><a href="#其他问题" class="headerlink" title="其他问题"></a>其他问题</h1><h2 id="Redis与Memcached的区别"><a href="#Redis与Memcached的区别" class="headerlink" title="Redis与Memcached的区别"></a>Redis与Memcached的区别</h2><p>两者都是非关系型内存键值数据库，现在公司一般都是用 Redis 来实现缓存，而且 Redis 自身也越来越强大了！Redis 与 Memcached 主要有以下不同：</p>
<table>
<thead>
<tr>
<th>对比参数</th>
<th>Redis</th>
<th>Memcac hed</th>
</tr>
</thead>
<tbody><tr>
<td>类型</td>
<td>1. 支持内存 2. 非关系型数据库</td>
<td>1. 支持内存 2. 键值对形式 3. 缓存形式</td>
</tr>
<tr>
<td>数据存储类型</td>
<td>1. String 2. List 3.    Set 4.   Hash 5.   Sort Set   【俗称  ZSet】</td>
<td>1.    文本型   2.    二进制类型</td>
</tr>
<tr>
<td>查询【操作】类型</td>
<td>1. 批量操作 2. 事务支持 3. 每个类型不同的  CRUD</td>
<td>1.常用的  CRUD 2. 少量的其他命令</td>
</tr>
<tr>
<td>附加功能</td>
<td>1.  发布&#x2F;订阅模式 2. 主从分区 3. 序列化  支持 4. 脚本支持  【Lua脚本】</td>
<td>1. 多线程服务支持</td>
</tr>
<tr>
<td>网络IO模型</td>
<td>1. 单线程的多路 IO 复用模型</td>
<td>1. 多线程，非阻塞IO模式</td>
</tr>
<tr>
<td>事件库</td>
<td>自封转简易事件库 AeEvent</td>
<td>贵族血统的  LibEvent 事件库</td>
</tr>
<tr>
<td>持久化支持</td>
<td>1. RDB 2.   AOF</td>
<td>不支持</td>
</tr>
<tr>
<td>集群模式</td>
<td>原生支持 cluster 模式，可以实现主从复制，读写分离</td>
<td>没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>内存管理机制</td>
<td>在 Redis 中，并不是所有数据都一直存储在内存中，可以将一些很久没用  的 value 交换到磁盘</td>
<td>Memcach ed 的数据则会一直在内存中，  Memcach  ed 将内存分割成特定长度的块来存储数据，以完全解决内存碎片的问题。但是这种方式会使得内存的利用率不高，例如块的大小为 128   bytes，只存储 100 bytes 的数据，那么剩下的 28 bytes 就浪费掉了。</td>
</tr>
<tr>
<td></td>
<td>复杂数据</td>
<td>纯key-  value，数据量非常大，并发量非常大的业务</td>
</tr>
<tr>
<td>适用场景</td>
<td>结构，有持久化，高可用需求，value 存储内容较大</td>
<td></td>
</tr>
</tbody></table>
<p>(1) memcached所有的值均是简单的字符串，redis作为其替代者，支持更为丰富的数据类型</p>
<p>(2) redis的速度比memcached快很多</p>
<p>(3) redis可以持久化其数据</p>
<h2 id="如何保证缓存与数据库双写时的数据一致性？"><a href="#如何保证缓存与数据库双写时的数据一致性？" class="headerlink" title="如何保证缓存与数据库双写时的数据一致性？"></a>如何保证缓存与数据库双写时的数据一致性？</h2><p>你只要用缓存，就可能会涉及到缓存与数据库双存储双写，你只要是双写，就一定会有数据一致性的问题，那么你如何解决一致性问题？一般来说，就是如果你的系统不是严格要求缓存+数据库必须一致性的话，缓存可以稍微的跟数据库偶尔有不一致的情况， 好不要做这个方案，读请求和写请求串行化，串到一个内存队列里去，这样就可以保证一定不会出现不一致的情况串行化之后，就会导致系统的吞吐量会大幅度的降低，用比正常情况下多几倍的机器去支撑线上的一个请求。</p>
<p>还有一种方式就是可能会暂时产生不一致的情况，但是发生的几率特别小，就是先更新数据库，然后再删除缓存。</p>
<table>
<thead>
<tr>
<th>问题场景</th>
<th>描述</th>
<th>解决</th>
</tr>
</thead>
<tbody><tr>
<td>先写缓存，再写数据库，缓存写成功，数据库写失败</td>
<td>缓存写成功，但写数据库失败或者响应延迟，则下次读取（并发读）缓存时，就出现脏读</td>
<td>这个写缓存的方式，本身就是错误的，需要改为先写数据库，把旧缓存置为失效；读取数据的时候，如果缓存不存在，则读取数据库再写缓存</td>
</tr>
<tr>
<td>先写数据库，再写缓存，数据库写成功，缓存写失败</td>
<td>写数据库成功，但写缓存失败，则下次读取（并发读）缓存时，则读不到数据</td>
<td>缓存使用时，假如读缓存失败，先读数据库，再回写缓存的方式实现</td>
</tr>
<tr>
<td>需要缓存异步刷新</td>
<td>指数据库操作和写缓存不在一个操作步骤中，比如在分布式场景下，无法做到同时写缓存或需要异步刷新（补</td>
<td>确定哪些数据适合此类场景，根据经验值确定合理的数据不一致时间，用户数据刷新的时间间隔</td>
</tr>
<tr>
<td></td>
<td>救措施）时候</td>
<td></td>
</tr>
</tbody></table>
<h2 id="Redis常见性能问题和解决方案？"><a href="#Redis常见性能问题和解决方案？" class="headerlink" title="Redis常见性能问题和解决方案？"></a>Redis常见性能问题和解决方案？</h2><ol>
<li><p>Master 好不要做任何持久化工作，包括内存快照和AOF日志文件，特别是不要启用内存快照做持久化。</p>
</li>
<li><p>如果数据比较关键，某个Slave开启AOF备份数据，策略为每秒同步一次。</p>
</li>
<li><p>为了主从复制的速度和连接的稳定性，Slave和Master  好在同一个局域网内。</p>
</li>
<li><p>尽量避免在压力较大的主库上增加从库</p>
</li>
<li><p>Master调用BGREWRITEAOF重写AOF文件，AOF在重写的时候会占大量的CPU和内存资源，导致服务load过高，出现短暂服务暂停现象。</p>
</li>
<li><p>为了Master的稳定性，主从复制不要用图状结构，用单向链表结构更稳定，即主从关系为：Master&lt;–Slave1&lt;–Slave2&lt;–Slave3…，这样的结构也方便解决单点故障问题，实现Slave对Master的替换，也即，如果</p>
</li>
</ol>
<p>Master挂了，可以立马启用Slave1做Master，其他不变。</p>
<h2 id="Redis官方为什么不提供Windows版本？"><a href="#Redis官方为什么不提供Windows版本？" class="headerlink" title="Redis官方为什么不提供Windows版本？"></a>Redis官方为什么不提供Windows版本？</h2><p>因为目前Linux版本已经相当稳定，而且用户量很大，无需开发windows版本，反而会带来兼容性等问题。</p>
<h3 id="一个字符串类型的值能存储最大容量是多少？"><a href="#一个字符串类型的值能存储最大容量是多少？" class="headerlink" title="一个字符串类型的值能存储最大容量是多少？"></a>一个字符串类型的值能存储最大容量是多少？</h3><p>512M</p>
<p>Redis如何做大量数据插入？ Redis2.6开始redis-cli支持一种新的被称之为pipe mode的新模式用于执行大量数据插入工作。</p>
<h2 id="假如Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如果将它们全部找出来？"><a href="#假如Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如果将它们全部找出来？" class="headerlink" title="假如Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如果将它们全部找出来？"></a>假如Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如果将它们全部找出来？</h2><p>使用keys指令可以扫出指定模式的key列表。</p>
<p>对方接着追问：如果这个redis正在给线上的业务提供服务，那使用keys指令会有什么问题？这个时候你要回答redis关键的一个特性：redis的单线程的。keys指令会导致线程阻塞一段时间，线上服务会停顿，直到指令执行完毕，服务才能恢复。这个时候可以使用scan指令，scan指令可以无阻塞的提取出指定模式的key列表，但是会有一定的重复概率，在客户端做一次去重就可以了，但是整体所花费的时间会比直接用keys指令长。</p>
<h2 id="使用Redis做过异步队列吗，是如何实现的"><a href="#使用Redis做过异步队列吗，是如何实现的" class="headerlink" title="使用Redis做过异步队列吗，是如何实现的"></a>使用Redis做过异步队列吗，是如何实现的</h2><p>使用list类型保存数据信息，rpush生产消息，lpop消费消息，当lpop没有消息时，可以sleep一段时间，然后再检查有没有信息，如果不想sleep的话，可以使用blpop, 在没有信息的时候，会一直阻塞，直到信息的到来。redis可以通过 pub&#x2F;sub主题订阅模式实现一个生产者，多个消费者，当然也存在一定的缺点，当消费者下线时，生产的消息会丢失。</p>
<h2 id="Redis如何实现延时队列"><a href="#Redis如何实现延时队列" class="headerlink" title="Redis如何实现延时队列"></a>Redis如何实现延时队列</h2><p>使用sortedset，使用时间戳做score, 消息内容作为key,调用zadd来生产消息，消费者使用zrangbyscore获取n秒之前的数据做轮询处理。</p>
<h2 id="Redis回收进程如何工作的？"><a href="#Redis回收进程如何工作的？" class="headerlink" title="Redis回收进程如何工作的？"></a>Redis回收进程如何工作的？</h2><ol>
<li><p>一个客户端运行了新的命令，添加了新的数据。</p>
</li>
<li><p>Redis检查内存使用情况，如果大于maxmemory的限制， 则根据设定好的策略进行回收。</p>
</li>
<li><p>一个新的命令被执行，等等。</p>
</li>
<li><p>所以我们不断地穿越内存限制的边界，通过不断达到边界然后不断地回收回到边界以下。</p>
</li>
</ol>
<p>如果一个命令的结果导致大量内存被使用（例如很大的集合的交集保存到一个新的键），不用多久内存限制就会被这个内存使用量超越。</p>
<h2 id="Redis回收使用的是什么算法？"><a href="#Redis回收使用的是什么算法？" class="headerlink" title="Redis回收使用的是什么算法？"></a>Redis回收使用的是什么算法？</h2><p>LRU算法</p>

      
    </div>

    
    
    

       
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/10/12/11-Linux%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%882020%E6%9C%80%E6%96%B0%E7%89%88%EF%BC%89/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="善善332">
      <meta itemprop="description" content="运气和努力一样重要">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="和善寺">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/10/12/11-Linux%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%882020%E6%9C%80%E6%96%B0%E7%89%88%EF%BC%89/" class="post-title-link" itemprop="url">未命名</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-10-12 15:01:16" itemprop="dateCreated datePublished" datetime="2022-10-12T15:01:16+08:00">2022-10-12</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-03-03 13:51:29" itemprop="dateModified" datetime="2021-03-03T13:51:29+08:00">2021-03-03</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Linux概述"><a href="#Linux概述" class="headerlink" title="Linux概述"></a>Linux概述</h1><h2 id="1-什么是Linux"><a href="#1-什么是Linux" class="headerlink" title="1. 什么是Linux"></a>1. 什么是Linux</h2><p>Linux是一套免费使用和自由传播的类Unix操作系统，是一个基于POSIX和Unix 的多用户、多任务、支持多线程和多CPU的操作系统。它能运行主要的Unix工 具软件、应用程序和网络协议。它支持32位和64位硬件。Linux继承了Unix以网 络为核心的设计思想，是一个性能稳定的多用户网络操作系统。 </p>
<h2 id="2-Unix和Linux有什么区别？"><a href="#2-Unix和Linux有什么区别？" class="headerlink" title="2. Unix和Linux有什么区别？"></a>2. Unix和Linux有什么区别？</h2><p>Linux和Unix都是功能强大的操作系统，都是应用广泛的服务器操作系统，有很 多相似之处，甚至有一部分人错误地认为Unix和Linux操作系统是一样的，然 而，事实并非如此，以下是两者的区别。 </p>
<ol>
<li>开源性 Linux是一款开源操作系统，不需要付费，即可使用；Unix是一款对源码实行知 识产权保护的传统商业软件，使用需要付费授权使用。 </li>
<li>跨平台性 Linux操作系统具有良好的跨平台性能，可运行在多种硬件平台上；Unix操作系 统跨平台性能较弱，大多需与硬件配套使用。 </li>
<li>可视化界面 Linux除了进行命令行操作，还有窗体管理系统；Unix只是命令行下的系统。 </li>
<li>硬件环境 Linux操作系统对硬件的要求较低，安装方法更易掌握；Unix对硬件要求比较苛 刻，按照难度较大。 </li>
<li>用户群体 Linux的用户群体很广泛，个人和企业均可使用；Unix的用户群体比较窄，多是 安全性要求高的大型企业使用，如银行、电信部门等，或者Unix硬件厂商使 用，如Sun等。</li>
</ol>
<p>相比于Unix操作系统，Linux操作系统更受广大计算机爱好者的喜爱，主要原因 是Linux操作系统具有Unix操作系统的全部功能，并且能够在普通PC计算机上实 现全部的Unix特性，开源免费的特性，更容易普及使用！ </p>
<h2 id="3-什么是-Linux-内核？"><a href="#3-什么是-Linux-内核？" class="headerlink" title="3. 什么是 Linux 内核？"></a>3. 什么是 Linux 内核？</h2><p>Linux 系统的核心是内核。内核控制着计算机系统上的所有硬件和软件，在必要 时分配硬件，并根据需要执行软件。 </p>
<p>系统内存管理 </p>
<p>应用程序管理 </p>
<p>硬件设备管理 </p>
<p>文件系统管理 </p>
<h2 id="4-Linux的基本组件是什么？"><a href="#4-Linux的基本组件是什么？" class="headerlink" title="4. Linux的基本组件是什么？"></a>4. Linux的基本组件是什么？</h2><p>就像任何其他典型的操作系统一样，Linux拥有所有这些组件：内核，shell和 GUI，系统实用程序和应用程序。Linux比其他操作系统更具优势的是每个方面 都附带其他功能，所有代码都可以免费下载。 </p>
<h2 id="5-Linux-的体系结构"><a href="#5-Linux-的体系结构" class="headerlink" title="5. Linux 的体系结构"></a>5. Linux 的体系结构</h2><p>从大的方面讲，Linux 体系结构可以分为两块：</p>
<p><img src="/11-Linux%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%882020%E6%9C%80%E6%96%B0%E7%89%88%EF%BC%89.assets/Linux%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84.png" alt="Linux体系结构"></p>
<ul>
<li>用户空间(User Space) ：用户空间又包括用户的应用程序(User  Applications)、C 库(C Library) 。 </li>
<li>内核空间(Kernel Space) ：内核空间又包括系统调用接口(System Call  Interface)、内核(Kernel)、平台架构相关的代码(Architecture-Dependent Kernel  Code) 。</li>
</ul>
<p><strong>为什么 Linux 体系结构要分为用户空间和内核空间的原因？</strong></p>
<ul>
<li>现代 CPU 实现了不同的工作模式，不同模式下 CPU 可以执行的指令和访问 的寄存器不同。 </li>
<li>Linux 从 CPU 的角度出发，为了保护内核的安全，把系统分成了两部分。</li>
</ul>
<p>用户空间和内核空间是程序执行的<strong>两种不同的状态</strong>，我们可以通过两种方式完成 用户空间到内核空间的转移：1）系统调用；2）硬件中断。 </p>
<h2 id="6-BASH和DOS之间的基本区别是什么？"><a href="#6-BASH和DOS之间的基本区别是什么？" class="headerlink" title="6. BASH和DOS之间的基本区别是什么？"></a>6. BASH和DOS之间的基本区别是什么？</h2><p>BASH和DOS控制台之间的主要区别在于3个方面： </p>
<ul>
<li>BASH命令区分大小写，而DOS命令则不区分; </li>
<li>在BASH下，&#x2F; character是目录分隔符，\作为转义字符。在DOS下，&#x2F;用作命令 参数分隔符，\是目录分隔符 </li>
<li>DOS遵循命名文件中的约定，即8个字符的文件名后跟一个点，扩展名为3个字 符。BASH没有遵循这样的惯例。</li>
</ul>
<h2 id="7-Linux-开机启动过程？"><a href="#7-Linux-开机启动过程？" class="headerlink" title="7. Linux 开机启动过程？"></a>7. Linux 开机启动过程？</h2><p>**了解即可。 **</p>
<ol>
<li>主机加电自检，加载 BIOS 硬件信息。 </li>
<li>读取 MBR 的引导文件(GRUB、LILO)。 </li>
<li>引导 Linux 内核。 </li>
<li>运行第一个进程 init (进程号永远为 1 )。 </li>
<li>进入相应的运行级别。 </li>
<li>运行终端，输入用户名和密码。</li>
</ol>
<h2 id="8-Linux系统缺省的运行级别？"><a href="#8-Linux系统缺省的运行级别？" class="headerlink" title="8. Linux系统缺省的运行级别？"></a>8. Linux系统缺省的运行级别？</h2><ul>
<li>关机。 </li>
<li>单机用户模式。 </li>
<li>字符界面的多用户模式(不支持网络)。 </li>
<li>字符界面的多用户模式。 </li>
<li>未分配使用。 </li>
<li>图形界面的多用户模式。 </li>
<li>重启。</li>
</ul>
<h2 id="9-Linux-使用的进程间通信方式？"><a href="#9-Linux-使用的进程间通信方式？" class="headerlink" title="9. Linux 使用的进程间通信方式？"></a>9. Linux 使用的进程间通信方式？</h2><p>**了解即可，不需要太深入。 **</p>
<ol>
<li>管道(pipe)、流管道(s_pipe)、有名管道(FIFO)。</li>
<li>信号(signal) 。 </li>
<li>消息队列。 </li>
<li>共享内存。 </li>
<li>信号量。 </li>
<li>套接字(socket) 。</li>
</ol>
<h2 id="10-Linux-有哪些系统日志文件？"><a href="#10-Linux-有哪些系统日志文件？" class="headerlink" title="10. Linux 有哪些系统日志文件？"></a>10. Linux 有哪些系统日志文件？</h2><p>**比较重要的是 <code>/var/log/messages </code>日志文件。 **<br>    该日志文件是许多进程日志文件的汇总，从该文件可以看出任何入侵企图或成功的入 侵。<br>    另外，如果胖友的系统里有 ELK 日志集中收集，它也会被收集进去。 </p>
<h1 id="Linux系统安装多个桌面环境有帮助吗？"><a href="#Linux系统安装多个桌面环境有帮助吗？" class="headerlink" title="Linux系统安装多个桌面环境有帮助吗？"></a>Linux系统安装多个桌面环境有帮助吗？</h1><p>通常，一个桌面环境，如KDE或Gnome，足以在没有问题的情况下运行。尽管系统允许从一个环境切换到另一个环境，但这对用户来说都是优先考虑的问题。有些程序在一个环境中工作而在另一个环境中无法工作，因此它也可以被视为选择使用哪个环境的一个因素。</p>
<h1 id="什么是交换空间？"><a href="#什么是交换空间？" class="headerlink" title="什么是交换空间？"></a>什么是交换空间？</h1><p>交换空间是Linux使用的一定空间，用于临时保存一些并发运行的程序。当RAM 没有足够的内存来容纳正在执行的所有程序时，就会发生这种情况。</p>
<h1 id="什么是root帐户"><a href="#什么是root帐户" class="headerlink" title="什么是root帐户"></a>什么是root帐户</h1><p>root帐户就像一个系统管理员帐户，允许你完全控制系统。你可以在此处创建和维护用户帐户，为每个帐户分配不同的权限。每次安装Linux时都是默认帐户。</p>
<h1 id="什么是LILO？"><a href="#什么是LILO？" class="headerlink" title="什么是LILO？"></a>什么是LILO？</h1><p>LILO是Linux的引导加载程序。它主要用于将Linux操作系统加载到主内存中，以便它可以开始运行。什么是BASH？</p>
<p>BASH是Bourne Again SHell的缩写。它由Steve Bourne编写，作为原始</p>
<p>Bourne Shell（由&#x2F; bin &#x2F; sh表示）的替代品。它结合了原始版本的Bourne </p>
<p>Shell的所有功能，以及其他功能，使其更容易使用。从那以后，它已被改编为运行Linux的大多数系统的默认shell。</p>
<h1 id="什么是CLI？"><a href="#什么是CLI？" class="headerlink" title="什么是CLI？"></a>什么是CLI？</h1><p>命令行界面（英语<strong>：command-line interface</strong>，缩写]：CLI）是在图形用</p>
<p>户界面得到普及之前使用  为广泛的用户界面，它通常不支持鼠标，用户通过键</p>
<p>盘输入指令，计算机接收到指令后，予以执行。也有人称之为字符用户界面</p>
<p>（CUI）。</p>
<p>通常认为，命令行界面（CLI）没有图形用户界面（GUI）那么方便用户操作。</p>
<p>因为，命令行界面的软件通常需要用户记忆操作的命令，但是，由于其本身的特点，命令行界面要较图形用户界面节约计算机系统的资源。在熟记命令的前提下，使用命令行界面往往要较使用图形用户界面的操作速度要快。所以，图形用户界面的操作系统中，都保留着可选的命令行界面。</p>
<h1 id="什么是GUI？"><a href="#什么是GUI？" class="headerlink" title="什么是GUI？"></a>什么是GUI？</h1><p>图形用户界面（Graphical User Interface，简称 GUI，又称图形用户接口）是指采用图形方式显示的计算机操作用户界面。</p>
<p>图形用户界面是一种人与计算机通信的界面显示格式，允许用户使用鼠标等输入设备操纵屏幕上的图标或菜单选项，以选择命令、调用文件、启动程序或执行其它一些日常任务。与通过键盘输入文本或字符命令来完成例行任务的字符界面相比，图形用户界面有许多优点。</p>
<h1 id="开源的优势是什么？"><a href="#开源的优势是什么？" class="headerlink" title="开源的优势是什么？"></a>开源的优势是什么？</h1><p>开源允许你将软件（包括源代码）免费分发给任何感兴趣的人。然后，人们可以添加功能，甚至可以调试和更正源代码中的错误。它们甚至可以让它运行得更好，然后再次自由地重新分配这些增强的源代码。这  终使社区中的每个人受益。</p>
<h1 id="GNU项目的重要性是什么？"><a href="#GNU项目的重要性是什么？" class="headerlink" title="GNU项目的重要性是什么？"></a>GNU项目的重要性是什么？</h1><p>这种所谓的自由软件运动具有多种优势，例如可以自由地运行程序以及根据你的需要自由学习和修改程序。它还允许你将软件副本重新分发给其他人，以及自由改进软件并将其发布给公众。</p>
<h1 id="磁盘、目录、文件"><a href="#磁盘、目录、文件" class="headerlink" title="磁盘、目录、文件"></a>磁盘、目录、文件</h1><h2 id="简单-Linux-文件系统？"><a href="#简单-Linux-文件系统？" class="headerlink" title="简单 Linux 文件系统？"></a>简单 Linux 文件系统？</h2><p>在 Linux 操作系统中，所有被操作系统管理的资源，例如网络接口卡、磁盘驱</p>
<p>动器、打印机、输入输出设备、普通文件或是目录都被看作是一个文件。</p>
<p>也就是说在 Linux 系统中有一个重要的概念<strong>：一切都是文件</strong>。其实这是</p>
<p>Unix 哲学的一个体现，而 Linux 是重写 Unix 而来，所以这个概念也就传承了下来。在 Unix 系统中，把一切资源都看作是文件，包括硬件设备。UNIX系统把每个硬件都看成是一个文件，通常称为设备文件，这样用户就可以用读写文件的方式实现对硬件的访问。</p>
<p>Linux 支持 5 种文件类型，如下图所示：<img src="/11-Linux%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%882020%E6%9C%80%E6%96%B0%E7%89%88%EF%BC%89.assets/%E6%96%87%E4%BB%B6%E7%B1%BB%E5%9E%8B.jpg" alt="文件类型"></p>
<h2 id="Linux-的目录结构是怎样的？"><a href="#Linux-的目录结构是怎样的？" class="headerlink" title="Linux 的目录结构是怎样的？"></a>Linux 的目录结构是怎样的？</h2><p>这个问题，一般不会问。更多是实际使用时，需要知道。</p>
<p>Linux 文件系统的结构层次鲜明，就像一棵倒立的树，  顶层是其根目录：</p>
<p><img src="/11-Linux%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%882020%E6%9C%80%E6%96%B0%E7%89%88%EF%BC%89.assets/Linux%E7%9A%84%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84.jpg" alt="Linux的目录结构"></p>
<p>常见目录说明：</p>
<ul>
<li>&#x2F;bin： 存放二进制可执行文件(ls,cat,mkdir等)，常用命令一般都在这里；</li>
<li>&#x2F;etc： 存放系统管理和配置文件；</li>
<li>&#x2F;home： 存放所有用户文件的根目录，是用户主目录的基点，比如用户user的主目录就是&#x2F;home&#x2F;user，可以用~user表示；</li>
<li>**&#x2F;usr **： 用于存放系统应用程序；</li>
<li>&#x2F;opt： 额外安装的可选应用程序包所放置的位置。一般情况下，我们可以把</li>
<li>tomcat等都安装到这里；</li>
<li>&#x2F;proc： 虚拟文件系统目录，是系统内存的映射。可直接访问这个目录来获取系统信息；</li>
<li>&#x2F;root： 超级用户（系统管理员）的主目录（特权阶级o）；</li>
<li>&#x2F;sbin: 存放二进制可执行文件，只有root才能访问。这里存放的是系统管理员使用的系统级别的管理命令和程序。如ifconfig等；</li>
<li>&#x2F;dev： 用于存放设备文件；</li>
<li>&#x2F;mnt： 系统管理员安装临时文件系统的安装点，系统提供这个目录是让用户临时挂载其他的文件系统；</li>
<li>&#x2F;boot： 存放用于系统引导时使用的各种文件；</li>
<li>**&#x2F;lib **： 存放着和系统运行相关的库文件 ；</li>
<li>&#x2F;tmp： 用于存放各种临时文件，是公用的临时文件存储点；</li>
<li>&#x2F;var： 用于存放运行时需要改变数据的文件，也是某些大文件的溢出区，比方说各种服务的日志文件（系统启动日志等。）等；</li>
<li>&#x2F;lost+found： 这个目录平时是空的，系统非正常关机而留下“无家可归”的文件（windows下叫什么.chk）就在这里。</li>
</ul>
<h2 id="什么是-inode-？"><a href="#什么是-inode-？" class="headerlink" title="什么是 inode ？"></a>什么是 inode ？</h2><p>一般来说，面试不会问 inode 。但是 inode 是一个重要概念，是理解 Unix&#x2F;Linux 文件系统和硬盘储存的基础。</p>
<p>理解inode，要从文件储存说起。</p>
<p>文件储存在硬盘上，硬盘的 小存储单位叫做”扇区”（Sector）。每个扇区储存</p>
<p>512字节（相当于0.5KB）。</p>
<p>操作系统读取硬盘的时候，不会一个个扇区地读取，这样效率太低，而是一次性连续读取多个扇区，即一次性读取一个”块”（block）。这种由多个扇区组成的”块”，是文件存取的 小单位。”块”的大小， 常见的是4KB，即连续八个 sector组成一个 block。</p>
<p>文件数据都储存在”块”中，那么很显然，我们还必须找到一个地方储存文件的元信息，比如文件的创建者、文件的创建日期、文件的大小等等。这种储存文件元信息的区域就叫做inode，中文译名为”索引节点”。</p>
<p>每一个文件都有对应的inode，里面包含了与该文件有关的一些信息。</p>
<p>简述 Linux 文件系统通过 i 节点把文件的逻辑结构和物理结构转换的工作过程？</p>
<p>如果看的一脸懵逼，也没关系。一般来说，面试官不太会问这个题目。</p>
<p>Linux 通过 inode 节点表将文件的逻辑结构和物理结构进行转换。</p>
<ul>
<li>inode 节点是一个 64 字节长的表，表中包含了文件的相关信息，其中有文件的大小、文件所有者、文件的存取许可方式以及文件的类型等重要信息。在 inode 节点表中 重要的内容是磁盘地址表。在磁盘地址表中有 13 个块号，文件将以块号在磁盘地址表中出现的顺序依次读取相应的块。</li>
<li>Linux 文件系统通过把 inode 节点和文件名进行连接，当需要读取该文件时，文件系统在当前目录表中查找该文件名对应的项，由此得到该文件相对应的 inode 节点号，通过该 inode 节点的磁盘地址表把分散存放的文件物理块连接成文件的逻辑结构</li>
</ul>
<h2 id="什么是硬链接和软链接？"><a href="#什么是硬链接和软链接？" class="headerlink" title="什么是硬链接和软链接？"></a>什么是硬链接和软链接？</h2><p>1）     硬链接</p>
<p>由于 Linux 下的文件是通过索引节点(inode)来识别文件，硬链接可以认为是一个指针，指向文件索引节点的指针，系统并不为它重新分配 inode 。每添加一个一个硬链接，文件的链接数就加 1 。</p>
<ul>
<li>不足：1）不可以在不同文件系统的文件间建立链接；2）只有超级用户才可以为目录创建硬链接。</li>
</ul>
<p>2）     软链接软链接克服了硬链接的不足，没有任何文件系统的限制，任何用户可以创建指向目录的符号链接。因而现在更为广泛使用，它具有更大的灵活性，甚至可以跨越不同机器、不同网络对文件进行链接。</p>
<ul>
<li>不足：因为链接文件包含有原文件的路径信息，所以当原文件从一个目录下移到其他目录中，再访问链接文件，系统就找不到了，而硬链接就没有这个缺陷，你想怎么移就怎么移；还有它要系统分配额外的空间用于建立新的索引节点和保存原文件的路径。</li>
</ul>
<p>实际场景下，基本是使用软链接。总结区别如下：</p>
<ul>
<li>硬链接不可以跨分区，软件链可以跨分区。</li>
<li>硬链接指向一个 inode 节点，而软链接则是创建一个新的 inode 节点。</li>
<li>删除硬链接文件，不会删除原文件，删除软链接文件，会把原文件删除。</li>
</ul>
<p>RAID 是什么?</p>
<p>RAID 全称为独立磁盘冗余阵列(Redundant Array of Independent Disks)，基本思想就是把多个相对便宜的硬盘组合起来，成为一个硬盘阵列组，使性能达到甚至超过一个价格昂贵、 容量巨大的硬盘。RAID 通常被用在服务器电脑上，使用完全相同的硬盘组成一个逻辑扇区，因此操作系统只会把它当做一个硬盘。</p>
<p>RAID 分为不同的等级，各个不同的等级均在数据可靠性及读写性能上做了不同的权衡。在实际应用中，可以依据自己的实际需求选择不同的 RAID 方案。</p>
<p>当然，因为很多公司都使用云服务，大家很难接触到 RAID 这个概念，更多的可能是普通云盘、SSD 云盘酱紫的概念。</p>
<h1 id="安全"><a href="#安全" class="headerlink" title="安全"></a>安全</h1><h2 id="一台-Linux-系统初始化环境后需要做一些什么安全工作？"><a href="#一台-Linux-系统初始化环境后需要做一些什么安全工作？" class="headerlink" title="一台 Linux 系统初始化环境后需要做一些什么安全工作？"></a>一台 Linux 系统初始化环境后需要做一些什么安全工作？</h2><p>1、添加普通用户登陆，禁止 root 用户登陆，更改 SSH 端口号。</p>
<p>修改 SSH 端口不一定绝对哈。当然，如果要暴露在外网，建议改下。l</p>
<p>2、服务器使用密钥登陆，禁止密码登陆。</p>
<p> 3、开启防火墙，关闭 SElinux ，根据业务需求设置相应的防火墙规则。</p>
<p>4、   装 fail2ban 这种防止 SSH 暴力破击的软件。</p>
<p>5、   设置只允许公司办公网出口 IP 能登陆服务器(看公司实际需要)</p>
<p>也可以安装 VPN 等软件，只允许连接 VPN 到服务器上。</p>
<p>6、   只允许有需要的服务器可以访问外网，其它全部禁止。</p>
<p>7、   做好软件层面的防护。</p>
<p>7.1 设置 nginx_waf 模块防止 SQL 注入。</p>
<p>7.2 把 Web 服务使用 www 用户启动，更改网站目录的所有者和所属组为 www 。</p>
<h2 id="什么叫-CC-攻击？什么叫-DDOS-攻击？"><a href="#什么叫-CC-攻击？什么叫-DDOS-攻击？" class="headerlink" title="什么叫 CC 攻击？什么叫 DDOS 攻击？"></a>什么叫 CC 攻击？什么叫 DDOS 攻击？</h2><ul>
<li>CC 攻击，主要是用来攻击页面的，模拟多个用户不停的对你的页面进行访问，从而使你的系统资源消耗殆尽。</li>
<li>DDOS 攻击，中文名叫分布式拒绝服务攻击，指借助服务器技术将多个计算机联合起来作为攻击平台，来对一个或多个目标发动 DDOS 攻击。</li>
</ul>
<p>攻击，即是通过大量合法的请求占用大量网络资源，以达到瘫痪网络的目的。</p>
<p>怎么预防 CC 攻击和 DDOS 攻击？防 CC、DDOS 攻击，这些只能是用硬件防火墙做流量清洗，将攻击流量引入黑洞。</p>
<p>流量清洗这一块，主要是买 ISP 服务商的防攻击的服务就可以，机房一般有空余流量，我们一般是买服务，毕竟攻击不会是持续长时间。</p>
<h2 id="什么是网站数据库注入？"><a href="#什么是网站数据库注入？" class="headerlink" title="什么是网站数据库注入？"></a>什么是网站数据库注入？</h2><ul>
<li>由于程序员的水平及经验参差不齐，大部分程序员在编写代码的时候，没有对用户输入数据的合法性进行判断。</li>
<li>应用程序存在安全隐患。用户可以提交一段数据库查询代码，根据程序返回的结果，获得某些他想得知的数据，这就是所谓的 SQL 注入。</li>
<li>SQL注入，是从正常的 WWW 端口访问，而且表面看起来跟一般的 Web 页面访问没什么区别，如果管理员没查看日志的习惯，可能被入侵很长时间都不会发觉。</li>
</ul>
<p>如何过滤与预防？</p>
<p>数据库网页端注入这种，可以考虑使用 nginx_waf 做过滤与预防。</p>
<h1 id="Shell"><a href="#Shell" class="headerlink" title="Shell"></a>Shell</h1><p>本小节为选读。我也不太会写 Shell 脚本，都是写的时候，在网络上拼拼凑凑。。。</p>
<h2 id="Shell-脚本是什么？"><a href="#Shell-脚本是什么？" class="headerlink" title="Shell 脚本是什么？"></a>Shell 脚本是什么？</h2><p>一个 Shell 脚本是一个文本文件，包含一个或多个命令。作为系统管理员，我们经常需要使用多个命令来完成一项任务，我们可以添加这些所有命令在一个文本文件(Shell 脚本)来完成这些日常工作任务。</p>
<p>什么是默认登录 Shell ？在 Linux 操作系统，”&#x2F;bin&#x2F;bash” 是默认登录 Shell，是在创建用户时分配的。</p>
<p>使用 chsh 命令可以改变默认的 Shell 。示例如下所示：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1	## chsh &lt;用户名&gt; ‐s &lt;新shell&gt;</span><br><span class="line">2	## chsh ThinkWon ‐s /bin/sh</span><br></pre></td></tr></table></figure>

<p>在 Shell 脚本中，如何写入注释？</p>
<p>注释可以用来描述一个脚本可以做什么和它是如何工作的。每一行注释以 # 开头。例子如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1 #!/bin/bash</span><br><span class="line">2 ## This is a command</span><br><span class="line">3  echo “I am logged in as $USER”</span><br></pre></td></tr></table></figure>

<h2 id="语法级"><a href="#语法级" class="headerlink" title="语法级"></a>语法级</h2><p>可以在 Shell 脚本中使用哪些类型的变量？</p>
<p>在 Shell 脚本，我们可以使用两种类型的变量：</p>
<ul>
<li><p>系统定义变量<br>系统变量是由系统系统自己创建的。这些变量通常由大写字母组成，可以通过 set 命令查看。</p>
</li>
<li><p>用户定义变量<br>用户变量由系统用户来生成和定义，变量的值可以通过命令 “echo $&lt;变量名&gt;” 查看。<br>Shell脚本中 $? 标记的用途是什么？在写一个 Shell 脚本时，如果你想要检查前一命令是否执行成功，在 if 条件中使用 $? 可以来检查前一命令的结束状态。</p>
</li>
<li><p>如果结束状态是 0 ，说明前一个命令执行成功。例如:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1	root@localhost:~## ls /usr/bin/shar</span><br><span class="line">2	/usr/bin/shar</span><br><span class="line">3	root@localhost:~## echo $?</span><br><span class="line">4	0</span><br></pre></td></tr></table></figure>
</li>
<li><p>如果结束状态不是0，说明命令执行失败。例如：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1	root@localhost:~## ls /usr/bin/share</span><br><span class="line">2	ls: cannot access /usr/bin/share: No such file or directory 3 root@localhost:~## echo $?</span><br><span class="line">4 2</span><br></pre></td></tr></table></figure></li>
</ul>
<p>Bourne Shell(bash) 中有哪些特殊的变量？下面的表列出了 Bourne Shell 为命令行设置的特殊变量。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">1	内建变量 解释</span><br><span class="line">2	$0 命令行中的脚本名字</span><br><span class="line">3	$1 第一个命令行参数</span><br><span class="line">4	$2 第二个命令行参数</span><br><span class="line">5	….. …….</span><br><span class="line">6	$9 第九个命令行参数</span><br><span class="line">7	$## 命令行参数的数量</span><br><span class="line">8	$* 所有命令行参数，以空格隔开</span><br></pre></td></tr></table></figure>

<p>如何取消变量或取消变量赋值？ unset 命令用于取消变量或取消变量赋值。语法如下所示：</p>
<p><code>1 ## unset &lt;变量名&gt;</code></p>
<p>Shell 脚本中 if 语法如何嵌套?</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">1  if [ 条件 ]</span><br><span class="line">2  then</span><br><span class="line">3  命令1</span><br><span class="line">4  命令2</span><br><span class="line">5 …..</span><br><span class="line">6  else</span><br><span class="line">7  if [ 条件 ]</span><br><span class="line">8  then</span><br><span class="line">9  命令1</span><br><span class="line">10  命令2</span><br><span class="line">11  ….</span><br><span class="line">12  else</span><br><span class="line">13  命令1</span><br><span class="line">14  命令2</span><br><span class="line">15  …..</span><br><span class="line">16  fi</span><br><span class="line">17  fi</span><br></pre></td></tr></table></figure>

<p>在 Shell 脚本中如何比较两个数字？在 if-then 中使用测试命令（ -gt 等）来比较两个数字。例如：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">1 #!/bin/bash</span><br><span class="line">2 x=10</span><br><span class="line">3 y=20</span><br><span class="line">4 if [ $x ‐gt $y ]</span><br><span class="line">5  then</span><br><span class="line">6  echo “x is greater than y”</span><br><span class="line">7  else</span><br><span class="line">8  echo “y is greater than x”</span><br><span class="line">9 fi</span><br></pre></td></tr></table></figure>

<p>Shell 脚本中 case 语句的语法?</p>
<p>基础语法如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">1	case 变量 in</span><br><span class="line">2	值1)</span><br><span class="line">3	命令1</span><br><span class="line">4	命令2</span><br><span class="line">5	…..</span><br><span class="line">6	最后命令</span><br><span class="line">!!</span><br><span class="line">7</span><br><span class="line">8	值2)</span><br><span class="line">9	命令1</span><br><span class="line">10	命令2</span><br><span class="line">11	……</span><br><span class="line">12	最后命令</span><br><span class="line">13	;;</span><br><span class="line">14	esac</span><br></pre></td></tr></table></figure>

<p>Shell 脚本中 for 循环语法？基础语法如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1  for 变量 in 循环列表</span><br><span class="line">2 do</span><br><span class="line">3  命令1</span><br><span class="line">4  命令2</span><br><span class="line">5 ….</span><br><span class="line">6  最后命令</span><br><span class="line">7  done</span><br></pre></td></tr></table></figure>

<p>Shell 脚本中 while 循环语法？如同 for 循环，while 循环只要条件成立就重复它的命令块。不同于 for循环，while 循环会不断迭代，直到它的条件不为真。基础语法：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1	while [ 条件 ]</span><br><span class="line">2	do</span><br><span class="line">3	命令…</span><br><span class="line">4	done</span><br></pre></td></tr></table></figure>

<p>do-while 语句的基本格式？</p>
<p>do-while 语句类似于 while 语句，但检查条件语句之前先执行命令（LCTT 译注：意即至少执行一次。）。下面是用 do-while 语句的语法：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1	do</span><br><span class="line">2	&#123;</span><br><span class="line">3	命令</span><br><span class="line">4	&#125; while (条件)</span><br></pre></td></tr></table></figure>

<p>Shell 脚本中 break 命令的作用？</p>
<p>break 命令一个简单的用途是退出执行中的循环。我们可以在 while 和 until 循环中使用 break 命令跳出循环。 Shell 脚本中 continue 命令的作用？ continue 命令不同于 break 命令，它只跳出当前循环的迭代，而不是整个循环。 continue 命令很多时候是很有用的，例如错误发生，但我们依然希望继续执行大循环的时候。</p>
<p>如何使脚本可执行?</p>
<p>使用 chmod 命令来使脚本可执行。例子如下：chmod a+x myscript.sh 。</p>
<p>#!&#x2F;bin&#x2F;bash 的作用？</p>
<p>#!&#x2F;bin&#x2F;bash 是 Shell 脚本的第一行，称为释伴（shebang）行。</p>
<p>这里 # 符号叫做 hash ，而 ! 叫做 bang。它的意思是命令通过 &#x2F;bin&#x2F;bash 来执行。</p>
<p>如何调试 Shell脚本？</p>
<p>使用 -x’ 数（sh -x myscript.sh）可以调试 Shell脚本。另一个种方法是使用 -nv 参数(sh -nv myscript.sh)。</p>
<p>如何将标准输出和错误输出同时重定向到同一位置?</p>
<p>方法一：2&gt;&amp;1 (如## ls &#x2F;usr&#x2F;share&#x2F;doc &gt; out.txt 2&gt;&amp;1 ) 。</p>
<p>方法二：&amp;&gt; (如## ls &#x2F;usr&#x2F;share&#x2F;doc &amp;&gt; out.txt ) 。</p>
<p>在 Shell 脚本中，如何测试文件？</p>
<p>test 命令可以用来测试文件。基础用法如下表格：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">1	Test 用法</span><br><span class="line">2	‐d 文件名 如果文件存在并且是目录，返回true</span><br><span class="line">3	‐e 文件名 如果文件存在，返回true</span><br><span class="line">4	‐f 文件名 如果文件存在并且是普通文件，返回true</span><br><span class="line">5	‐r 文件名 如果文件存在并可读，返回true</span><br><span class="line">6	‐s 文件名 如果文件存在并且不为空，返回true</span><br><span class="line">7	‐w 文件名 如果文件存在并可写，返回true</span><br><span class="line">8	‐x 文件名 如果文件存在并可执行，返回true</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>在 Shell 脚本如何定义函数呢？</p>
<p>函数是拥有名字的代码块。当我们定义代码块，我们就可以在我们的脚本调用函数名字，该块就会被执行。示例如下所示：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">1	$ diskusage () &#123; df ‐h ; &#125;</span><br><span class="line">2	译注：下面是我给的shell函数语法，原文没有</span><br><span class="line">3	[ function ] 函数名 [()]</span><br><span class="line">4	&#123;</span><br><span class="line">5	命令;</span><br><span class="line">6	[return int;]</span><br><span class="line">7	&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>如何让 Shell 就脚本得到来自终端的输入?</p>
<p>read 命令可以读取来自终端（使用键盘）的数据。read 命令得到用户的输入并置于你给出的变量中。例子如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">1	## vi /tmp/test.sh</span><br><span class="line">!/</span><br><span class="line">2	#bin/bash</span><br><span class="line">3	echo ‘Please enter your name’</span><br><span class="line">4	read name</span><br><span class="line">5	echo “My Name is $name”</span><br><span class="line">6	## ./test.sh</span><br><span class="line">7	Please enter your name</span><br><span class="line">8	ThinkWon</span><br><span class="line">9	My Name is ThinkWon</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>如何执行算术运算？</p>
<p>有两种方法来执行算术运算：</p>
<p>1、使用 expr 命令：## expr 5 + 2 。</p>
<p> 2、用一个美元符号和方括号（$[ 表达式 ]）：test&#x3D;$[16 + 4] ; test&#x3D;$[16 + 4] </p>
<h2 id="编程题-。"><a href="#编程题-。" class="headerlink" title="编程题(。)"></a>编程题(。)</h2><p>判断一文件是不是字符设备文件，如果是将其拷贝到 &#x2F;dev 目录下？</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">1 #!/bin/bash</span><br><span class="line">2  read ‐p &quot;Input file name: &quot; FILENAME</span><br><span class="line">3 if [ ‐c &quot;$FILENAME&quot; ];then</span><br><span class="line">4	cp $FILENAME /dev</span><br><span class="line">5 fi</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>添加一个新组为 class1 ，然后添加属于这个组的 30 个用户，用户名的形式为 stdxx ，其中 xx 从 01 到 30 ？</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"> #!/bin/bash</span><br><span class="line">2  groupadd class1</span><br><span class="line">3 for((i=1;i&lt;31;i++))</span><br><span class="line">4 do</span><br><span class="line">5   if [ $i ‐le 10 ];then</span><br><span class="line">6   useradd ‐g class1 std0$i</span><br><span class="line">7   else</span><br><span class="line">8   useradd ‐g class1 std$i</span><br><span class="line">9   fi</span><br><span class="line">10  done</span><br></pre></td></tr></table></figure>

<p>编写 Shell 程序，实现自动删除 50 个账号的功能，账号名为stud1 至 stud50？</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1 #!/bin/bash</span><br><span class="line">2 for((i=1;i&lt;51;i++))</span><br><span class="line">3 do</span><br><span class="line">4   userdel ‐r stud$i</span><br><span class="line">5  done</span><br></pre></td></tr></table></figure>

<p>写一个 sed 命令，修改 &#x2F;tmp&#x2F;input.txt 文件的内容？</p>
<p>要求：</p>
<p>删除所有空行。</p>
<p>一行中，如果包含 “11111”，则在 “11111” 前面插入 “AAA”，在 “11111” 后面插入 “BBB” 。比如：将内容为 &#96;000111112222 的一行改为 0000AAA11111BBB2222 。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">1	[root@~]## cat ‐n /tmp/input.txt</span><br><span class="line">2	1 000011111222</span><br><span class="line">3	2</span><br><span class="line">4	3 000011111222222</span><br><span class="line">5	4 11111000000222</span><br><span class="line">6	5</span><br><span class="line">7	6</span><br><span class="line">8	7 111111111111122222222222</span><br><span class="line">9	8 2211111111</span><br><span class="line">10	9 112222222</span><br><span class="line">11	10 1122</span><br><span class="line">12	11</span><br><span class="line">13</span><br><span class="line">14	## 删除所有空行命令</span><br><span class="line">15	[root@~]## sed &#x27;/^$/d&#x27; /tmp/input.txt</span><br><span class="line">16	000011111222</span><br><span class="line">17	000011111222222</span><br><span class="line">18	11111000000222</span><br><span class="line">19	111111111111122222222222</span><br><span class="line">20	2211111111</span><br><span class="line">21	112222222</span><br><span class="line">22	1122</span><br><span class="line">23</span><br><span class="line">24	## 插入指定的字符</span><br><span class="line">25	[root@~]## sed &#x27;s#\(11111\)#AAA\1BBB#g&#x27; /tmp/input.txt</span><br><span class="line">26	0000AAA11111BBB222</span><br><span class="line">27	0000AAA11111BBB222222</span><br><span class="line">28	AAA11111BBB000000222</span><br><span class="line">29	AAA11111BBBAAA11111BBB11122222222222</span><br><span class="line">30	22AAA11111BBB111</span><br><span class="line">31	112222222</span><br><span class="line">32	1122</span><br></pre></td></tr></table></figure>

<p>实战如何选择 Linux 操作系统版本?</p>
<p>一般来讲，桌面用户首选 Ubuntu ；服务器首选 RHEL 或 CentOS ，两者中首选 CentOS 。</p>
<p>根据具体要求：</p>
<p>安全性要求较高，则选择 Debian 或者 FreeBSD 。</p>
<p>需要使用数据库高级服务和电子邮件网络应用的用户可以选择 SUSE 。</p>
<p>想要新技术新功能可以选择 Feddora ，Feddora 是 RHEL 和 CentOS 的一个测试版和预发布版本。</p>
<p> 【重点】根据现有状况，绝大多数互联网公司选择 CentOS 。现在比较常用的是 6 系列，现在市场占有大概一半左右。另外的原因是 CentOS </p>
<p>更侧重服务器领域，并且无版权约束。</p>
<p>CentOS 7 系列，也慢慢使用的会比较多了。</p>
<h2 id="如何规划一台-Linux-主机，步骤是怎样？"><a href="#如何规划一台-Linux-主机，步骤是怎样？" class="headerlink" title="如何规划一台 Linux 主机，步骤是怎样？"></a>如何规划一台 Linux 主机，步骤是怎样？</h2><p>1、确定机器是做什么用的，比如是做 WEB 、DB、还是游戏服务器。</p>
<p>不同的用途，机器的配置会有所不同。</p>
<p>2、确定好之后，就要定系统需要怎么安装，默认安装哪些系统、分区怎么做。</p>
<p> 3、需要优化系统的哪些参数，需要创建哪些用户等等的。</p>
<h2 id="请问当用户反馈网站访问慢，你会如何处理？"><a href="#请问当用户反馈网站访问慢，你会如何处理？" class="headerlink" title="请问当用户反馈网站访问慢，你会如何处理？"></a>请问当用户反馈网站访问慢，你会如何处理？</h2><p>有哪些方面的因素会导致网站网站访问慢？</p>
<p>1、服务器出口带宽不够用</p>
<ul>
<li>本身服务器购买的出口带宽比较小。一旦并发量大的话，就会造成分给每个用户的出口带宽就小，访问速度自然就会慢。</li>
<li>跨运营商网络导致带宽缩减。例如，公司网站放在电信的网络上，那么客户这边对接是长城宽带或联通，这也可能导致带宽的缩减。</li>
</ul>
<p> 2、服务器负载过大，导致响应不过来</p>
<p>可以从两个方面入手分析：</p>
<ul>
<li>分析系统负载，使用 w 命令或者 uptime 命令查看系统负载。如果负载很高，则使用 top 命令查看 CPU ，MEM 等占用情况，要么是 CPU 繁忙，要么是内存不够。</li>
<li>如果这二者都正常，再去使用 sar 命令分析网卡流量，分析是不是遭到了攻击。一旦分析出问题的原因，采取对应的措施解决，如决定要不要杀死一些进程，或者禁止一些访问等。</li>
</ul>
<p>3、数据库瓶颈</p>
<ul>
<li>如果慢查询比较多。那么就要开发人员或 DBA 协助进行 SQL 语句的优化。</li>
<li>如果数据库响应慢，考虑可以加一个数据库缓存，如 Redis 等。然后，也可以搭建 MySQL 主从，一台 MySQL 服务器负责写，其他几台从数据库负责读。</li>
</ul>
<p>4、网站开发代码没有优化好</p>
<ul>
<li>例如 SQL 语句没有优化，导致数据库读写相当耗时。</li>
</ul>
<p>针对网站访问慢，怎么去排查？</p>
<p> 1、首先要确定是用户端还是服务端的问题。当接到用户反馈访问慢，那边自己立即访问网站看看，如果自己这边访问快，基本断定是用户端问题，就需要耐心跟客户解释，协助客户解决问题。不要上来就看服务端的问题。一定要从源头开始，逐步逐步往下。</p>
<p> 2、如果访问也慢，那么可以利用浏览器的调试功能，看看加载那一项数据消耗时间过多，是图片加载慢，还是某些数据加载慢。</p>
<p> 3、针对服务器负载情况。查看服务器硬件(网络、CPU、内存)的消耗情况。如果是购买的云主机，比如阿里云，可以登录阿里云平台提供各方面的监控，比如 CPU、内存、带宽的使用情况。  </p>
<p>4、如果发现硬件资源消耗都不高，那么就需要通过查日志，比如看看 MySQL慢查询的日志，看看是不是某条 SQL 语句查询慢，导致网站访问慢。怎么去解决？</p>
<p>1、   如果是出口带宽问题，那么久申请加大出口带宽。</p>
<p>2、   如果慢查询比较多，那么就要开发人员或 DBA 协助进行 SQL 语句的优化。</p>
<p>3、   如果数据库响应慢，考虑可以加一个数据库缓存，如 Redis 等等。然后也可以搭建MySQL 主从，一台 MySQL 服务器负责写，其他几台从数据库负责读。</p>
<p>4、   申请购买 CDN 服务，加载用户的访问。</p>
<p>5、   如果访问还比较慢，那就需要从整体架构上进行优化咯。做到专角色专用，多台服务器提供同一个服务。</p>
<h2 id="Linux-性能调优都有哪几种方法？"><a href="#Linux-性能调优都有哪几种方法？" class="headerlink" title="Linux 性能调优都有哪几种方法？"></a>Linux 性能调优都有哪几种方法？</h2><p>1、Disabling daemons (关闭 daemons)。</p>
<p>2、Shutting down the GUI (关闭 GUI)。</p>
<p>3、Changing kernel parameters (改变内核参数)。</p>
<p>4、Kernel parameters (内核参数)。</p>
<p>5、Tuning the processor subsystem (处理器子系统调优)。</p>
<p>6、Tuning the memory subsystem (内存子系统调优)。</p>
<p>7、Tuning the file system (文件系统子系统调优)。</p>
<p>8、Tuning the network subsystem（网络子系统调优)。</p>
<h2 id="文件管理命令-cat-命令"><a href="#文件管理命令-cat-命令" class="headerlink" title="文件管理命令 cat 命令"></a>文件管理命令 cat 命令</h2><p>cat 命令用于连接文件并打印到标准输出设备上。</p>
<p>cat 主要有三大功能：</p>
<p>1.一次显示整个文件:</p>
<p><code>cat filename</code></p>
<p>2.从键盘创建一个文件</p>
<p><code>cat &gt; filename</code></p>
<p>只能创建新文件,不能编辑已有文件</p>
<p>3.将几个文件合并为一个文件:</p>
<p><code>cat file1 file2 &gt; file</code></p>
<ul>
<li>-b 对非空输出行号</li>
<li>-n 输出所有行号实例：</li>
</ul>
<p>（1）  把 log2012.log 的文件内容加上行号后输入 log2013.log 这个文件里</p>
<p><code>1  cat ‐n log2012.log log2013.log</code></p>
<p>（2）  把 log2012.log 和 log2013.log 的文件内容加上行号（空白行不加）之后将内容附加到 log.log 里</p>
<p><code>1  cat ‐b log2012.log log2013.log log.log</code></p>
<p>（3）  使用 here doc 生成新文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">1	cat &gt;log.txt &lt;&lt;EOF</span><br><span class="line">2	&gt;Hello</span><br><span class="line">3	&gt;World</span><br><span class="line">4	&gt;PWD=$(pwd)</span><br><span class="line">5	&gt;EOF</span><br><span class="line">6	ls ‐l log.txt</span><br><span class="line">7	cat log.txt</span><br><span class="line">8	Hello</span><br><span class="line">9	World</span><br><span class="line">=/</span><br><span class="line">10	PWD opt/soft/test</span><br></pre></td></tr></table></figure>

<p>（4）  反向列示</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1	tac log.txt</span><br><span class="line">=/</span><br><span class="line">2	PWD opt/soft/test</span><br><span class="line">3	World</span><br><span class="line">4	Hello</span><br></pre></td></tr></table></figure>

<h2 id="chmod-命令"><a href="#chmod-命令" class="headerlink" title="chmod 命令"></a>chmod 命令</h2><p>Linux&#x2F;Unix 的文件调用权限分为三级 : 文件拥有者、群组、其他。利用 chmod 可以控制文件如何被他人所调用。</p>
<p>用于改变 linux 系统文件或目录的访问权限。用它控制文件或目录的访问权限。该命令有两种用法。一种是包含字母和操作符表达式的文字设定法；另一种是包含数字的数字设定法。</p>
<p>每一文件或目录的访问权限都有三组，每组用三位表示，分别为文件属主的读、写和执行权限；与属主同组的用户的读、写和执行权限；系统中其他用户的读、写和执行权限。可使用 ls -l test.txt 查找。</p>
<p>以文件 log2012.log 为例：</p>
<p><code>1 ‐rw‐r‐‐r‐‐ 1 root root 296K 11‐13 06:03 log2012.log</code></p>
<p>第一列共有 10 个位置，第一个字符指定了文件类型。在通常意义上，一个目录也是一个文件。如果第一个字符是横线，表示是一个非目录的文件。如果是 d，表示是一个目录。从第二个字符开始到第十个 9 个字符，3 个字符一组，分别表示了 3 组用户对文件或者目录的权限。权限字符用横线代表空许可，r 代表只读，w 代表写，x 代表可执行。常用参数：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1	‐c 当发生改变时，报告处理信息</span><br><span class="line">2	‐R 处理指定目录以及其子目录下所有文件</span><br></pre></td></tr></table></figure>

<p>权限范围：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1	u ：目录或者文件的当前的用户</span><br><span class="line">2	g ：目录或者文件的当前的群组</span><br><span class="line">3	o ：除了目录或者文件的当前用户或群组之外的用户或者群组</span><br><span class="line">4	a ：所有的用户及群组</span><br></pre></td></tr></table></figure>

<p>权限代号：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1	r ：读权限，用数字4表示</span><br><span class="line">2	w ：写权限，用数字2表示</span><br><span class="line">3	x ：执行权限，用数字1表示</span><br><span class="line">4	‐ ：删除权限，用数字0表示</span><br><span class="line">5	s ：特殊权限</span><br></pre></td></tr></table></figure>

<p>实例：</p>
<p>（1）  增加文件 t.log 所有用户可执行权限</p>
<p><code>1  chmod a+x t.log</code></p>
<p>（2）  撤销原来所有的权限，然后使拥有者具有可读权限,并输出处理信息</p>
<p><code>1  chmod u=r t.log ‐c</code></p>
<p>（3）  给 file 的属主分配读、写、执行(7)的权限，给file的所在组分配读、执行</p>
<p>(5)的权限，给其他用户分配执行(1)的权限</p>
<p><code>1  chmod 751 t.log ‐c（或者：chmod u=rwx,g=rx,o=x t.log ‐c)</code></p>
<p>（4）  将 test 目录及其子目录所有文件添加可读权限</p>
<p><code>1  chmod u+r,g+r,o+r ‐R text/ ‐c</code></p>
<h2 id="chown-命令"><a href="#chown-命令" class="headerlink" title="chown 命令"></a>chown 命令</h2><p>chown 将指定文件的拥有者改为指定的用户或组，用户可以是用户名或者用户 ID；组可以是组名或者组 ID；文件是以空格分开的要改变权限的文件列表，支持通配符。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1	‐c 显示更改的部分的信息</span><br><span class="line">2	‐R 处理指定目录及子目录</span><br></pre></td></tr></table></figure>

<p>实例：</p>
<p>（1）  改变拥有者和群组 并显示改变信息</p>
<p><code>1  chown ‐c mail:mail log2012.log</code></p>
<p>（1）  改变文件群组</p>
<p><code>1  chown ‐c :mail t.log</code></p>
<p>（2）  改变文件夹及子文件目录属主及属组为 mail</p>
<p><code>1  chown ‐cR mail: test/</code></p>
<h2 id="cp-命令"><a href="#cp-命令" class="headerlink" title="cp 命令"></a>cp 命令</h2><p>将源文件复制至目标文件，或将多个源文件复制至目标目录。</p>
<p>注意：命令行复制，如果目标文件已经存在会提示是否覆盖，而在 shell 脚本中，如果不加 -i 参数，则不会提示，而是直接覆盖！</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1	‐i 提示</span><br><span class="line">2	‐r 复制目录及目录内所有项目</span><br><span class="line">3	‐a 复制的文件与原文件时间一样</span><br></pre></td></tr></table></figure>

<p>实例：</p>
<p>（1）  复制 a.txt 到 test 目录下，保持原文件时间，如果原文件存在提示是否覆盖。</p>
<p><code>1  cp ‐ai a.txt test</code></p>
<p>（2）  为 a.txt 建议一个链接（快捷方式）</p>
<p><code>1  cp ‐s a.txt link_a.txt</code></p>
<h2 id="find-命令"><a href="#find-命令" class="headerlink" title="find 命令"></a>find 命令</h2><p>用于在文件树中查找文件，并作出相应的处理。</p>
<p>命令格式：</p>
<p><code>1 find pathname ‐options [‐print ‐exec ‐ok ...]</code></p>
<p>命令参数：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1	pathname: find命令所查找的目录路径。例如用.来表示当前目录，用/来表示系统根目录。</span><br><span class="line">2	‐print： find命令将匹配的文件输出到标准输出。</span><br><span class="line">3	‐exec： find命令对匹配的文件执行该参数所给出的shell命令。相应命令的形式为&#x27;comm and&#x27; &#123; &#125; \;，注意&#123; &#125;和\；之间的空格。</span><br><span class="line">4	‐ok： 和‐exec的作用相同，只不过以一种更为安全的模式来执行该参数所给出的shell命令，在执行每一个命令之前，都会给出提示，让用户来确定是否执行。</span><br></pre></td></tr></table></figure>

<p>命令选项：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">1	‐name 按照文件名查找文件</span><br><span class="line">2	‐perm 按文件权限查找文件</span><br><span class="line">3	‐user 按文件属主查找文件</span><br><span class="line">4	‐group 按照文件所属的组来查找文件。</span><br><span class="line">5	‐type 查找某一类型的文件，诸如：</span><br><span class="line">6	b ‐ 块设备文件</span><br><span class="line">7	d ‐ 目录</span><br><span class="line">8	c ‐ 字符设备文件</span><br><span class="line">9	l ‐ 符号链接文件</span><br><span class="line">10	p ‐ 管道文件</span><br><span class="line">11	f ‐ 普通文件</span><br></pre></td></tr></table></figure>

<p>实例：</p>
<p>（1）  查找 48 小时内修改过的文件</p>
<p><code>1  find ‐atime ‐2</code></p>
<p>（2）  在当前目录查找 以 .log 结尾的文件。 . 代表当前目录</p>
<p><code>1  find ./ ‐name &#39;*.log&#39;</code></p>
<p>（3）  查找 &#x2F;opt 目录下 权限为 777 的文件</p>
<p><code>1  find /opt ‐perm 777</code></p>
<p>（4）  查找大于 1K 的文件</p>
<p><code>1  find ‐size +1000c</code></p>
<p>查找等于 1000 字符的文件</p>
<p><code>1 find ‐size 1000c</code></p>
<p>-exec 参数后面跟的是 command 命令，它的终止是以 ; 为结束标志的，所以</p>
<p>这句命令后面的分号是不可缺少的，考虑到各个系统中分号会有不同的意义，所以前面加反斜杠。{} 花括号代表前面find查找出来的文件名。</p>
<h2 id="head-命令"><a href="#head-命令" class="headerlink" title="head 命令"></a>head 命令</h2><p>head 用来显示档案的开头至标准输出中，默认 head 命令打印其相应文件的开头 10 行。常用参数：</p>
<p><code>1 ‐n&lt;行数&gt; 显示的行数（行数为复数表示从最后向前数）</code></p>
<p>实例：</p>
<p>（1）  显示 1.log 文件中前 20 行</p>
<p><code>1  head 1.log ‐n 20</code></p>
<p>（2）  显示 1.log 文件前 20 字节</p>
<p><code>1  head ‐c 20 log2014.log</code></p>
<p>（3）  显示 t.log  后 10 行</p>
<p><code>1  head ‐n ‐10 t.log</code></p>
<h2 id="less-命令"><a href="#less-命令" class="headerlink" title="less 命令"></a>less 命令</h2><p>less 与 more 类似，但使用 less 可以随意浏览文件，而 more 仅能向前移动，却不能向后移动，而且 less 在查看之前不会加载整个文件。常用命令参数：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">1	‐i 忽略搜索时的大小写</span><br><span class="line">2	‐N 显示每行的行号</span><br><span class="line">3	‐o &lt;文件名&gt; 将less 输出的内容在指定文件中保存起来</span><br><span class="line">4	‐s 显示连续空行为一行</span><br><span class="line">5	/字符串：向下搜索“字符串”的功能</span><br><span class="line">6	?字符串：向上搜索“字符串”的功能</span><br><span class="line">7	n：重复前一个搜索（与 / 或 ? 有关）</span><br><span class="line">8	N：反向重复前一个搜索（与 / 或 ? 有关）</span><br><span class="line">9	‐x &lt;数字&gt; 将“tab”键显示为规定的数字空格</span><br><span class="line">10	b 向后翻一页</span><br><span class="line">11	d 向后翻半页</span><br><span class="line">12	h 显示帮助界面</span><br><span class="line">13	Q 退出less 命令</span><br><span class="line">14	u 向前滚动半页</span><br><span class="line">15	y 向前滚动一行</span><br><span class="line">16	空格键 滚动一行</span><br><span class="line">17	回车键 滚动一页</span><br><span class="line">18	[pagedown]： 向下翻动一页</span><br><span class="line">19	[pageup]： 向上翻动一页</span><br></pre></td></tr></table></figure>

<p>实例：</p>
<p>（1）  ps 查看进程信息并通过 less 分页显示</p>
<p><code>1  ps ‐aux | less ‐N</code></p>
<p>（2）  查看多个文件</p>
<p><code>1  less 1.log 2.log</code></p>
<p>可以使用 n 查看下一个，使用 p 查看前一个。</p>
<h2 id="ln-命令"><a href="#ln-命令" class="headerlink" title="ln 命令"></a>ln 命令</h2><p>功能是为文件在另外一个位置建立一个同步的链接，当在不同目录需要该问题时，就不需要为每一个目录创建同样的文件，通过 ln 创建的链接（link）减少磁盘占用量。</p>
<p>链接分类：软件链接及硬链接软链接：</p>
<p>1.软链接，以路径的形式存在。类似于Windows操作系统中的快捷方式</p>
<p>2.软链接可以 跨文件系统 ，硬链接不可以</p>
<p>3.软链接可以对一个不存在的文件名进行链接</p>
<p>4.软链接可以对目录进行链接硬链接:</p>
<p>1.硬链接，以文件副本的形式存在。但不占用实际空间。</p>
<p>2.不允许给目录创建硬链接</p>
<p>3.硬链接只有在同一个文件系统中才能创建需要注意：</p>
<p> 第一：ln命令会保持每一处链接文件的同步性，也就是说，不论你改动了哪一处，其它的文件都会发生相同的变化；</p>
<p> 第二：ln的链接又分软链接和硬链接两种，软链接就是ln –s 源文件 目标文件，它只会在你选定的位置上生成一个文件的镜像，不会占用磁盘空间，硬链接 ln 源文件 目标文件，没有参数-s， 它会在你选定的位置上生成一个和源文件大小相同的文件，无论是软链接还是硬链接，文件都保持同步变化。</p>
<p> 第三：ln指令用在链接文件或目录，如同时指定两个以上的文件或目录，且  后的目的地是一个已经存在的目录，则会把前面指定的所有文件或目录复制到该目录中。若同时指定多个文件或目录，且  后的目的地并非是一个已存在的目录，则会出现错误信息。</p>
<p>常用参数：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1	‐b 删除，覆盖以前建立的链接</span><br><span class="line">2	‐s 软链接（符号链接）</span><br><span class="line">3	‐v 显示详细处理过程</span><br></pre></td></tr></table></figure>

<p>实例：</p>
<p>（1）  给文件创建软链接，并显示操作信息</p>
<p><code>1  ln ‐sv source.log link.log</code></p>
<p>（2）  给文件创建硬链接，并显示操作信息</p>
<p><code>1  ln ‐v source.log link1.log</code></p>
<p>（3）  给目录创建软链接</p>
<p><code>1  ln ‐sv /opt/soft/test/test3 /opt/soft/test/test5</code></p>
<h2 id="locate-命令"><a href="#locate-命令" class="headerlink" title="locate 命令"></a>locate 命令</h2><p>locate 通过搜寻系统内建文档数据库达到快速找到档案，数据库由 updatedb </p>
<p>程序来更新，updatedb 是由 cron daemon 周期性调用的。默认情况下 </p>
<p>locate 命令在搜寻数据库时比由整个由硬盘资料来搜寻资料来得快，但较差劲的是 locate 所找到的档案若是  近才建立或 刚更名的，可能会找不到，在内定值中，updatedb 每天会跑一次，可以由修改 crontab 来更新设定值 </p>
<p>(etc&#x2F;crontab)。</p>
<p>locate 与 find 命令相似，可以使用如 *、? 等进行正则匹配查找常用参数：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1	‐l num（要显示的行数）</span><br><span class="line">2	‐f 将特定的档案系统排除在外，如将proc排除在外</span><br><span class="line">3	‐r 使用正则运算式做为寻找条件</span><br></pre></td></tr></table></figure>

<p>实例：</p>
<p>（1）  查找和 pwd 相关的所有文件(文件名中包含 pwd）</p>
<p><code>1  locate pwd</code></p>
<p>（2）  搜索 etc 目录下所有以 sh 开头的文件</p>
<p><code>1  locate /etc/sh</code></p>
<p>（3）  查找 &#x2F;var 目录下，以 reason 结尾的文件</p>
<p><code>1  locate ‐r &#39;^/var.*reason$&#39;（其中.表示一个字符，*表示任务多个；.*表示任意多个字符）</code></p>
<h2 id="more-命令"><a href="#more-命令" class="headerlink" title="more 命令"></a>more 命令</h2><p>功能类似于 cat, more 会以一页一页的显示方便使用者逐页阅读，而 基本的指令就是按空白键（space）就往下一页显示，按 b 键就会往回（back）一页显示。</p>
<p>命令参数：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">1  +n 从笫 n 行开始显示</span><br><span class="line">2  ‐n 定义屏幕大小为n行</span><br><span class="line">3  +/pattern 在每个档案显示前搜寻该字串（pattern），然后从该字串前两行之后开始显示</span><br><span class="line">4  ‐c 从顶部清屏，然后显示</span><br><span class="line">5  ‐d 提示“Press space to continue，’q’ to quit（按空格键继续，按q键退出）”，禁用响铃功能</span><br><span class="line">6  ‐l 忽略Ctrl+l（换页）字符</span><br><span class="line">7  ‐p 通过清除窗口而不是滚屏来对文件进行换页，与‐c选项相似</span><br><span class="line">8  ‐s 把连续的多个空行显示为一行</span><br><span class="line">9  ‐u 把文件内容中的下画线去掉</span><br></pre></td></tr></table></figure>

<p>常用操作命令：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">1  Enter 向下 n 行，需要定义。默认为 1 行</span><br><span class="line">2  Ctrl+F 向下滚动一屏</span><br><span class="line">3  空格键 向下滚动一屏</span><br><span class="line">4  Ctrl+B 返回上一屏</span><br><span class="line">5  = 输出当前行的行号</span><br><span class="line">6  :f 输出文件名和当前行的行号</span><br><span class="line">7  V 调用vi编辑器</span><br><span class="line">8  !命令 调用Shell，并执行命令</span><br><span class="line">9  q 退出more</span><br></pre></td></tr></table></figure>

<p>实例：</p>
<p>（1）  显示文件中从第3行起的内容</p>
<p><code>1  more +3 text.txt</code></p>
<p>（2）  在所列出文件目录详细信息，借助管道使每次显示 5 行</p>
<p><code>1  ls ‐l |more ‐5</code></p>
<p>按空格显示下 5 行。</p>
<h2 id="mv-命令"><a href="#mv-命令" class="headerlink" title="mv 命令"></a>mv 命令</h2><p>移动文件或修改文件名，根据第二参数类型（如目录，则移动文件；如为文件则重命令该文件）。</p>
<p>当第二个参数为目录时，第一个参数可以是多个以空格分隔的文件或目录，然后移动第一个参数指定的多个文件到第二个参数指定的目录中。</p>
<p>实例：</p>
<p>（1）  将文件 test.log 重命名为 test1.txt</p>
<p><code>1  mv test.log test1.txt</code></p>
<p>（2）  将文件 log1.txt,log2.txt,log3.txt 移动到根的 test3 目录中</p>
<p><code>1  mv llog1.txt log2.txt log3.txt /test3</code></p>
<p>（3）  将文件 file1 改名为 file2，如果 file2 已经存在，则询问是否覆盖</p>
<p><code>1  mv ‐i log1.txt log2.txt</code></p>
<p>（4）  移动当前文件夹下的所有文件到上一级目录</p>
<p><code>1  mv * ../</code></p>
<h2 id="rm-命令"><a href="#rm-命令" class="headerlink" title="rm 命令"></a>rm 命令</h2><p>删除一个目录中的一个或多个文件或目录，如果没有使用 -r 选项，则 rm 不会删除目录。如果使用 rm 来删除文件，通常仍可以将该文件恢复原状。</p>
<p><code>1 rm[选项] 文件…</code></p>
<p>实例：</p>
<p>（1）  删除任何 .log 文件，删除前逐一询问确认：</p>
<p><code>1  rm ‐i *.log</code></p>
<p>（2）  删除 test 子目录及子目录中所有档案删除，并且不用一一确认：</p>
<p><code>1  rm ‐rf test</code></p>
<p>（3）  删除以 -f 开头的文件</p>
<p><code>1  rm ‐‐ ‐f*</code></p>
<h2 id="tail-命令"><a href="#tail-命令" class="headerlink" title="tail 命令"></a>tail 命令</h2><p>用于显示指定文件末尾内容，不指定文件时，作为输入信息进行处理。常用查看日志文件。常用参数：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1	‐f 循环读取（常用于查看递增的日志文件）</span><br><span class="line">2	‐n&lt;行数&gt; 显示行数（从后向前）</span><br></pre></td></tr></table></figure>

<p>（1）循环读取逐渐增加的文件内容</p>
<p><code>1 ping 127.0.0.1 &gt; ping.log &amp;</code></p>
<p>后台运行：可使用 jobs -l 查看，也可使用 fg 将其移到前台运行。</p>
<p><code>1 tail ‐f ping.log</code></p>
<h2 id="（查看日志）-touch-命令"><a href="#（查看日志）-touch-命令" class="headerlink" title="（查看日志） touch 命令"></a>（查看日志） touch 命令</h2><p>Linux touch命令用于修改文件或者目录的时间属性，包括存取时间和更改时间。若文件不存在，系统会建立一个新的文件。</p>
<p>ls -l 可以显示档案的时间记录。</p>
<p>语法</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1 touch [‐acfm][‐d&lt;日期时间&gt;][‐r&lt;参考文件或目录&gt;] [‐t&lt;日期时间&gt;][‐‐help][‐‐ver sion][文件或目录…]</span><br></pre></td></tr></table></figure>

<p>参数说明：</p>
<ul>
<li>a 改变档案的读取时间记录。 m 改变档案的修改时间记录。 c 假如目的档案不存在，不会建立新的档案。与 –no-create 的效果一样。</li>
<li>f 不使用，是为了与其他 unix 系统的相容性而保留。</li>
<li>r 使用参考档的时间记录，与 –file 的效果一样。</li>
<li>d 设定时间与日期，可以使用各种不同的格式。</li>
<li>t 设定档案的时间记录，格式与 date 指令相同。</li>
<li>–no-create 不会建立新档案。</li>
<li>–help 列出指令格式。</li>
<li>–version 列出版本讯息。</li>
</ul>
<p>实例</p>
<p>使用指令”touch”修改文件”testfile”的时间属性为当前系统时间，输入如下命令：</p>
<p><code>1 $ touch testfile #修改文件的时间属性</code></p>
<p>首先，使用ls命令查看testfile文件的属性，如下所示：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1	$ ls ‐l testfile #查看文件的时间属性</span><br><span class="line">2	#原来文件的修改时间为16:09</span><br><span class="line">3	‐rw‐r‐‐r‐‐ 1 hdd hdd 55 2011‐08‐22 16:09 testfile</span><br></pre></td></tr></table></figure>

<p>执行指令”touch”修改文件属性以后，并再次查看该文件的时间属性，如下所示：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1	$ touch testfile #修改文件时间属性为当前系统时间</span><br><span class="line">2	$ ls ‐l testfile #查看文件的时间属性</span><br><span class="line">3	#修改后文件的时间属性为当前系统时间</span><br><span class="line">4	‐rw‐r‐‐r‐‐ 1 hdd hdd 55 2011‐08‐22 19:53 testfile</span><br></pre></td></tr></table></figure>

<p>使用指令”touch”时，如果指定的文件不存在，则将创建一个新的空白文件。例如，在当前目录下，使用该指令创建一个空白文件”file”，输入如下命令：</p>
<p><code>1 $ touchfile#创建一个名为“file”的新的空白文件</code></p>
<h2 id="vim-命令"><a href="#vim-命令" class="headerlink" title="vim 命令"></a>vim 命令</h2><p>Vim是从 vi 发展出来的一个文本编辑器。代码补完、编译及错误跳转等方便编程的功能特别丰富，在程序员中被广泛使用。</p>
<p>打开文件并跳到第 10 行：vim +10 filename.txt 。</p>
<p>打开文件跳到第一个匹配的行：vim +&#x2F;search-term filename.txt 。</p>
<p>以只读模式打开文件：vim -R &#x2F;etc&#x2F;passwd 。</p>
<p>基本上 vi&#x2F;vim 共分为三种模式，分别是命令模式（Command mode），输入模式（Insert mode）和底线命令模式（Last line mode）。简单的说，我们可以将这三个模式想成底下的图标来表示：<img src="/11-Linux%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%882020%E6%9C%80%E6%96%B0%E7%89%88%EF%BC%89.assets/Vim%E5%B7%A5%E4%BD%9C%E6%A8%A1%E5%BC%8F.jpg" alt="Vim工作模式"></p>
<h2 id="whereis-命令"><a href="#whereis-命令" class="headerlink" title="whereis 命令"></a>whereis 命令</h2><p>whereis 命令只能用于程序名的搜索，而且只搜索二进制文件（参数-b）、</p>
<p>man说明文件（参数-m）和源代码文件（参数-s）。如果省略参数，则返回所有信息。whereis 及 locate 都是基于系统内建的数据库进行搜索，因此效率很高，而find则是遍历硬盘查找文件。</p>
<p>常用参数：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1	‐b 定位可执行文件。</span><br><span class="line">2	‐m 定位帮助文件。</span><br><span class="line">3	‐s 定位源代码文件。</span><br><span class="line">4	‐u 搜索默认路径下除可执行文件、源代码文件、帮助文件以外的其它文件。</span><br></pre></td></tr></table></figure>

<p>实例：</p>
<p>（1）  查找 locate 程序相关文件</p>
<p><code>1  whereislocate</code></p>
<p>（2）  查找 locate 的源码文件</p>
<p><code>1  whereis ‐s locate</code></p>
<p>（3）  查找 lcoate 的帮助文件</p>
<p><code>1  whereis ‐m locate</code></p>
<h2 id="which-命令"><a href="#which-命令" class="headerlink" title="which 命令"></a>which 命令</h2><p>在 linux 要查找某个文件，但不知道放在哪里了，可以使用下面的一些命令来搜索：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1	which 查看可执行文件的位置。</span><br><span class="line">2	whereis 查看文件的位置。</span><br><span class="line">3	locate 配合数据库查看文件位置。</span><br><span class="line">4	find 实际搜寻硬盘查询文件名称。</span><br></pre></td></tr></table></figure>

<p>which 是在 PATH 就是指定的路径中，搜索某个系统命令的位置，并返回第一个搜索结果。使用 which 命令，就可以看到某个系统命令是否存在，以及执行的到底是哪一个位置的命令。</p>
<p>常用参数：</p>
<p><code>1 ‐n 指定文件名长度，指定的长度必须大于或等于所有文件中最长的文件名。</code></p>
<p>实例：</p>
<p>（1）  查看 ls 命令是否存在，执行哪个</p>
<p><code>1  whichls</code></p>
<p>（2）  查看 which</p>
<p><code>1  whichwhich</code></p>
<p>（3）  查看 cd</p>
<p><code>1  which cd（显示不存在，因为 cd 是内建命令，而 which 查找显示是 PATH 中的命令）</code></p>
<p>查看当前 PATH 配置：</p>
<p>&#96;1 echo$PATH</p>
<p>或使用 env 查看所有环境变量及对应值文档编辑命令 grep 命令</p>
<p>强大的文本搜索命令，grep(Global Regular Expression Print) 全局正则表达式搜索。</p>
<p>grep 的工作方式是这样的，它在一个或多个文件中搜索字符串模板。如果模板包括空格，则必须被引用，模板后的所有字符串被看作文件名。搜索的结果被送到标准输出，不影响原文件内容。</p>
<p>命令格式：</p>
<p><code> grep [option] pattern file|dir</code></p>
<p>常用参数：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">1	‐A n ‐‐after‐context显示匹配字符后n行</span><br><span class="line">2	‐B n ‐‐before‐context显示匹配字符前n行</span><br><span class="line">3	‐C n ‐‐context 显示匹配字符前后n行</span><br><span class="line">4	‐c ‐‐count 计算符合样式的列数</span><br><span class="line">5	‐i 忽略大小写</span><br><span class="line">6	‐l 只列出文件内容符合指定的样式的文件名称</span><br><span class="line">7	‐f 从文件中读取关键词</span><br><span class="line">8	‐n 显示匹配内容的所在文件中行数</span><br><span class="line">9	‐R 递归查找文件夹</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>grep 的规则表达式:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"> ^ #锚定行的开始 如：&#x27;^grep&#x27;匹配所有以grep开头的行。 2 $ #锚定行的结束 如：&#x27;grep$&#x27;匹配所有以grep结尾的行。</span><br><span class="line">3	. #匹配一个非换行符的字符 如：&#x27;gr.p&#x27;匹配gr后接一个任意字符，然后是p。</span><br><span class="line">4	* #匹配零个或多个先前字符 如：&#x27;*grep&#x27;匹配所有一个或多个空格后紧跟grep的行。</span><br><span class="line">5	.* #一起用代表任意字符。</span><br><span class="line">6	[] #匹配一个指定范围内的字符，如&#x27;[Gg]rep&#x27;匹配Grep和grep。</span><br><span class="line">7	[^] #匹配一个不在指定范围内的字符，如：&#x27;[^A‐FH‐Z]rep&#x27;匹配不包含A‐R和T‐Z的一个</span><br><span class="line">字母开头，紧跟rep的行。</span><br><span class="line">8	\(..\) #标记匹配字符，如&#x27;\(love\)&#x27;，love被标记为1。</span><br><span class="line">9	\&lt; #锚定单词的开始，如:&#x27;\&lt;grep&#x27;匹配包含以grep开头的单词的行。</span><br><span class="line">10	\&gt; #锚定单词的结束，如&#x27;grep\&gt;&#x27;匹配包含以grep结尾的单词的行。</span><br><span class="line">11	x\&#123;m\&#125; #重复字符x，m次，如：&#x27;0\&#123;5\&#125;&#x27;匹配包含5个o的行。</span><br><span class="line">12	x\&#123;m,\&#125; #重复字符x,至少m次，如：&#x27;o\&#123;5,\&#125;&#x27;匹配至少有5个o的行。</span><br><span class="line">13	x\&#123;m,n\&#125; #重复字符x，至少m次，不多于n次，如：&#x27;o\&#123;5,10\&#125;&#x27;匹配5‐‐10个o的行。</span><br><span class="line">14	\w #匹配文字和数字字符，也就是[A‐Za‐z0‐9]，如：&#x27;G\w*p&#x27;匹配以G后跟零个或多个文字或数字字符，然后是p。</span><br><span class="line">15	\W #\w的反置形式，匹配一个或多个非单词字符，如点号句号等。</span><br><span class="line">16	\b #单词锁定符，如: &#x27;\bgrep\b&#x27;只匹配grep。</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>实例：（1）查找指定进程</p>
<p><code>1 ps ‐ef |grep svn</code></p>
<p>（2）  查找指定进程个数</p>
<p><code>1  ps ‐ef |grep svn ‐c</code></p>
<p>（3）  从文件中读取关键词</p>
<p><code>1  cat test1.txt |grep ‐f key.log</code></p>
<p>（4）  从文件夹中递归查找以grep开头的行，并只列出文件</p>
<p><code>1  grep ‐lR &#39;^grep&#39; /tmp</code></p>
<p>（5）  查找非x开关的行内容</p>
<p><code>1  grep&#39;^[^x]&#39; test.txt</code></p>
<p>（6）  显示包含 ed 或者 at 字符的内容行</p>
<p><code>1  grep ‐E &#39;ed|at&#39; test.txt</code></p>
<h2 id="wc-命令"><a href="#wc-命令" class="headerlink" title="wc 命令"></a>wc 命令</h2><p>wc(word count)功能为统计指定的文件中字节数、字数、行数，并将统计结果输出命令格式：</p>
<p><code>1 wc [option] file..</code></p>
<p>命令参数：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1	‐c 统计字节数</span><br><span class="line">2	‐l 统计行数</span><br><span class="line">3	‐m 统计字符数</span><br><span class="line">4	‐w 统计词数，一个字被定义为由空白、跳格或换行字符分隔的字符串</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>实例：</p>
<p>（1）  查找文件的 行数 单词数 字节数 文件名</p>
<p><code>1  wc text.txt</code></p>
<p>结果：</p>
<p><code>1 7 8 70 test.txt</code></p>
<p>（2）  统计输出结果的行数</p>
<p><code>1  cat test.txt |wc ‐l</code></p>
<h1 id="磁盘管理命令-cd-命令"><a href="#磁盘管理命令-cd-命令" class="headerlink" title="磁盘管理命令 cd 命令"></a>磁盘管理命令 cd 命令</h1><p>cd(changeDirectory) 命令语法：</p>
<p><code>1 cd [目录名]</code></p>
<p>说明：切换当前目录至 dirName。</p>
<p>实例：（1）进入要目录</p>
<p><code>1 cd /</code></p>
<p>（2）  进入 “home” 目录</p>
<p><code>1  cd ~</code></p>
<p>（3）  进入上一次工作路径</p>
<p><code>1  cd ‐</code></p>
<p>（4）  把上个命令的参数作为cd参数使用。</p>
<p><code>1  cd!$</code></p>
<h2 id="df-命令"><a href="#df-命令" class="headerlink" title="df 命令"></a>df 命令</h2><p>显示磁盘空间使用情况。获取硬盘被占用了多少空间，目前还剩下多少空间等信息，如果没有文件名被指定，则所有当前被挂载的文件系统的可用空间将被显</p>
<p>示。默认情况下，磁盘空间将以 1KB 为单位进行显示，除非环境变量 </p>
<p>POSIXLY_CORRECT 被指定，那样将以512字节为单位进行显示：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1	‐a 全部文件系统列表</span><br><span class="line">2	‐h 以方便阅读的方式显示信息</span><br><span class="line">3	‐i 显示inode信息</span><br><span class="line">4	‐k 区块为1024字节</span><br><span class="line">5	‐l 只显示本地磁盘</span><br><span class="line">6	‐T 列出文件系统类型</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>实例：</p>
<p>（1）  显示磁盘使用情况</p>
<p>1  df ‐l</p>
<p>（2）  以易读方式列出所有文件系统及其类型</p>
<p>1  df ‐haT</p>
<h2 id="du-命令"><a href="#du-命令" class="headerlink" title="du 命令"></a>du 命令</h2><p>du 命令也是查看使用空间的，但是与 df 命令不同的是 Linux du 命令是对文件和目录磁盘使用的空间的查看：命令格式：</p>
<p>1 du [选项] [文件]</p>
<p>常用参数：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">1	‐a 显示目录中所有文件大小</span><br><span class="line">2	‐k 以KB为单位显示文件大小</span><br><span class="line">3	‐m 以MB为单位显示文件大小</span><br><span class="line">4	‐g 以GB为单位显示文件大小</span><br><span class="line">5	‐h 以易读方式显示文件大小</span><br><span class="line">6	‐s 仅显示总计</span><br><span class="line">7	‐c或‐‐total 除了显示个别目录或文件的大小外，同时也显示所有目录或文件的总和</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>实例：</p>
<p>（1）  以易读方式显示文件夹内及子文件夹大小</p>
<p><code>1  du ‐h scf/</code></p>
<p>（2）  以易读方式显示文件夹内所有文件大小</p>
<p><code>1  du ‐ah scf/</code></p>
<p>（3）  显示几个文件或目录各自占用磁盘空间的大小，还统计它们的总和</p>
<p><code>1  du ‐hc test/ scf/</code></p>
<p>（4）  输出当前目录下各个子目录所使用的空间</p>
<p><code>1  du ‐hc ‐‐max‐depth=1 scf/</code></p>
<h2 id="ls命令"><a href="#ls命令" class="headerlink" title="ls命令"></a>ls命令</h2><p>就是 list 的缩写，通过 ls 命令不仅可以查看 linux 文件夹包含的文件，而且可以查看文件权限(包括目录、文件夹、文件权限) 查看目录信息等等。</p>
<p>常用参数搭配：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">1	ls ‐a 列出目录所有文件，包含以.开始的隐藏文件</span><br><span class="line">2	ls ‐A 列出除.及..的其它文件</span><br><span class="line">3	ls ‐r 反序排列</span><br><span class="line">4	ls ‐t 以文件修改时间排序</span><br><span class="line">5	ls ‐S 以文件大小排序</span><br><span class="line">6	ls ‐h 以易读大小显示</span><br><span class="line">7	ls ‐l 除了文件名之外，还将文件的权限、所有者、文件大小等信息详细列出来</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>实例：</p>
<p>(1) 按易读方式按时间反序排序，并显示文件详细信息</p>
<p><code>1  ls ‐lhrt</code></p>
<p>(2) 按大小反序显示文件详细信息</p>
<p><code>1  ls ‐lrS</code></p>
<p>(3)列出当前目录中所有以”t”开头的目录的详细内容</p>
<p><code>1 ls ‐l t*</code></p>
<p>(4) 列出文件绝对路径（不包含隐藏文件）</p>
<p><code>1  ls|sed&quot;s:^:</code>pwd<code>/:&quot;</code></p>
<p>(5) 列出文件绝对路径（包含隐藏文件）</p>
<p><code>1  find$pwd ‐maxdepth 1 |xargsls ‐ld</code></p>
<h2 id="mkdir-命令"><a href="#mkdir-命令" class="headerlink" title="mkdir 命令"></a>mkdir 命令</h2><p>mkdir 命令用于创建文件夹。</p>
<p>可用选项：</p>
<p>-m: 对新建目录设置存取权限，也可以用 chmod 命令设置;</p>
<p> -p: 可以是一个路径名称。此时若路径中的某些目录尚不存在,加上此选项后，系统将自动建立好那些尚不在的目录，即一次可以建立多个目录。</p>
<p>实例：</p>
<p>（1）  当前工作目录下创建名为 t的文件夹</p>
<p><code>1 mkdir t</code></p>
<p>（2）  在 tmp 目录下创建路径为 test&#x2F;t1&#x2F;t 的目录，若不存在，则创建：</p>
<p> <code>1 mkdir ‐p /tmp/test/t1/t  </code></p>
<h2 id="pwd-命令"><a href="#pwd-命令" class="headerlink" title="pwd 命令"></a>pwd 命令</h2><p>pwd 命令用于查看当前工作目录路径。</p>
<p>实例：</p>
<p>（1）  查看当前路径</p>
<p><code>1 pwd</code></p>
<p>（2）  查看软链接的实际路径</p>
<p><code>1 pwd</code></p>
<h2 id="rmdir-命令"><a href="#rmdir-命令" class="headerlink" title="rmdir 命令"></a>rmdir 命令</h2><p>从一个目录中删除一个或多个子目录项，删除某目录时也必须具有对其父目录的写权限。</p>
<p>注意：不能删除非空目录实例：</p>
<p>（1）当 parent 子目录被删除后使它也成为空目录的话，则顺便一并删除：</p>
<p>  <code>1 rmdir ‐p parent/child/child11  </code></p>
<h2 id="网络通讯命令-ifconfig-命令"><a href="#网络通讯命令-ifconfig-命令" class="headerlink" title="网络通讯命令 ifconfig 命令"></a>网络通讯命令 ifconfig 命令</h2><ul>
<li>ifconfig 用于查看和配置 Linux 系统的网络接口。</li>
<li>查看所有网络接口及其状态：ifconfig -a 。</li>
<li>使用 up 和 down 命令启动或停止某个接口：ifconfig eth0 up 和 ifconfig eth0 down 。</li>
</ul>
<p>iptables 命令</p>
<p>iptables ，是一个配置 Linux 内核防火墙的命令行工具。功能非常强大，对于</p>
<p>我们开发来说，主要掌握如何开放端口即可。例如：</p>
<p> 把来源 IP 为 192.168.1.101 访问本机 80 端口的包直接拒绝： iptables -I INPUT -s 192.168.1.101 -p tcp –dport 80 -j REJECT 。 </p>
<p> 开启 80 端口，因为web对外都是这个端口</p>
<p>iptables -A INPUT -p tcp –dport 80 -j ACCEP</p>
<p>​                    1</p>
<p> 另外，要注意使用 iptables save 命令，进行保存。否则，服务器重启后，配置的规则将丢失。</p>
<h2 id="netstat-命令"><a href="#netstat-命令" class="headerlink" title="netstat 命令"></a>netstat 命令</h2><p>Linux netstat命令用于显示网络状态。</p>
<p>利用netstat指令可让你得知整个Linux系统的网络情况。语法</p>
<p>  <code>1 netstat [‐acCeFghilMnNoprstuvVwx][‐A&lt;网络类型&gt;][‐‐ip]</code></p>
<p>参数说明：</p>
<ul>
<li>-a或–all 显示所有连线中的Socket。</li>
<li>-A&lt;网络类型&gt;或–&lt;网络类型&gt; 列出该网络类型连线中的相关地址。</li>
<li>-c或–continuous 持续列出网络状态。</li>
<li>-C或–cache 显示路由器配置的快取信息。</li>
<li>-e或–extend 显示网络其他相关信息。</li>
<li>-F或–fib 显示FIB。</li>
<li>-g或–groups 显示多重广播功能群组组员名单。</li>
<li>-h或–help 在线帮助。</li>
<li>-i或–interfaces 显示网络界面信息表单。</li>
<li>-l或–listening 显示监控中的服务器的Socket。</li>
<li>-M或–masquerade 显示伪装的网络连线。</li>
<li>-n或–numeric 直接使用IP地址，而不通过域名服务器。</li>
<li>-N或–netlink或–symbolic 显示网络硬件外围设备的符号连接名称。</li>
<li>-o或–timers 显示计时器。</li>
<li>-p或–programs 显示正在使用Socket的程序识别码和程序名称。</li>
<li>-r或–route 显示Routing Table。</li>
<li>-s或–statistice 显示网络工作信息统计表。</li>
<li>-t或–tcp 显示TCP传输协议的连线状况。</li>
<li>-u或–udp 显示UDP传输协议的连线状况。</li>
<li>-v或–verbose 显示指令执行过程。</li>
<li>-V或–version 显示版本信息。</li>
<li>-w或–raw 显示RAW传输协议的连线状况。</li>
<li>-x或–unix 此参数的效果和指定”-A unix”参数相同。</li>
<li>–ip或–inet 此参数的效果和指定”-A inet”参数相同。</li>
</ul>
<p>实例如何查看系统都开启了哪些端口？</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">1	[root@centos6 ~ 13:20 #55]# netstat ‐lnp</span><br><span class="line">2	Active Internet connections (only servers)</span><br><span class="line">3	Proto Recv‐Q Send‐Q Local Address Foreign Address State PID/Program name</span><br><span class="line">4	tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 1035/sshd</span><br><span class="line">5	tcp 0 0 :::22 :::* LISTEN 1035/sshd</span><br><span class="line">6	udp 0 0 0.0.0.0:68 0.0.0.0:* 931/dhclient 7 Active UNIX domain sockets (only servers)</span><br><span class="line">8	Proto RefCnt Flags Type State I‐Node PID/Program name Path</span><br><span class="line">9	unix 2 [ ACC ] STREAM LISTENING 6825 1/init @/com/ubuntu/upstart</span><br><span class="line">10	unix 2 [ ACC ] STREAM LISTENING 8429 1003/dbus‐daemon /var/run/dbus/syst em_bus_socket</span><br></pre></td></tr></table></figure>

<p>如何查看网络连接状况？</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1	[root@centos6 ~ 13:22 #58]# netstat ‐an</span><br><span class="line">2	Active Internet connections (servers and established)</span><br><span class="line">3	Proto Recv‐Q Send‐Q Local Address Foreign Address State</span><br><span class="line">4	tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN</span><br><span class="line">5	tcp 0 0 192.168.147.130:22 192.168.147.1:23893 ESTABLISHED</span><br><span class="line">6	tcp 0 0 :::22 :::* LISTEN</span><br><span class="line">7	udp 0 0 0.0.0.0:68 0.0.0.0:*</span><br></pre></td></tr></table></figure>

<p>如何统计系统当前进程连接数？输入命令 netstat -an | grep ESTABLISHED | wc -l 。输出结果 177 。一共有 177 连接数。用 netstat 命令配合其他命令，按照源 IP 统计所有到 80 端口的 </p>
<p>ESTABLISHED 状态链接的个数？严格来说，这个题目考验的是对 awk 的使用。</p>
<p>首先，使用 netstat -an|grep ESTABLISHED 命令。结果如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">1 tcp 0 0 120.27.146.122:80 113.65.18.33:62721 ESTABLISHED 2 tcp 0 0 120.27.146.122:80 27.43.83.115:47148 ESTABLISHED</span><br><span class="line">3	tcp 0 0 120.27.146.122:58838 106.39.162.96:443 ESTABLISHED</span><br><span class="line">4	tcp 0 0 120.27.146.122:52304 203.208.40.121:443 ESTABLISHED</span><br><span class="line">5	tcp 0 0 120.27.146.122:33194 203.208.40.122:443 ESTABLISHED</span><br><span class="line">6	tcp 0 0 120.27.146.122:53758 101.37.183.144:443 ESTABLISHED</span><br><span class="line">7	tcp 0 0 120.27.146.122:27017 23.105.193.30:50556 ESTABLISHED</span><br></pre></td></tr></table></figure>

<h2 id="ping-命令"><a href="#ping-命令" class="headerlink" title="ping 命令"></a>ping 命令</h2><p>Linux ping命令用于检测主机。</p>
<p>执行ping指令会使用ICMP传输协议，发出要求回应的信息，若远端主机的网络功能没有问题，就会回应该信息，因而得知该主机运作正常。指定接收包的次数</p>
<p><code>1 ping ‐c 2 www.baidu.com</code></p>
<h2 id="telnet-命令"><a href="#telnet-命令" class="headerlink" title="telnet 命令"></a>telnet 命令</h2><p>Linux telnet命令用于远端登入。执行telnet指令开启终端机阶段作业，并登入远端主机。语法</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1 telnet [‐8acdEfFKLrx][‐b&lt;主机别名&gt;][‐e&lt;脱离字符&gt;][‐k&lt;域名&gt;][‐l&lt;用户名称&gt;][n&lt;记录文件&gt;][‐S&lt;服务类型&gt;][‐X&lt;认证形态&gt;][主机名称或IP地址&lt;通信端口&gt;]</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>参数说明:</p>
<ul>
<li>8 允许使用8位字符资料，包括输入与输出。 -a 尝试自动登入远端系统。</li>
<li>-b&lt;主机别名&gt; 使用别名指定远端主机名称。</li>
<li>-c 不读取用户专属目录里的.telnetrc文件。</li>
<li>-d 启动排错模式。</li>
<li>-e&lt;脱离字符&gt; 设置脱离字符。</li>
<li>-E 滤除脱离字符。</li>
<li>-f 此参数的效果和指定”-F”参数相同。</li>
<li>-F 使用Kerberos V5认证时，加上此参数可把本地主机的认证数据上传到远端主机。</li>
<li>-k&lt;域名&gt; 使用Kerberos认证时，加上此参数让远端主机采用指定的领域名，而非该主机的域名。</li>
<li>-K 不自动登入远端主机。</li>
<li>-l&lt;用户名称&gt; 指定要登入远端主机的用户名称。</li>
<li>-L 允许输出8位字符资料。</li>
<li>-n&lt;记录文件&gt; 指定文件记录相关信息。</li>
<li>-r 使用类似rlogin指令的用户界面。</li>
<li>-S&lt;服务类型&gt; 设置telnet连线所需的IP TOS信息。</li>
<li>-x 假设主机有支持数据加密的功能，就使用它。</li>
<li>-X&lt;认证形态&gt; 关闭指定的认证形态。</li>
</ul>
<p>实例</p>
<p>登录远程主机</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1	# 登录IP为 192.168.0.5 的远程主机</span><br><span class="line">2	telnet 192.168.0.5</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="系统管理命令-date-命令"><a href="#系统管理命令-date-命令" class="headerlink" title="系统管理命令 date 命令"></a>系统管理命令 date 命令</h2><p>显示或设定系统的日期与时间。</p>
<p>命令参数：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">1	‐d&lt;字符串&gt;  显示字符串所指的日期与时间。字符串前后必须加上双引号。</span><br><span class="line">2	‐s&lt;字符串&gt;  根据字符串来设置日期与时间。字符串前后必须加上双引号。</span><br><span class="line">3	‐u  显示GMT。</span><br><span class="line">4	%H 小时(00‐23)</span><br><span class="line">5	%I 小时(00‐12)</span><br><span class="line">6	%M 分钟(以00‐59来表示)</span><br><span class="line">7	%s 总秒数。起算时间为1970‐01‐01 00:00:00 UTC。</span><br><span class="line">8	%S 秒(以本地的惯用法来表示) 9 %a 星期的缩写。</span><br><span class="line">10	%A 星期的完整名称。</span><br><span class="line">11	%d 日期(以01‐31来表示)。</span><br><span class="line">12	%D 日期(含年月日)。</span><br><span class="line">13	%m 月份(以01‐12来表示)。</span><br><span class="line">14	%y 年份(以00‐99来表示)。</span><br><span class="line">15	%Y 年份(以四位数来表示)。</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>实例：</p>
<p>（1）  显示下一天</p>
<p><code>1 date +%Y%m%d ‐‐date=&quot;+1 day&quot; //显示下一天的日期</code></p>
<p>（2）  -d参数使用</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1  date ‐d &quot;nov 22&quot; 今年的 11 月 22 日是星期三</span><br><span class="line">2  date ‐d &#x27;2 weeks&#x27; 2周后的日期</span><br><span class="line">3  date ‐d &#x27;next monday&#x27; (下周一的日期)</span><br><span class="line">4  date ‐d next‐day +%Y%m%d（明天的日期）或者：date ‐d tomorrow +%Y%m%d</span><br><span class="line">5  date ‐d last‐day +%Y%m%d(昨天的日期) 或者：date ‐d yesterday +%Y%m%d</span><br><span class="line">6  date ‐d last‐month +%Y%m(上个月是几月)</span><br><span class="line">7  date ‐d next‐month +%Y%m(下个月是几月)</span><br></pre></td></tr></table></figure>

<h2 id="free-命令"><a href="#free-命令" class="headerlink" title="free 命令"></a>free 命令</h2><p>显示系统内存使用情况，包括物理内存、交互区内存(swap)和内核缓冲区内存。</p>
<p>命令参数：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1	‐b 以Byte显示内存使用情况</span><br><span class="line">2	‐k 以kb为单位显示内存使用情况</span><br><span class="line">3	‐m 以mb为单位显示内存使用情况</span><br><span class="line">4	‐g 以gb为单位显示内存使用情况</span><br><span class="line">5	‐s&lt;间隔秒数&gt; 持续显示内存</span><br><span class="line">6	‐t 显示内存使用总合</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>实例：</p>
<p>（1）  显示内存使用情况</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1	free</span><br><span class="line">2	free ‐k</span><br><span class="line">3	free ‐m</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>（1）  以总和的形式显示内存的使用信息</p>
<p><code>1  free ‐t</code></p>
<p>（2）  周期性查询内存使用情况</p>
<p><code>1  free ‐s 10</code></p>
<h2 id="kill-命令"><a href="#kill-命令" class="headerlink" title="kill 命令"></a>kill 命令</h2><p>发送指定的信号到相应进程。不指定型号将发送SIGTERM（15）终止指定进</p>
<p>程。如果任无法终止该程序可用”-KILL” 参数，其发送的信号为SIGKILL(9) ，将强制结束进程，使用ps命令或者jobs 命令可以查看进程号。root用户将影响用户的进程，非root用户只能影响自己的进程。</p>
<p>常用参数：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1	‐l 信号，若果不加信号的编号参数，则使用“‐l”参数会列出全部的信号名称</span><br><span class="line">2	‐a 当处理当前进程时，不限制命令名和进程号的对应关系</span><br><span class="line">3	‐p 指定kill 命令只打印相关进程的进程号，而不发送任何信号</span><br><span class="line">4	‐s 指定发送信号</span><br><span class="line">5	‐u 指定用户</span><br></pre></td></tr></table></figure>

<p>实例：</p>
<p>（1）先使用ps查找进程pro1，然后用kill杀掉</p>
<p>1 kill ‐9 $(ps ‐ef |grep pro1)</p>
<h2 id="ps-命令"><a href="#ps-命令" class="headerlink" title="ps 命令"></a>ps 命令</h2><p>ps(process status)，用来查看当前运行的进程状态，一次性查看，如果需要动态连续结果使用 top linux上进程有5种状态:</p>
<ol>
<li><p>运行(正在运行或在运行队列中等待)</p>
</li>
<li><p>中断(休眠中, 受阻, 在等待某个条件的形成或接受到信号)</p>
</li>
<li><p>不可中断(收到信号不唤醒和不可运行, 进程必须等待直到有中断发生) </p>
</li>
<li><p>僵死(进程已终止, 但进程描述符存在, 直到父进程调用wait4()系统调用后释放)</p>
</li>
<li><p>停止(进程收到SIGSTOP, SIGSTP, SIGTIN, SIGTOU信号后停止运行运</p>
</li>
</ol>
<p>行)</p>
<p>ps 工具标识进程的5种状态码:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">1	D 不可中断 uninterruptible sleep (usually IO)</span><br><span class="line">2	R 运行 runnable (on run queue)</span><br><span class="line">3	S 中断 sleeping</span><br><span class="line">4	T 停止 traced or stopped</span><br><span class="line">5	Z 僵死 a defunct (”zombie”) process</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>命令参数：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">1	‐A 显示所有进程</span><br><span class="line">2	a 显示所有进程</span><br><span class="line">3	‐a 显示同一终端下所有进程</span><br><span class="line">4	c 显示进程真实名称</span><br><span class="line">5	e 显示环境变量</span><br><span class="line">6	f 显示进程间的关系</span><br><span class="line">7	r 显示当前终端运行的进程</span><br><span class="line">8	‐aux 显示所有包含其它使用的进程</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>实例：</p>
<p>（1）  显示当前所有进程环境变量及进程间关系</p>
<p><code>1  ps ‐ef</code></p>
<p>（2）  显示当前所有进程</p>
<p><code>1  ps ‐A</code></p>
<p>（3）  与grep联用查找某进程</p>
<p><code>1  ps ‐aux |grep apache</code></p>
<p>（4）  找出与 cron 与 syslog 这两个服务有关的 PID 号码</p>
<p><code>1  ps aux |grep&#39;(cron|syslog)&#39;</code></p>
<h2 id="rpm-命令"><a href="#rpm-命令" class="headerlink" title="rpm 命令"></a>rpm 命令</h2><p>Linux rpm 命令用于管理套件。</p>
<p>rpm(redhat package manager) 原本是 Red Hat Linux 发行版专门用来管理 </p>
<p>Linux 各项套件的程序，由于它遵循 GPL 规则且功能强大方便，因而广受欢迎。逐渐受到其他发行版的采用。RPM 套件管理方式的出现，让 Linux 易于安装，升级，间接提升了 Linux 的适用度。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">1	# 查看系统自带jdk</span><br><span class="line">2	rpm ‐qa | grep jdk</span><br><span class="line">3	# 删除系统自带jdk</span><br><span class="line">4	rpm ‐e ‐‐nodeps 查看jdk显示的数据</span><br><span class="line">5	# 安装jdk</span><br><span class="line">6	rpm ‐ivh jdk‐7u80‐linux‐x64.rpm</span><br></pre></td></tr></table></figure>

<h2 id="top-命令"><a href="#top-命令" class="headerlink" title="top 命令"></a>top 命令</h2><p>显示当前系统正在执行的进程的相关信息，包括进程 ID、内存占用率、CPU 占用率等常用参数：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1	‐c 显示完整的进程命令</span><br><span class="line">2	‐s 保密模式</span><br><span class="line">3	‐p &lt;进程号&gt; 指定进程显示</span><br><span class="line">4	‐n &lt;次数&gt;循环显示次数</span><br></pre></td></tr></table></figure>

<p>实例：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">1	top ‐ 14:06:23 up 70 days, 16:44, 2 users, load average: 1.25, 1.32, 1.35</span><br><span class="line">2	Tasks: 206 total, 1 running, 205 sleeping, 0 stopped, 0 zombie</span><br><span class="line">3	Cpu(s): 5.9%us, 3.4%sy, 0.0%ni, 90.4%id, 0.0%wa, 0.0%hi, 0.2%si, 0.0%st</span><br><span class="line">4	Mem: 32949016k total, 14411180k used, 18537836k free, 169884k buffers</span><br><span class="line">5	Swap: 32764556k total, 0k used, 32764556k free, 3612636k cached</span><br><span class="line">6	PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND</span><br><span class="line">7	28894 root 22 0 1501m 405m 10m S 52.2 1.3 2534:16 java</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>前五行是当前系统情况整体的统计信息区。</p>
<p>第一行，任务队列信息，同 uptime 命令的执行结果，具体参数说明情况如下：</p>
<p>14:06:23 — 当前系统时间</p>
<p>up 70 days, 16:44 — 系统已经运行了70天16小时44分钟（在这期间系统没有重启过的吆！）</p>
<p>2 users — 当前有2个用户登录系统</p>
<p>load average: 1.15, 1.42, 1.44 — load average后面的三个数分别是1分钟、5 分钟、15分钟的负载情况。</p>
<p>load average数据是每隔5秒钟检查一次活跃的进程数，然后按特定算法计算出的数值。如果这个数除以逻辑CPU的数量，结果高于5的时候就表明系统在超负荷运转了。</p>
<p>第二行，Tasks — 任务（进程），具体信息说明如下：系统现在共有206个进程，其中处于运行中的有1个，205个在休眠（sleep）， stoped状态的有0个，zombie状态（僵尸）的有0个。</p>
<p>第三行，cpu状态信息，具体属性说明如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1	5.9%us — 用户空间占用CPU的百分比。</span><br><span class="line">2	3.4% sy — 内核空间占用CPU的百分比。</span><br><span class="line">3	0.0% ni — 改变过优先级的进程占用CPU的百分比</span><br><span class="line">4	90.4% id — 空闲CPU百分比</span><br><span class="line">5	0.0% wa — IO等待占用CPU的百分比</span><br><span class="line">6	0.0% hi — 硬中断（Hardware IRQ）占用CPU的百分比</span><br><span class="line">7	0.2% si — 软中断（Software Interrupts）占用CPU的百分比</span><br></pre></td></tr></table></figure>

<p>备注：在这里CPU的使用比率和windows概念不同，需要理解linux系统用户空间和内核空间的相关知识！</p>
<p>第四行，内存状态，具体信息如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1	32949016k total — 物理内存总量（32GB）</span><br><span class="line">2	14411180k used — 使用中的内存总量（14GB）</span><br><span class="line">3	18537836k free — 空闲内存总量（18GB）</span><br><span class="line">4  169884k buffers — 缓存的内存量 （169M）</span><br></pre></td></tr></table></figure>

<p>第五行，swap交换分区信息，具体信息说明如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1  32764556k total — 交换区总量（32GB）</span><br><span class="line">2  0k used — 使用的交换区总量（0K）</span><br><span class="line">3  32764556k free — 空闲交换区总量（32GB）</span><br><span class="line">4  3612636k cached — 缓冲的交换区总量（3.6GB）</span><br></pre></td></tr></table></figure>

<p>第六行，空行。</p>
<p>第七行以下：各进程（任务）的状态监控，项目列信息说明如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">1	PID — 进程id</span><br><span class="line">2	USER — 进程所有者</span><br><span class="line">3	PR — 进程优先级</span><br><span class="line">4	NI — nice值。负值表示高优先级，正值表示低优先级</span><br><span class="line">5	VIRT — 进程使用的虚拟内存总量，单位kb。VIRT=SWAP+RES</span><br><span class="line">6	RES — 进程使用的、未被换出的物理内存大小，单位kb。RES=CODE+DATA</span><br><span class="line">7	SHR — 共享内存大小，单位kb</span><br><span class="line">8	S — 进程状态。D=不可中断的睡眠状态 R=运行 S=睡眠 T=跟踪/停止 Z=僵尸进程</span><br><span class="line">9	%CPU — 上次更新到现在的CPU时间占用百分比</span><br><span class="line">10	%MEM — 进程使用的物理内存百分比</span><br><span class="line">11	TIME+ — 进程使用的CPU时间总计，单位1/100秒</span><br><span class="line">12	COMMAND — 进程名称（命令名/命令行）</span><br></pre></td></tr></table></figure>

<p>top 交互命令</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">1	 h 显示top交互命令帮助信息</span><br><span class="line">2	c 切换显示命令名称和完整命令行</span><br><span class="line">3	m 以内存使用率排序</span><br><span class="line">4	 P 根据CPU使用百分比大小进行排序</span><br><span class="line">5	T 根据时间/累计时间进行排序</span><br><span class="line">6  W 将当前设置写入~/.toprc文件中</span><br><span class="line">7	o或者O 改变显示项目的顺序</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="yum-命令"><a href="#yum-命令" class="headerlink" title="yum 命令"></a>yum 命令</h2><p>yum（ Yellow dog Updater, Modified）是一个在Fedora和RedHat以及</p>
<p>SUSE中的Shell前端软件包管理器。</p>
<p>基於RPM包管理，能够从指定的服务器自动下载RPM包并且安装，可以自动处理依赖性关系，并且一次安装所有依赖的软体包，无须繁琐地一次次下载、安装。</p>
<p>yum提供了查找、安装、删除某一个、一组甚至全部软件包的命令，而且命令简洁而又好记。</p>
<p>1.列出所有可更新的软件清单命令：yum check-update</p>
<p>2.更新所有软件命令：yum update</p>
<p>3.仅安装指定的软件命令：yum install</p>
<p>4.仅更新指定的软件命令：yum update</p>
<p>5.列出所有可安裝的软件清单命令：yum list</p>
<p>6.删除软件包命令：</p>
<ul>
<li>yum remove 7.查找软件包 命令：</li>
<li>yum search 8.清除缓存命令:</li>
<li>yum clean packages: 清除缓存目录下的软件包 yum clean headers: 清除缓存目录下的 headers</li>
<li>yum clean oldheaders: 清除缓存目录下旧的 headers</li>
<li>yum clean, yum clean all (&#x3D; yum clean packages; yum clean oldheaders) :清除缓存目录下的软件包及旧的headers</li>
</ul>
<p>实例</p>
<p>安装 pam-devel</p>
<p>1 [root@www ~]# yum install pam‐devel</p>
<h2 id="备份压缩命令-bzip2-命令"><a href="#备份压缩命令-bzip2-命令" class="headerlink" title="备份压缩命令 bzip2 命令"></a>备份压缩命令 bzip2 命令</h2><p>创建 *.bz2 压缩文件：bzip2 test.txt 。解压 *.bz2 文件：bzip2 -d test.txt.bz2 。</p>
<h2 id="gzip-命令"><a href="#gzip-命令" class="headerlink" title="gzip 命令"></a>gzip 命令</h2><p>创建一个 *.gz 的压缩文件：gzip test.txt 。解压 *.gz 文件：gzip -d test.txt.gz 。</p>
<p>显示压缩的比率：gzip -l *.gz 。</p>
<h2 id="tar-命令"><a href="#tar-命令" class="headerlink" title="tar 命令"></a>tar 命令</h2><p>用来压缩和解压文件。tar 本身不具有压缩功能，只具有打包功能，有关压缩及解压是调用其它的功能来完成。</p>
<p>弄清两个概念：打包和压缩。打包是指将一大堆文件或目录变成一个总的文件；压缩则是将一个大的文件通过一些压缩算法变成一个小文件常用参数：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">1	‐c 建立新的压缩文件</span><br><span class="line">2	‐f 指定压缩文件</span><br><span class="line">3	‐r 添加文件到已经压缩文件包中</span><br><span class="line">4	‐u 添加改了和现有的文件到压缩包中</span><br><span class="line">5	‐x 从压缩包中抽取文件</span><br><span class="line">6	‐t 显示压缩文件中的内容</span><br><span class="line">7	‐z 支持gzip压缩</span><br><span class="line">8	‐j 支持bzip2压缩</span><br><span class="line">9	‐Z 支持compress解压文件</span><br><span class="line">10	‐v 显示操作过程</span><br></pre></td></tr></table></figure>

<p>有关 gzip 及 bzip2 压缩:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">1	gzip 实例：压缩 gzip fileName .tar.gz 和.tgz 解压：gunzip filename.gz 或 gz ip ‐d filename.gz</span><br><span class="line">2	对应：tar zcvf filename.tar.gz tar zxvf filename.tar.gz</span><br><span class="line">3</span><br><span class="line">4	bz2实例：压缩 bzip2 ‐z filename .tar.bz2 解压：bunzip filename.bz2或bzip ‐d filename.bz2</span><br><span class="line">5	对应：tar jcvf filename.tar.gz 解压：tar jxvf filename.tar.bz2</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>实例：</p>
<p>（1）  将文件全部打包成 tar 包</p>
<p><code>1  tar ‐cvf log.tar 1.log,2.log 或tar ‐cvf log.*</code></p>
<p>（2）  将 &#x2F;etc 下的所有文件及目录打包到指定目录，并使用 gz 压缩</p>
<p><code>1  tar ‐zcvf /tmp/etc.tar.gz /etc</code></p>
<p>（3）  查看刚打包的文件内容（一定加z，因为是使用 gzip 压缩的）</p>
<p><code>1  tar ‐ztvf /tmp/etc.tar.gz</code></p>
<p>（4）  要压缩打包 &#x2F;home, &#x2F;etc ，但不要 &#x2F;home&#x2F;dmtsai</p>
<p><code>1  tar ‐‐exclude /home/dmtsai ‐zcvf myfile.tar.gz /home/* /etc</code></p>
<h2 id="unzip-命令"><a href="#unzip-命令" class="headerlink" title="unzip 命令"></a>unzip 命令</h2><p>解压 *.zip 文件：unzip test.zip 。查看 *.zip 文件的内容：unzip -l jasper.zip 。</p>

      
    </div>

    
    
    

       
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="善善332"
      src="/images/avatar.png">
  <p class="site-author-name" itemprop="name">善善332</p>
  <div class="site-description" itemprop="description">运气和努力一样重要</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">23</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/CHl332" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;CHl332" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:2541621686@qq.com" title="E-Mail → mailto:2541621686@qq.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="/images/mywechat.jpg" title="Wechar → &#x2F;images&#x2F;mywechat.jpg"><i class="fa-weixin fa-fw"></i>Wechar</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.instagram.com/shanshan3.32/" title="Instagram → https:&#x2F;&#x2F;www.instagram.com&#x2F;shanshan3.32&#x2F;" rel="noopener" target="_blank"><i class="fab fa-instagram fa-fw"></i>Instagram</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.yuque.com/docs/share/4fda01be-199a-4d34-aa02-eb4960d4fa2b#%20%E3%80%8ASpringCloud%E3%80%8B" title="YuQue → https:&#x2F;&#x2F;www.yuque.com&#x2F;docs&#x2F;share&#x2F;4fda01be-199a-4d34-aa02-eb4960d4fa2b?# 《SpringCloud》" rel="noopener" target="_blank"><i class="fa-file-text fa-fw"></i>YuQue</a>
      </span>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title"><i class="link fa-fw"></i>
      推荐阅读
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://funnylog.gitee.io/mysql45/iframe/" title="https:&#x2F;&#x2F;funnylog.gitee.io&#x2F;mysql45&#x2F;iframe&#x2F;" rel="noopener" target="_blank">MySQL45讲</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://fishc.com.cn/" title="https:&#x2F;&#x2F;fishc.com.cn" rel="noopener" target="_blank">鱼C论坛</a>
        </li>
    </ul>
  </div>

      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2022-09 – 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">善善332</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>


<!-- 自定义加上的 -->
<div class="theme-info">
  <div class="powered-by"></div>
  <span class="post-count">博客全站共255.2k字</span>
</div>


    <script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

    <span id="busuanzi_container_site_pv">总访问量<span id="busuanzi_value_site_pv"></span>次</span>
    <span class="post-meta-divider">|</span>
    <span id="busuanzi_container_site_uv">总访客数<span id="busuanzi_value_site_uv"></span>人</span>
    <span class="post-meta-divider">|</span>
<!-- 不蒜子计数初始值纠正 -->
<script>
$(document).ready(function() {

    var int = setInterval(fixCount, 50);  // 50ms周期检测函数
    var countOffset = 20000;  // 初始化首次数据

    function fixCount() {            
       if (document.getElementById("busuanzi_container_site_pv").style.display != "none")
        {
            $("#busuanzi_value_site_pv").html(parseInt($("#busuanzi_value_site_pv").html()) + countOffset); 
            clearInterval(int);
        }                  
        if ($("#busuanzi_container_site_pv").css("display") != "none")
        {
            $("#busuanzi_value_site_uv").html(parseInt($("#busuanzi_value_site_uv").html()) + countOffset); // 加上初始数据 
            clearInterval(int); // 停止检测
        }  
    }
       	
});
</script> 


        
<div class="busuanzi-count">
  <script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/pjax/pjax.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>

  <script>
var pjax = new Pjax({
  selectors: [
    'head title',
    '#page-configurations',
    '.content-wrap',
    '.post-toc-wrap',
    '.languages',
    '#pjax'
  ],
  switches: {
    '.post-toc-wrap': Pjax.switches.innerHTML
  },
  analytics: false,
  cacheBust: false,
  scrollTo : !CONFIG.bookmark.enable
});

window.addEventListener('pjax:success', () => {
  document.querySelectorAll('script[data-pjax], script#page-configurations, #pjax script').forEach(element => {
    var code = element.text || element.textContent || element.innerHTML || '';
    var parent = element.parentNode;
    parent.removeChild(element);
    var script = document.createElement('script');
    if (element.id) {
      script.id = element.id;
    }
    if (element.className) {
      script.className = element.className;
    }
    if (element.type) {
      script.type = element.type;
    }
    if (element.src) {
      script.src = element.src;
      // Force synchronous loading of peripheral JS.
      script.async = false;
    }
    if (element.dataset.pjax !== undefined) {
      script.dataset.pjax = '';
    }
    if (code !== '') {
      script.appendChild(document.createTextNode(code));
    }
    parent.appendChild(script);
  });
  NexT.boot.refresh();
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.subMenu)
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  NexT.utils.updateSidebarPosition();
});
</script>




  















    <div id="pjax">
  

  


    </div>
</body>

<script type="text/javascript">
var OriginTitile = document.title,
    st;
document.addEventListener("visibilitychange", function () {
    document.hidden ? (document.title = "暂时离开一下", clearTimeout(st)) : (document.title =
        "回来了O(∩_∩)O~", st = setTimeout(function () {
            document.title = OriginTitile
        }, 3e3))
})
</script>
</html>
